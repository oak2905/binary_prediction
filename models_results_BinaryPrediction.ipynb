{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oak2905/binary_prediction/blob/main/models_results_BinaryPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVjBI23l-6T9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader.data as reader\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH06Tw-Ca8dR",
        "outputId": "10f30dff-6e75-4ed5-e3bb-43426cbf4303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6CMHnXE3SEo"
      },
      "source": [
        "## **Import the data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTxbwYAv3DRc",
        "outputId": "53e21943-197d-43c9-b59e-72ef503c1dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEBANK_05.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^BSESN_05.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEI_05.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^CNXIT_05.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEMDCP50_05.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEI_02.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEBANK_02.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEMDCP50_02.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^BSESN_02.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^CNXIT_02.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEI_10.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEBANK_10.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^BSESN_10.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^CNXIT_10.csv\n",
            "/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF/^NSEMDCP50_10.csv\n"
          ]
        }
      ],
      "source": [
        "# import required module\n",
        "import os\n",
        "# assign directory\n",
        "directory = '/content/drive/MyDrive/Binary_Classification/Datasets_QW_BF'\n",
        "datasets = []\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        print(f)\n",
        "    df = pd.read_csv(f)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df.set_index('Date', inplace=True)\n",
        "    df = df.dropna(axis = 0)\n",
        "    df = df.astype('int64')\n",
        "    datasets.append(df)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bwio_8iECJj4",
        "outputId": "e7b4e33d-ecc6-4576-e97b-77eafcdd292e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            sma_trend  macd_trend  CCI_trend  RSI_trend  momentum_trend  \\\n",
              "Date                                                                      \n",
              "2011-01-31          1           1          1          1               1   \n",
              "2011-02-01          1           0          0          0               1   \n",
              "2011-02-02          1           0          0          0               0   \n",
              "2011-02-03          1           1          1          1               1   \n",
              "2011-02-04          1           0          0          0               0   \n",
              "...               ...         ...        ...        ...             ...   \n",
              "2019-12-23          0           1          0          0               1   \n",
              "2019-12-24          0           0          0          0               1   \n",
              "2019-12-26          0           0          0          0               1   \n",
              "2019-12-27          0           1          1          1               1   \n",
              "2019-12-30          0           0          1          0               1   \n",
              "\n",
              "            stck_trend  stcd_trend  ado_trend  lwr_trend  price_trend  \n",
              "Date                                                                   \n",
              "2011-01-31           1           0          0          0            1  \n",
              "2011-02-01           0           0          1          1            0  \n",
              "2011-02-02           0           0          0          1            0  \n",
              "2011-02-03           1           1          0          0            1  \n",
              "2011-02-04           0           0          1          1            0  \n",
              "...                ...         ...        ...        ...          ...  \n",
              "2019-12-23           0           0          1          1            0  \n",
              "2019-12-24           0           0          1          1            0  \n",
              "2019-12-26           0           0          1          1            0  \n",
              "2019-12-27           1           1          0          0            1  \n",
              "2019-12-30           0           0          1          1            0  \n",
              "\n",
              "[1905 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18b88969-9a4c-4f9c-ba25-a6f5866d061f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sma_trend</th>\n",
              "      <th>macd_trend</th>\n",
              "      <th>CCI_trend</th>\n",
              "      <th>RSI_trend</th>\n",
              "      <th>momentum_trend</th>\n",
              "      <th>stck_trend</th>\n",
              "      <th>stcd_trend</th>\n",
              "      <th>ado_trend</th>\n",
              "      <th>lwr_trend</th>\n",
              "      <th>price_trend</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-31</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-02-01</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-02-02</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-02-03</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-02-04</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-27</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1905 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b88969-9a4c-4f9c-ba25-a6f5866d061f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18b88969-9a4c-4f9c-ba25-a6f5866d061f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18b88969-9a4c-4f9c-ba25-a6f5866d061f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvhSnAN0qGHC",
        "outputId": "3245e8e8-ecf1-4f9f-dd66-633ba7250d83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "momentum_trend    9.142137e-07\n",
              "sma_trend         2.290614e-09\n",
              "macd_trend        8.085826e-31\n",
              "ado_trend         3.348540e-33\n",
              "stcd_trend        1.650753e-34\n",
              "CCI_trend         1.555961e-50\n",
              "RSI_trend         1.110203e-60\n",
              "lwr_trend         1.368918e-72\n",
              "stck_trend        5.015996e-75\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "p_values_all = []\n",
        "df = pd.DataFrame()\n",
        "for i in range(len(datasets)):\n",
        "\n",
        "  df = datasets[i]\n",
        "  X = df.loc[:,df.columns != 'price_trend']\n",
        "  X[X<0] = 0\n",
        "  y = df['price_trend']\n",
        "  chi_scores = chi2(X,y)\n",
        "\n",
        "  p_values = pd.Series(chi_scores[1],index = X.columns)\n",
        "  p_values.sort_values(ascending = False , inplace = True)\n",
        "  p_values_all.append(p_values)\n",
        "p_values_all[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "uUF8nmQWAF5I",
        "outputId": "b1c5a7f9-7ab1-4597-b582-5a1964c44faf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(p_values_all[3],color=\"red\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6upg8Kqi5dfz"
      },
      "source": [
        "## **Creating the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSd4gvnDTJIo"
      },
      "outputs": [],
      "source": [
        "train_data_all = []\n",
        "test_data_all = []\n",
        "df = pd.DataFrame()\n",
        "for i in range(len(datasets)):\n",
        " df = datasets[i]\n",
        " train_size = int(len(df)*0.8)\n",
        " train_data = df.iloc[:train_size]\n",
        " test_data = df.iloc[train_size:]\n",
        " train_data_all.append(train_data)\n",
        " test_data_all.append(test_data)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aJIdkgR5tiN"
      },
      "source": [
        "GRU/LSTM/SimpleRNN accepts a 3D input of the format (num_samples, num_timesteps, num_features). In the following model lookback is 30 because it is assumed that the model makes predictions based on the past 30 days data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXdPhE20UToP",
        "outputId": "cffa1c2f-ea50-4fe8-858c-f9f410c0d5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train.shape:  (1514, 10, 6)\n",
            "y_train.shape:  (1514, 1)\n",
            "X_test.shape:  (371, 10, 6)\n",
            "y_test.shape:  (371, 1)\n",
            "\n",
            "X_train.shape:  (1735, 10, 6)\n",
            "y_train.shape:  (1735, 1)\n",
            "X_test.shape:  (427, 10, 6)\n",
            "y_test.shape:  (427, 1)\n",
            "\n",
            "X_train.shape:  (1728, 10, 6)\n",
            "y_train.shape:  (1728, 1)\n",
            "X_test.shape:  (425, 10, 6)\n",
            "y_test.shape:  (425, 1)\n",
            "\n",
            "X_train.shape:  (1502, 10, 6)\n",
            "y_train.shape:  (1502, 1)\n",
            "X_test.shape:  (368, 10, 6)\n",
            "y_test.shape:  (368, 1)\n",
            "\n",
            "X_train.shape:  (1713, 10, 6)\n",
            "y_train.shape:  (1713, 1)\n",
            "X_test.shape:  (421, 10, 6)\n",
            "y_test.shape:  (421, 1)\n",
            "\n",
            "X_train.shape:  (1728, 10, 6)\n",
            "y_train.shape:  (1728, 1)\n",
            "X_test.shape:  (425, 10, 6)\n",
            "y_test.shape:  (425, 1)\n",
            "\n",
            "X_train.shape:  (1514, 10, 6)\n",
            "y_train.shape:  (1514, 1)\n",
            "X_test.shape:  (371, 10, 6)\n",
            "y_test.shape:  (371, 1)\n",
            "\n",
            "X_train.shape:  (1713, 10, 6)\n",
            "y_train.shape:  (1713, 1)\n",
            "X_test.shape:  (421, 10, 6)\n",
            "y_test.shape:  (421, 1)\n",
            "\n",
            "X_train.shape:  (1735, 10, 6)\n",
            "y_train.shape:  (1735, 1)\n",
            "X_test.shape:  (427, 10, 6)\n",
            "y_test.shape:  (427, 1)\n",
            "\n",
            "X_train.shape:  (1502, 10, 6)\n",
            "y_train.shape:  (1502, 1)\n",
            "X_test.shape:  (368, 10, 6)\n",
            "y_test.shape:  (368, 1)\n",
            "\n",
            "X_train.shape:  (1728, 10, 6)\n",
            "y_train.shape:  (1728, 1)\n",
            "X_test.shape:  (425, 10, 6)\n",
            "y_test.shape:  (425, 1)\n",
            "\n",
            "X_train.shape:  (1514, 10, 6)\n",
            "y_train.shape:  (1514, 1)\n",
            "X_test.shape:  (371, 10, 6)\n",
            "y_test.shape:  (371, 1)\n",
            "\n",
            "X_train.shape:  (1735, 10, 6)\n",
            "y_train.shape:  (1735, 1)\n",
            "X_test.shape:  (427, 10, 6)\n",
            "y_test.shape:  (427, 1)\n",
            "\n",
            "X_train.shape:  (1502, 10, 6)\n",
            "y_train.shape:  (1502, 1)\n",
            "X_test.shape:  (368, 10, 6)\n",
            "y_test.shape:  (368, 1)\n",
            "\n",
            "X_train.shape:  (1713, 10, 6)\n",
            "y_train.shape:  (1713, 1)\n",
            "X_test.shape:  (421, 10, 6)\n",
            "y_test.shape:  (421, 1)\n"
          ]
        }
      ],
      "source": [
        "def create_dataset (X, look_back = 1):\n",
        "    Xs, ys = [], []\n",
        " \n",
        "    for i in range(len(X)-look_back):\n",
        "        v = X[X.columns[0:6]].iloc[i:i+look_back]\n",
        "        Xs.append(v)\n",
        "        ys.append(X['price_trend'].iloc[i+look_back])\n",
        " \n",
        "    return np.array(Xs), np.array(ys)\n",
        "LOOK_BACK = 10\n",
        "X_train_all = []\n",
        "y_train_all = []\n",
        "X_test_all = []\n",
        "y_test_all = []\n",
        "for i in range(len(datasets)):\n",
        "\n",
        "  X_train, y_train = create_dataset(train_data_all[i],LOOK_BACK)\n",
        "  X_test, y_test = create_dataset(test_data_all[i],LOOK_BACK)\n",
        "  y_train = y_train.reshape(-1,1)\n",
        "  y_test = y_test.reshape(-1,1)\n",
        "  X_train_all.append(X_train)\n",
        "  X_test_all.append(X_test)\n",
        "  y_train_all.append(y_train)\n",
        "  y_test_all.append(y_test)\n",
        "# Print data shape\n",
        "  print('\\nX_train.shape: ', X_train.shape)\n",
        "  print('y_train.shape: ', y_train.shape)\n",
        "  print('X_test.shape: ', X_test.shape) \n",
        "  print('y_test.shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbbHkLRx8ZAy"
      },
      "source": [
        "## **Creating and fitting the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6azfUQTG4kW"
      },
      "source": [
        "**(1) GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeqnsY-TBlch",
        "outputId": "06bccdd1-dce1-4605-f3a5-0379dc209235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 10, 64)            13824     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 64)            0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 100)               49800     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73,926\n",
            "Trainable params: 73,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create GRU model\n",
        "def create_gru(units):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(GRU (units = units, return_sequences = True, \n",
        "                   input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
        "    model.add(Dropout(0.2)) \n",
        "\n",
        "    # Hidden layer\n",
        "    model.add(GRU(units = 100)) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units = 100))\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "    #Compile model\n",
        "    #model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"binary_accuracy\"])\n",
        "    model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "    return model\n",
        "model_gru = create_gru(64)\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOpyUTofJSqi"
      },
      "source": [
        "**(2) LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa4U_ZNdJcr0",
        "outputId": "d6c673d5-6cc7-4596-bff8-7c3044d61a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 10, 64)            18176     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               66000     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94,478\n",
            "Trainable params: 94,478\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create LSTM model\n",
        "def create_lstm(units):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(LSTM (units = units, return_sequences = True, \n",
        "                   input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
        "    model.add(Dropout(0.2)) \n",
        "\n",
        "    # Hidden layer\n",
        "    model.add(LSTM(units = 100)) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units = 100))\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "    #Compile model\n",
        "    #model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"binary_accuracy\"])\n",
        "    model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "    return model\n",
        "model_lstm = create_lstm(64)\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YwHQ_jnLJB4"
      },
      "source": [
        "**(3) RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUQR-nqaLH6s",
        "outputId": "53f45f0a-99da-4ff4-bd93-1484d4bd8ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 10, 64)            4544      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10, 64)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               16500     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,346\n",
            "Trainable params: 31,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create RNN model\n",
        "def create_rnn(units):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(SimpleRNN (units, return_sequences = True, \n",
        "                        input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
        "    model.add(Dropout(0.2)) \n",
        "\n",
        "    # Hidden layer\n",
        "    model.add(SimpleRNN(units = 100)) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units = 100))\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "    #Compile model\n",
        "    #model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"binary_accuracy\"])\n",
        "    model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "    return model\n",
        "model_rnn = create_rnn(64)\n",
        "model_rnn.build(X_train.shape)\n",
        "model_rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qpCn45ZQDEn"
      },
      "outputs": [],
      "source": [
        "def fit_model(model,X_train,y_train):\n",
        "    #early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10)\n",
        "    callbacks = [\n",
        "      keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=10, min_lr=0.00000000000000000001\n",
        "      ),\n",
        "      keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=100, verbose=1),\n",
        "    ]\n",
        "    history = model.fit(X_train, y_train, epochs = 10000,  \n",
        "                        validation_split = 0.2,\n",
        "                        batch_size = 16, shuffle = False, \n",
        "                        callbacks = callbacks)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC38DjMCJAX1",
        "outputId": "45e4f6d3-6bd4-484d-9d8a-47bb05b0a253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 6s 28ms/step - loss: 0.6649 - accuracy: 0.6367 - val_loss: 0.5872 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6534 - accuracy: 0.6424 - val_loss: 0.5872 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6538 - accuracy: 0.6375 - val_loss: 0.5931 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6513 - accuracy: 0.6400 - val_loss: 0.5954 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6503 - accuracy: 0.6416 - val_loss: 0.5940 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6489 - accuracy: 0.6408 - val_loss: 0.5949 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6474 - accuracy: 0.6400 - val_loss: 0.5947 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6487 - accuracy: 0.6424 - val_loss: 0.5995 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6449 - accuracy: 0.6416 - val_loss: 0.5947 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6467 - accuracy: 0.6424 - val_loss: 0.5926 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6450 - accuracy: 0.6367 - val_loss: 0.5975 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6381 - accuracy: 0.6433 - val_loss: 0.6082 - val_accuracy: 0.7096 - lr: 5.0000e-04\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6391 - accuracy: 0.6441 - val_loss: 0.6056 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6372 - accuracy: 0.6457 - val_loss: 0.6075 - val_accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6359 - accuracy: 0.6524 - val_loss: 0.6109 - val_accuracy: 0.6997 - lr: 5.0000e-04\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6334 - accuracy: 0.6540 - val_loss: 0.6131 - val_accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6344 - accuracy: 0.6515 - val_loss: 0.6142 - val_accuracy: 0.6898 - lr: 5.0000e-04\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6331 - accuracy: 0.6557 - val_loss: 0.6153 - val_accuracy: 0.6964 - lr: 5.0000e-04\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6285 - accuracy: 0.6631 - val_loss: 0.6169 - val_accuracy: 0.6733 - lr: 5.0000e-04\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6282 - accuracy: 0.6647 - val_loss: 0.6171 - val_accuracy: 0.6766 - lr: 5.0000e-04\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6305 - accuracy: 0.6482 - val_loss: 0.6174 - val_accuracy: 0.6733 - lr: 5.0000e-04\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6262 - accuracy: 0.6606 - val_loss: 0.6247 - val_accuracy: 0.6700 - lr: 2.5000e-04\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6275 - accuracy: 0.6590 - val_loss: 0.6256 - val_accuracy: 0.6700 - lr: 2.5000e-04\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6243 - accuracy: 0.6631 - val_loss: 0.6299 - val_accuracy: 0.6667 - lr: 2.5000e-04\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6246 - accuracy: 0.6656 - val_loss: 0.6268 - val_accuracy: 0.6700 - lr: 2.5000e-04\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6250 - accuracy: 0.6581 - val_loss: 0.6274 - val_accuracy: 0.6634 - lr: 2.5000e-04\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6234 - accuracy: 0.6639 - val_loss: 0.6276 - val_accuracy: 0.6601 - lr: 2.5000e-04\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6204 - accuracy: 0.6631 - val_loss: 0.6326 - val_accuracy: 0.6667 - lr: 2.5000e-04\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6229 - accuracy: 0.6614 - val_loss: 0.6328 - val_accuracy: 0.6568 - lr: 2.5000e-04\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6197 - accuracy: 0.6631 - val_loss: 0.6360 - val_accuracy: 0.6634 - lr: 2.5000e-04\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6182 - accuracy: 0.6722 - val_loss: 0.6403 - val_accuracy: 0.6601 - lr: 2.5000e-04\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6155 - accuracy: 0.6664 - val_loss: 0.6378 - val_accuracy: 0.6700 - lr: 1.2500e-04\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6139 - accuracy: 0.6705 - val_loss: 0.6404 - val_accuracy: 0.6733 - lr: 1.2500e-04\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6122 - accuracy: 0.6705 - val_loss: 0.6417 - val_accuracy: 0.6700 - lr: 1.2500e-04\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6132 - accuracy: 0.6664 - val_loss: 0.6432 - val_accuracy: 0.6799 - lr: 1.2500e-04\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6112 - accuracy: 0.6713 - val_loss: 0.6471 - val_accuracy: 0.6634 - lr: 1.2500e-04\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6097 - accuracy: 0.6771 - val_loss: 0.6477 - val_accuracy: 0.6568 - lr: 1.2500e-04\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6153 - accuracy: 0.6656 - val_loss: 0.6467 - val_accuracy: 0.6700 - lr: 1.2500e-04\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6097 - accuracy: 0.6713 - val_loss: 0.6505 - val_accuracy: 0.6601 - lr: 1.2500e-04\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6098 - accuracy: 0.6722 - val_loss: 0.6511 - val_accuracy: 0.6634 - lr: 1.2500e-04\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6060 - accuracy: 0.6796 - val_loss: 0.6574 - val_accuracy: 0.6535 - lr: 1.2500e-04\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6056 - accuracy: 0.6680 - val_loss: 0.6568 - val_accuracy: 0.6601 - lr: 6.2500e-05\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6050 - accuracy: 0.6780 - val_loss: 0.6578 - val_accuracy: 0.6634 - lr: 6.2500e-05\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.6072 - accuracy: 0.6796 - val_loss: 0.6555 - val_accuracy: 0.6634 - lr: 6.2500e-05\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6057 - accuracy: 0.6780 - val_loss: 0.6582 - val_accuracy: 0.6667 - lr: 6.2500e-05\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6052 - accuracy: 0.6771 - val_loss: 0.6576 - val_accuracy: 0.6634 - lr: 6.2500e-05\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6029 - accuracy: 0.6763 - val_loss: 0.6577 - val_accuracy: 0.6568 - lr: 6.2500e-05\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5997 - accuracy: 0.6746 - val_loss: 0.6617 - val_accuracy: 0.6667 - lr: 6.2500e-05\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6049 - accuracy: 0.6771 - val_loss: 0.6636 - val_accuracy: 0.6568 - lr: 6.2500e-05\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6028 - accuracy: 0.6813 - val_loss: 0.6622 - val_accuracy: 0.6601 - lr: 6.2500e-05\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6023 - accuracy: 0.6746 - val_loss: 0.6631 - val_accuracy: 0.6502 - lr: 6.2500e-05\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6035 - accuracy: 0.6746 - val_loss: 0.6636 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.6005 - accuracy: 0.6813 - val_loss: 0.6653 - val_accuracy: 0.6502 - lr: 3.1250e-05\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6017 - accuracy: 0.6804 - val_loss: 0.6644 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5950 - accuracy: 0.6804 - val_loss: 0.6662 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6009 - accuracy: 0.6746 - val_loss: 0.6660 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.6788 - val_loss: 0.6650 - val_accuracy: 0.6502 - lr: 3.1250e-05\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5984 - accuracy: 0.6804 - val_loss: 0.6657 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5986 - accuracy: 0.6730 - val_loss: 0.6656 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.6821 - val_loss: 0.6665 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6008 - accuracy: 0.6771 - val_loss: 0.6671 - val_accuracy: 0.6469 - lr: 3.1250e-05\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6005 - accuracy: 0.6804 - val_loss: 0.6671 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6015 - accuracy: 0.6788 - val_loss: 0.6674 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5974 - accuracy: 0.6846 - val_loss: 0.6683 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5993 - accuracy: 0.6887 - val_loss: 0.6683 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5962 - accuracy: 0.6796 - val_loss: 0.6684 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5937 - accuracy: 0.6846 - val_loss: 0.6697 - val_accuracy: 0.6568 - lr: 1.5625e-05\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5958 - accuracy: 0.6788 - val_loss: 0.6704 - val_accuracy: 0.6568 - lr: 1.5625e-05\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5961 - accuracy: 0.6887 - val_loss: 0.6714 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5971 - accuracy: 0.6821 - val_loss: 0.6718 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5988 - accuracy: 0.6903 - val_loss: 0.6713 - val_accuracy: 0.6535 - lr: 1.5625e-05\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5977 - accuracy: 0.6821 - val_loss: 0.6714 - val_accuracy: 0.6568 - lr: 7.8125e-06\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5978 - accuracy: 0.6804 - val_loss: 0.6716 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5949 - accuracy: 0.6846 - val_loss: 0.6721 - val_accuracy: 0.6568 - lr: 7.8125e-06\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5986 - accuracy: 0.6854 - val_loss: 0.6720 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6014 - accuracy: 0.6846 - val_loss: 0.6719 - val_accuracy: 0.6568 - lr: 7.8125e-06\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5997 - accuracy: 0.6854 - val_loss: 0.6719 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.5989 - accuracy: 0.6780 - val_loss: 0.6722 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5983 - accuracy: 0.6804 - val_loss: 0.6723 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5934 - accuracy: 0.6796 - val_loss: 0.6722 - val_accuracy: 0.6535 - lr: 7.8125e-06\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5975 - accuracy: 0.6862 - val_loss: 0.6722 - val_accuracy: 0.6502 - lr: 7.8125e-06\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6017 - accuracy: 0.6813 - val_loss: 0.6722 - val_accuracy: 0.6502 - lr: 3.9063e-06\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6024 - accuracy: 0.6796 - val_loss: 0.6722 - val_accuracy: 0.6502 - lr: 3.9063e-06\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6003 - accuracy: 0.6763 - val_loss: 0.6723 - val_accuracy: 0.6502 - lr: 3.9063e-06\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6035 - accuracy: 0.6763 - val_loss: 0.6722 - val_accuracy: 0.6502 - lr: 3.9063e-06\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5981 - accuracy: 0.6887 - val_loss: 0.6723 - val_accuracy: 0.6502 - lr: 3.9063e-06\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5986 - accuracy: 0.6780 - val_loss: 0.6722 - val_accuracy: 0.6469 - lr: 3.9063e-06\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5954 - accuracy: 0.6862 - val_loss: 0.6725 - val_accuracy: 0.6469 - lr: 3.9063e-06\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5974 - accuracy: 0.6920 - val_loss: 0.6726 - val_accuracy: 0.6469 - lr: 3.9063e-06\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5982 - accuracy: 0.6755 - val_loss: 0.6724 - val_accuracy: 0.6469 - lr: 3.9063e-06\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5945 - accuracy: 0.6821 - val_loss: 0.6724 - val_accuracy: 0.6469 - lr: 3.9063e-06\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5976 - accuracy: 0.6928 - val_loss: 0.6725 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5971 - accuracy: 0.6829 - val_loss: 0.6725 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6023 - accuracy: 0.6763 - val_loss: 0.6725 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5954 - accuracy: 0.6837 - val_loss: 0.6726 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5985 - accuracy: 0.6796 - val_loss: 0.6726 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.6895 - val_loss: 0.6727 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5980 - accuracy: 0.6862 - val_loss: 0.6727 - val_accuracy: 0.6469 - lr: 1.9531e-06\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5964 - accuracy: 0.6912 - val_loss: 0.6728 - val_accuracy: 0.6502 - lr: 1.9531e-06\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5997 - accuracy: 0.6788 - val_loss: 0.6728 - val_accuracy: 0.6502 - lr: 1.9531e-06\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5952 - accuracy: 0.6813 - val_loss: 0.6729 - val_accuracy: 0.6502 - lr: 1.9531e-06\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6453 - accuracy: 0.6520 - val_loss: 0.6167 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6428 - accuracy: 0.6520 - val_loss: 0.6156 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6385 - accuracy: 0.6592 - val_loss: 0.6146 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6364 - accuracy: 0.6635 - val_loss: 0.6136 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6373 - accuracy: 0.6621 - val_loss: 0.6127 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6407 - accuracy: 0.6556 - val_loss: 0.6118 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6348 - accuracy: 0.6722 - val_loss: 0.6110 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6363 - accuracy: 0.6599 - val_loss: 0.6102 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6353 - accuracy: 0.6592 - val_loss: 0.6094 - val_accuracy: 0.7003 - lr: 9.7656e-07\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6348 - accuracy: 0.6635 - val_loss: 0.6087 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6272 - accuracy: 0.6765 - val_loss: 0.6080 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6291 - accuracy: 0.6643 - val_loss: 0.6073 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6329 - accuracy: 0.6715 - val_loss: 0.6066 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6333 - accuracy: 0.6700 - val_loss: 0.6060 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6327 - accuracy: 0.6729 - val_loss: 0.6053 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6302 - accuracy: 0.6722 - val_loss: 0.6047 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6268 - accuracy: 0.6780 - val_loss: 0.6041 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6298 - accuracy: 0.6736 - val_loss: 0.6035 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6287 - accuracy: 0.6693 - val_loss: 0.6030 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6294 - accuracy: 0.6801 - val_loss: 0.6024 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6269 - accuracy: 0.6729 - val_loss: 0.6019 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6260 - accuracy: 0.6830 - val_loss: 0.6014 - val_accuracy: 0.7003 - lr: 9.7656e-07\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6266 - accuracy: 0.6751 - val_loss: 0.6009 - val_accuracy: 0.7003 - lr: 9.7656e-07\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6257 - accuracy: 0.6794 - val_loss: 0.6005 - val_accuracy: 0.7003 - lr: 9.7656e-07\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6235 - accuracy: 0.6758 - val_loss: 0.6000 - val_accuracy: 0.7032 - lr: 9.7656e-07\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6267 - accuracy: 0.6801 - val_loss: 0.5995 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6274 - accuracy: 0.6722 - val_loss: 0.5990 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6246 - accuracy: 0.6837 - val_loss: 0.5986 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6239 - accuracy: 0.6873 - val_loss: 0.5982 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6283 - accuracy: 0.6823 - val_loss: 0.5978 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6289 - accuracy: 0.6787 - val_loss: 0.5973 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6278 - accuracy: 0.6852 - val_loss: 0.5969 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6223 - accuracy: 0.6888 - val_loss: 0.5965 - val_accuracy: 0.7061 - lr: 9.7656e-07\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6272 - accuracy: 0.6844 - val_loss: 0.5962 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6230 - accuracy: 0.6816 - val_loss: 0.5958 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6237 - accuracy: 0.6837 - val_loss: 0.5954 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6233 - accuracy: 0.6780 - val_loss: 0.5951 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6208 - accuracy: 0.6844 - val_loss: 0.5948 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6234 - accuracy: 0.6808 - val_loss: 0.5944 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6233 - accuracy: 0.6859 - val_loss: 0.5941 - val_accuracy: 0.7089 - lr: 9.7656e-07\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6220 - accuracy: 0.6880 - val_loss: 0.5938 - val_accuracy: 0.7147 - lr: 9.7656e-07\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6192 - accuracy: 0.6895 - val_loss: 0.5934 - val_accuracy: 0.7147 - lr: 9.7656e-07\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6237 - accuracy: 0.6837 - val_loss: 0.5931 - val_accuracy: 0.7176 - lr: 9.7656e-07\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6186 - accuracy: 0.6888 - val_loss: 0.5928 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6190 - accuracy: 0.6866 - val_loss: 0.5925 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6229 - accuracy: 0.6880 - val_loss: 0.5923 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6162 - accuracy: 0.6909 - val_loss: 0.5920 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6213 - accuracy: 0.6866 - val_loss: 0.5918 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6220 - accuracy: 0.6902 - val_loss: 0.5915 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6170 - accuracy: 0.6873 - val_loss: 0.5912 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6183 - accuracy: 0.6931 - val_loss: 0.5910 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6125 - accuracy: 0.6967 - val_loss: 0.5907 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6174 - accuracy: 0.6866 - val_loss: 0.5905 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6193 - accuracy: 0.6960 - val_loss: 0.5903 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6192 - accuracy: 0.6859 - val_loss: 0.5901 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6186 - accuracy: 0.6895 - val_loss: 0.5898 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6210 - accuracy: 0.6916 - val_loss: 0.5896 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6154 - accuracy: 0.6895 - val_loss: 0.5894 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6150 - accuracy: 0.6974 - val_loss: 0.5892 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6149 - accuracy: 0.6945 - val_loss: 0.5890 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6157 - accuracy: 0.6931 - val_loss: 0.5888 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6184 - accuracy: 0.6931 - val_loss: 0.5886 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6136 - accuracy: 0.6988 - val_loss: 0.5884 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6110 - accuracy: 0.7010 - val_loss: 0.5882 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6140 - accuracy: 0.6974 - val_loss: 0.5881 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6142 - accuracy: 0.6967 - val_loss: 0.5879 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6170 - accuracy: 0.6902 - val_loss: 0.5877 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6140 - accuracy: 0.6981 - val_loss: 0.5875 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6138 - accuracy: 0.7003 - val_loss: 0.5874 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6126 - accuracy: 0.6916 - val_loss: 0.5872 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6154 - accuracy: 0.6895 - val_loss: 0.5870 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6144 - accuracy: 0.6931 - val_loss: 0.5868 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6161 - accuracy: 0.6931 - val_loss: 0.5867 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6150 - accuracy: 0.6938 - val_loss: 0.5866 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6122 - accuracy: 0.6974 - val_loss: 0.5864 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6121 - accuracy: 0.7017 - val_loss: 0.5863 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6101 - accuracy: 0.6974 - val_loss: 0.5861 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6106 - accuracy: 0.6988 - val_loss: 0.5860 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6127 - accuracy: 0.6981 - val_loss: 0.5858 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6124 - accuracy: 0.6931 - val_loss: 0.5857 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6111 - accuracy: 0.7039 - val_loss: 0.5856 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6100 - accuracy: 0.7017 - val_loss: 0.5854 - val_accuracy: 0.7205 - lr: 9.7656e-07\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6126 - accuracy: 0.6974 - val_loss: 0.5853 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6132 - accuracy: 0.7032 - val_loss: 0.5852 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6136 - accuracy: 0.6981 - val_loss: 0.5850 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6091 - accuracy: 0.7003 - val_loss: 0.5849 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6147 - accuracy: 0.6981 - val_loss: 0.5848 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6122 - accuracy: 0.7024 - val_loss: 0.5846 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6086 - accuracy: 0.6974 - val_loss: 0.5845 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6117 - accuracy: 0.7010 - val_loss: 0.5844 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6068 - accuracy: 0.6967 - val_loss: 0.5843 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6092 - accuracy: 0.7024 - val_loss: 0.5842 - val_accuracy: 0.7233 - lr: 9.7656e-07\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6137 - accuracy: 0.6974 - val_loss: 0.5841 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6087 - accuracy: 0.6974 - val_loss: 0.5840 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6099 - accuracy: 0.6952 - val_loss: 0.5839 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6108 - accuracy: 0.7003 - val_loss: 0.5838 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6086 - accuracy: 0.7032 - val_loss: 0.5837 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6098 - accuracy: 0.6988 - val_loss: 0.5836 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6097 - accuracy: 0.7017 - val_loss: 0.5835 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6115 - accuracy: 0.6996 - val_loss: 0.5834 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6078 - accuracy: 0.7032 - val_loss: 0.5833 - val_accuracy: 0.7262 - lr: 9.7656e-07\n",
            "Epoch 102/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6103 - accuracy: 0.7032 - val_loss: 0.5832 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 103/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6076 - accuracy: 0.7010 - val_loss: 0.5832 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 104/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6063 - accuracy: 0.6981 - val_loss: 0.5831 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 105/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6079 - accuracy: 0.7024 - val_loss: 0.5830 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 106/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6084 - accuracy: 0.7039 - val_loss: 0.5829 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 107/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6110 - accuracy: 0.7046 - val_loss: 0.5828 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 108/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6072 - accuracy: 0.7068 - val_loss: 0.5828 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 109/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6090 - accuracy: 0.6974 - val_loss: 0.5827 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 110/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6071 - accuracy: 0.7003 - val_loss: 0.5826 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 111/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6098 - accuracy: 0.7046 - val_loss: 0.5825 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 112/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6074 - accuracy: 0.7017 - val_loss: 0.5824 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 113/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6084 - accuracy: 0.7010 - val_loss: 0.5823 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 114/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6048 - accuracy: 0.6945 - val_loss: 0.5822 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 115/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6070 - accuracy: 0.7046 - val_loss: 0.5821 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 116/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6063 - accuracy: 0.6945 - val_loss: 0.5821 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 117/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6071 - accuracy: 0.7003 - val_loss: 0.5820 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 118/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6077 - accuracy: 0.7003 - val_loss: 0.5819 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 119/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6086 - accuracy: 0.6981 - val_loss: 0.5818 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 120/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6071 - accuracy: 0.7017 - val_loss: 0.5817 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 121/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6061 - accuracy: 0.7046 - val_loss: 0.5817 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 122/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6054 - accuracy: 0.7039 - val_loss: 0.5816 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 123/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6078 - accuracy: 0.7010 - val_loss: 0.5815 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 124/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6063 - accuracy: 0.6988 - val_loss: 0.5815 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 125/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6064 - accuracy: 0.6967 - val_loss: 0.5814 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 126/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6066 - accuracy: 0.7017 - val_loss: 0.5813 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 127/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6038 - accuracy: 0.7039 - val_loss: 0.5813 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 128/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6056 - accuracy: 0.7032 - val_loss: 0.5812 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 129/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6046 - accuracy: 0.6981 - val_loss: 0.5811 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 130/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6040 - accuracy: 0.7039 - val_loss: 0.5811 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 131/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.7046 - val_loss: 0.5810 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 132/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6038 - accuracy: 0.7017 - val_loss: 0.5810 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 133/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6071 - accuracy: 0.7024 - val_loss: 0.5809 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 134/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6073 - accuracy: 0.7039 - val_loss: 0.5809 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 135/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6071 - accuracy: 0.7039 - val_loss: 0.5808 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 136/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6064 - accuracy: 0.7010 - val_loss: 0.5808 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 137/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6071 - accuracy: 0.7024 - val_loss: 0.5807 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 138/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6063 - accuracy: 0.6974 - val_loss: 0.5807 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 139/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6077 - accuracy: 0.7032 - val_loss: 0.5806 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 140/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6048 - accuracy: 0.7003 - val_loss: 0.5806 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 141/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6051 - accuracy: 0.7039 - val_loss: 0.5805 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 142/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6079 - accuracy: 0.7017 - val_loss: 0.5804 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 143/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6081 - accuracy: 0.7017 - val_loss: 0.5804 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 144/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6087 - accuracy: 0.6967 - val_loss: 0.5803 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 145/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6025 - accuracy: 0.6952 - val_loss: 0.5803 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 146/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6062 - accuracy: 0.7046 - val_loss: 0.5802 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 147/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6045 - accuracy: 0.7061 - val_loss: 0.5802 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 148/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6049 - accuracy: 0.7061 - val_loss: 0.5801 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 149/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6042 - accuracy: 0.7024 - val_loss: 0.5801 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 150/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6035 - accuracy: 0.7032 - val_loss: 0.5800 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 151/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6033 - accuracy: 0.7032 - val_loss: 0.5800 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 152/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6063 - accuracy: 0.7032 - val_loss: 0.5799 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 153/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6022 - accuracy: 0.7075 - val_loss: 0.5799 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 154/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6026 - accuracy: 0.7046 - val_loss: 0.5798 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 155/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6048 - accuracy: 0.7032 - val_loss: 0.5798 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 156/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6058 - accuracy: 0.7039 - val_loss: 0.5797 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 157/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6053 - accuracy: 0.7053 - val_loss: 0.5797 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 158/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6053 - accuracy: 0.7075 - val_loss: 0.5797 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 159/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6019 - accuracy: 0.7075 - val_loss: 0.5796 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 160/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6047 - accuracy: 0.7061 - val_loss: 0.5796 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 161/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6022 - accuracy: 0.7046 - val_loss: 0.5795 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 162/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6061 - accuracy: 0.7039 - val_loss: 0.5795 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 163/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6058 - accuracy: 0.7061 - val_loss: 0.5795 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 164/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6039 - accuracy: 0.7017 - val_loss: 0.5794 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 165/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6027 - accuracy: 0.7061 - val_loss: 0.5794 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 166/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6074 - accuracy: 0.6988 - val_loss: 0.5793 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 167/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6044 - accuracy: 0.6981 - val_loss: 0.5793 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 168/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6014 - accuracy: 0.7003 - val_loss: 0.5793 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 169/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6024 - accuracy: 0.7032 - val_loss: 0.5792 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 170/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6027 - accuracy: 0.7003 - val_loss: 0.5792 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 171/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6029 - accuracy: 0.6996 - val_loss: 0.5792 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 172/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6032 - accuracy: 0.7061 - val_loss: 0.5791 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 173/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6052 - accuracy: 0.7032 - val_loss: 0.5791 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 174/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6013 - accuracy: 0.7053 - val_loss: 0.5790 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 175/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6045 - accuracy: 0.7017 - val_loss: 0.5790 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 176/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6017 - accuracy: 0.7017 - val_loss: 0.5789 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 177/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6021 - accuracy: 0.7024 - val_loss: 0.5789 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 178/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6054 - accuracy: 0.7082 - val_loss: 0.5789 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 179/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6018 - accuracy: 0.6981 - val_loss: 0.5788 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 180/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6047 - accuracy: 0.7046 - val_loss: 0.5788 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 181/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6036 - accuracy: 0.7075 - val_loss: 0.5788 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 182/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6018 - accuracy: 0.7039 - val_loss: 0.5787 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 183/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6033 - accuracy: 0.7068 - val_loss: 0.5787 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 184/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6026 - accuracy: 0.7032 - val_loss: 0.5787 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 185/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6020 - accuracy: 0.7061 - val_loss: 0.5786 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 186/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6024 - accuracy: 0.7061 - val_loss: 0.5786 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 187/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6003 - accuracy: 0.7068 - val_loss: 0.5786 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 188/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6038 - accuracy: 0.7053 - val_loss: 0.5786 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 189/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.5997 - accuracy: 0.7068 - val_loss: 0.5785 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 190/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6016 - accuracy: 0.7039 - val_loss: 0.5785 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 191/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6016 - accuracy: 0.7032 - val_loss: 0.5784 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 192/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5999 - accuracy: 0.7053 - val_loss: 0.5784 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 193/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5991 - accuracy: 0.7068 - val_loss: 0.5784 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 194/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6007 - accuracy: 0.7053 - val_loss: 0.5784 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 195/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6033 - accuracy: 0.7082 - val_loss: 0.5783 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 196/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6025 - accuracy: 0.7003 - val_loss: 0.5783 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 197/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6002 - accuracy: 0.7039 - val_loss: 0.5783 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 198/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6033 - accuracy: 0.7024 - val_loss: 0.5782 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 199/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6011 - accuracy: 0.7032 - val_loss: 0.5782 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 200/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5988 - accuracy: 0.7053 - val_loss: 0.5782 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 201/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5996 - accuracy: 0.7061 - val_loss: 0.5781 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 202/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5988 - accuracy: 0.7061 - val_loss: 0.5781 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 203/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6001 - accuracy: 0.7039 - val_loss: 0.5781 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 204/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6047 - accuracy: 0.7068 - val_loss: 0.5780 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 205/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6030 - accuracy: 0.7053 - val_loss: 0.5780 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 206/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5988 - accuracy: 0.7068 - val_loss: 0.5780 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 207/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6004 - accuracy: 0.7068 - val_loss: 0.5779 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 208/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6040 - accuracy: 0.7053 - val_loss: 0.5779 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 209/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6015 - accuracy: 0.7032 - val_loss: 0.5779 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 210/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6022 - accuracy: 0.7075 - val_loss: 0.5778 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 211/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6034 - accuracy: 0.7032 - val_loss: 0.5778 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 212/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6025 - accuracy: 0.7075 - val_loss: 0.5777 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 213/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5999 - accuracy: 0.7003 - val_loss: 0.5777 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 214/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6037 - accuracy: 0.7017 - val_loss: 0.5777 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 215/10000\n",
            "87/87 [==============================] - 1s 16ms/step - loss: 0.6036 - accuracy: 0.7024 - val_loss: 0.5777 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 216/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5997 - accuracy: 0.7068 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 217/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6010 - accuracy: 0.7075 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 218/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5985 - accuracy: 0.7104 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 219/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6017 - accuracy: 0.7032 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 220/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6009 - accuracy: 0.7053 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 221/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6018 - accuracy: 0.7046 - val_loss: 0.5776 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 222/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5994 - accuracy: 0.7039 - val_loss: 0.5775 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 223/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6015 - accuracy: 0.7017 - val_loss: 0.5775 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 224/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5987 - accuracy: 0.7053 - val_loss: 0.5775 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 225/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6021 - accuracy: 0.7046 - val_loss: 0.5775 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 226/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6032 - accuracy: 0.7082 - val_loss: 0.5775 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 227/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6033 - accuracy: 0.7061 - val_loss: 0.5774 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 228/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6005 - accuracy: 0.6996 - val_loss: 0.5774 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 229/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5977 - accuracy: 0.7082 - val_loss: 0.5774 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 230/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5995 - accuracy: 0.7024 - val_loss: 0.5773 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 231/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6008 - accuracy: 0.7046 - val_loss: 0.5773 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 232/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6026 - accuracy: 0.7075 - val_loss: 0.5773 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 233/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6007 - accuracy: 0.7039 - val_loss: 0.5772 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 234/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5984 - accuracy: 0.7024 - val_loss: 0.5772 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 235/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6024 - accuracy: 0.7003 - val_loss: 0.5772 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 236/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6022 - accuracy: 0.7017 - val_loss: 0.5772 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 237/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6023 - accuracy: 0.7061 - val_loss: 0.5772 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 238/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5992 - accuracy: 0.7097 - val_loss: 0.5771 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 239/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6009 - accuracy: 0.7068 - val_loss: 0.5771 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 240/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5972 - accuracy: 0.7024 - val_loss: 0.5771 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 241/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5963 - accuracy: 0.7061 - val_loss: 0.5771 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 242/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6001 - accuracy: 0.7061 - val_loss: 0.5770 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 243/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5996 - accuracy: 0.7053 - val_loss: 0.5770 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 244/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5988 - accuracy: 0.7097 - val_loss: 0.5770 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 245/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6017 - accuracy: 0.7003 - val_loss: 0.5770 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 246/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5990 - accuracy: 0.7068 - val_loss: 0.5769 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 247/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5985 - accuracy: 0.7068 - val_loss: 0.5769 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 248/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5984 - accuracy: 0.7061 - val_loss: 0.5769 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 249/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5994 - accuracy: 0.7046 - val_loss: 0.5769 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 250/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5978 - accuracy: 0.7075 - val_loss: 0.5769 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 251/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6003 - accuracy: 0.7010 - val_loss: 0.5768 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 252/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6016 - accuracy: 0.7017 - val_loss: 0.5768 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 253/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5973 - accuracy: 0.7068 - val_loss: 0.5768 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 254/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6015 - accuracy: 0.7046 - val_loss: 0.5768 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 255/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5992 - accuracy: 0.7061 - val_loss: 0.5767 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 256/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5993 - accuracy: 0.7032 - val_loss: 0.5767 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 257/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5981 - accuracy: 0.7111 - val_loss: 0.5767 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 258/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5978 - accuracy: 0.7068 - val_loss: 0.5767 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 259/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7032 - val_loss: 0.5766 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 260/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5969 - accuracy: 0.7053 - val_loss: 0.5766 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 261/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5995 - accuracy: 0.7046 - val_loss: 0.5766 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 262/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6025 - accuracy: 0.7046 - val_loss: 0.5766 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 263/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5985 - accuracy: 0.7046 - val_loss: 0.5765 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 264/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6010 - accuracy: 0.7053 - val_loss: 0.5765 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 265/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5995 - accuracy: 0.7075 - val_loss: 0.5765 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 266/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5990 - accuracy: 0.7046 - val_loss: 0.5764 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 267/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5980 - accuracy: 0.7046 - val_loss: 0.5764 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 268/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6002 - accuracy: 0.7089 - val_loss: 0.5764 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 269/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5991 - accuracy: 0.7046 - val_loss: 0.5764 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 270/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5969 - accuracy: 0.7061 - val_loss: 0.5764 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 271/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6000 - accuracy: 0.7053 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 272/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5972 - accuracy: 0.7032 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 273/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5991 - accuracy: 0.7046 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 274/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7024 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 275/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5971 - accuracy: 0.7061 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 276/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5978 - accuracy: 0.7039 - val_loss: 0.5763 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 277/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5988 - accuracy: 0.7017 - val_loss: 0.5762 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 278/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7046 - val_loss: 0.5762 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 279/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6009 - accuracy: 0.7061 - val_loss: 0.5762 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 280/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5990 - accuracy: 0.7061 - val_loss: 0.5762 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 281/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5973 - accuracy: 0.7024 - val_loss: 0.5762 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 282/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6008 - accuracy: 0.7024 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 283/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6005 - accuracy: 0.7061 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 284/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6000 - accuracy: 0.7061 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 285/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5983 - accuracy: 0.6996 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 286/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5995 - accuracy: 0.6996 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 287/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5998 - accuracy: 0.7039 - val_loss: 0.5761 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 288/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5988 - accuracy: 0.7053 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 289/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5953 - accuracy: 0.7068 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 290/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5996 - accuracy: 0.7075 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 291/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5968 - accuracy: 0.7061 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 292/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5980 - accuracy: 0.7089 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 293/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5998 - accuracy: 0.7003 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 294/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5979 - accuracy: 0.7068 - val_loss: 0.5760 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 295/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5990 - accuracy: 0.7061 - val_loss: 0.5759 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 296/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7039 - val_loss: 0.5759 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 297/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5994 - accuracy: 0.7017 - val_loss: 0.5759 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 298/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5996 - accuracy: 0.7024 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 299/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.7046 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 300/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5949 - accuracy: 0.7039 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 301/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5997 - accuracy: 0.7082 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 302/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7032 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 303/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5996 - accuracy: 0.7046 - val_loss: 0.5758 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 304/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5963 - accuracy: 0.7024 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 305/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7032 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 306/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5978 - accuracy: 0.7089 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 307/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5986 - accuracy: 0.7024 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 308/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7068 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 309/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5981 - accuracy: 0.7061 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 310/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7046 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 311/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5956 - accuracy: 0.7082 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 312/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5939 - accuracy: 0.7024 - val_loss: 0.5757 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 313/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7053 - val_loss: 0.5756 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 314/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5973 - accuracy: 0.7039 - val_loss: 0.5756 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 315/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5943 - accuracy: 0.7075 - val_loss: 0.5756 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 316/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5949 - accuracy: 0.7046 - val_loss: 0.5756 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 317/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5982 - accuracy: 0.7046 - val_loss: 0.5756 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 318/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5964 - accuracy: 0.7061 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 319/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5967 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 320/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5995 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 321/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5982 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 322/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5961 - accuracy: 0.7053 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 323/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5969 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 324/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5936 - accuracy: 0.7032 - val_loss: 0.5754 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 325/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5976 - accuracy: 0.7032 - val_loss: 0.5754 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 326/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5953 - accuracy: 0.7075 - val_loss: 0.5754 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 327/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7053 - val_loss: 0.5754 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 328/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7046 - val_loss: 0.5754 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 329/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5986 - accuracy: 0.7046 - val_loss: 0.5754 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 330/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7017 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 331/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5978 - accuracy: 0.7039 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 332/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5977 - accuracy: 0.7032 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 333/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5981 - accuracy: 0.7046 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 334/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5966 - accuracy: 0.7061 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 335/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5985 - accuracy: 0.7061 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 336/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5955 - accuracy: 0.7053 - val_loss: 0.5753 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 337/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7039 - val_loss: 0.5752 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 338/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5987 - accuracy: 0.7046 - val_loss: 0.5752 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 339/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5992 - accuracy: 0.7024 - val_loss: 0.5752 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 340/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6002 - accuracy: 0.7061 - val_loss: 0.5752 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 341/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7046 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 342/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5955 - accuracy: 0.7017 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 343/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5976 - accuracy: 0.7053 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 344/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5980 - accuracy: 0.7046 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 345/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5971 - accuracy: 0.7010 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 346/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7017 - val_loss: 0.5751 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 347/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5955 - accuracy: 0.7068 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 348/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5997 - accuracy: 0.7032 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 349/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5940 - accuracy: 0.7097 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 350/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7061 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 351/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5969 - accuracy: 0.7068 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 352/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7046 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 353/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7046 - val_loss: 0.5750 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 354/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7032 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 355/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.7075 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 356/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7024 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 357/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5948 - accuracy: 0.7075 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 358/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7039 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 359/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7053 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 360/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7039 - val_loss: 0.5749 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 361/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5997 - accuracy: 0.7039 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 362/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7053 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 363/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7039 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 364/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7075 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 365/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7061 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 366/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5937 - accuracy: 0.7053 - val_loss: 0.5748 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 367/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7024 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 368/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5972 - accuracy: 0.7046 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 369/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7053 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 370/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5991 - accuracy: 0.7061 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 371/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7017 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 372/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5986 - accuracy: 0.7046 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 373/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5948 - accuracy: 0.7068 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 374/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5982 - accuracy: 0.6988 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 375/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7010 - val_loss: 0.5747 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 376/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7032 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 377/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5967 - accuracy: 0.7024 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 378/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5981 - accuracy: 0.7024 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 379/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6010 - accuracy: 0.7061 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 380/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7032 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 381/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5971 - accuracy: 0.7032 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 382/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5976 - accuracy: 0.7046 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 383/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5957 - accuracy: 0.7046 - val_loss: 0.5746 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 384/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5959 - accuracy: 0.7061 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 385/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5950 - accuracy: 0.7061 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 386/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5960 - accuracy: 0.7053 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 387/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5955 - accuracy: 0.7039 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 388/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5960 - accuracy: 0.7039 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 389/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5957 - accuracy: 0.7017 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 390/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5963 - accuracy: 0.7061 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 391/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5944 - accuracy: 0.7039 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 392/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5952 - accuracy: 0.7061 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 393/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5966 - accuracy: 0.7039 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 394/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5956 - accuracy: 0.7053 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 395/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7075 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 396/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7053 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 397/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5960 - accuracy: 0.7075 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 398/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5988 - accuracy: 0.7010 - val_loss: 0.5745 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 399/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5966 - accuracy: 0.7039 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 400/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7089 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 401/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5978 - accuracy: 0.7039 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 402/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5948 - accuracy: 0.7032 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 403/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5966 - accuracy: 0.7024 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 404/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5945 - accuracy: 0.7032 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 405/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.6996 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 406/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5958 - accuracy: 0.7061 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 407/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5961 - accuracy: 0.7046 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 408/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5953 - accuracy: 0.7046 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 4.8828e-07\n",
            "Epoch 409/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5989 - accuracy: 0.7017 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 410/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5953 - accuracy: 0.7039 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 411/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5980 - accuracy: 0.7061 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 412/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5988 - accuracy: 0.7010 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 413/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7053 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 414/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5993 - accuracy: 0.7046 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 415/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5942 - accuracy: 0.7089 - val_loss: 0.5744 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 416/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5983 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 417/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5968 - accuracy: 0.7089 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 418/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5956 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 419/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5945 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 420/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 421/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 422/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5940 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 423/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 424/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5947 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 425/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5966 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 426/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5961 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.4414e-07\n",
            "Epoch 427/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5954 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 428/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5971 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 429/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 430/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 431/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5966 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 432/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5914 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 433/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 434/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5959 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 435/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 436/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.2207e-07\n",
            "Epoch 437/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 438/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5947 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 439/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 440/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 441/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5986 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 442/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5957 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 443/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5961 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 444/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 445/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5963 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 446/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 6.1035e-08\n",
            "Epoch 447/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5958 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 448/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 449/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5945 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 450/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 451/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5950 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 452/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 453/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5975 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 454/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5981 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 455/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5952 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 456/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5980 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.0518e-08\n",
            "Epoch 457/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5939 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 458/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5981 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 459/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5944 - accuracy: 0.6996 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 460/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 461/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5956 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 462/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5930 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 463/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 464/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 465/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5965 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 466/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5950 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.5259e-08\n",
            "Epoch 467/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5948 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 468/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 469/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5958 - accuracy: 0.7003 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 470/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5930 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 471/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5962 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 472/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5963 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 473/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 474/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5962 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 475/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5973 - accuracy: 0.7089 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 476/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5967 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.6294e-09\n",
            "Epoch 477/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 478/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5959 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 479/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5944 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 480/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 481/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5953 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 482/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 483/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5976 - accuracy: 0.7003 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 484/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 485/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 486/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5969 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.8147e-09\n",
            "Epoch 487/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5963 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 488/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5952 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 489/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 490/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5943 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 491/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5970 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 492/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5963 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 493/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 494/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5934 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 495/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 496/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5987 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.9073e-09\n",
            "Epoch 497/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5981 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 498/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 499/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 500/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5939 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 501/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5948 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 502/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 503/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5954 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 504/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 505/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5933 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 506/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7082 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 9.5367e-10\n",
            "Epoch 507/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5943 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 508/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5932 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 509/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5953 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 510/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5962 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 511/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 512/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5973 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 513/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5989 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 514/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 515/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5950 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 516/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5957 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 4.7684e-10\n",
            "Epoch 517/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5936 - accuracy: 0.7097 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 518/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5941 - accuracy: 0.7082 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 519/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5977 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 520/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 521/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 522/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6001 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 523/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5944 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 524/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6005 - accuracy: 0.6996 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 525/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5964 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 526/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5955 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.3842e-10\n",
            "Epoch 527/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 528/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5991 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 529/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5963 - accuracy: 0.7082 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 530/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5953 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 531/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5937 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 532/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5981 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 533/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5961 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 534/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5968 - accuracy: 0.7089 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 535/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5955 - accuracy: 0.7003 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 536/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5934 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.1921e-10\n",
            "Epoch 537/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5922 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 538/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 539/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5959 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 540/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 541/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5952 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 542/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5965 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 543/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5951 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 544/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5941 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 545/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 546/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5955 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 5.9605e-11\n",
            "Epoch 547/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5958 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 548/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 549/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 550/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5963 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 551/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5944 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 552/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 553/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 554/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5929 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 555/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5961 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 556/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 2.9802e-11\n",
            "Epoch 557/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5950 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 558/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5967 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 559/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 560/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 561/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 562/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5945 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 563/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 564/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5955 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 565/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5927 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 566/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7010 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.4901e-11\n",
            "Epoch 567/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5938 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 568/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 569/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 570/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 571/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5968 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 572/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 573/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 574/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5947 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 575/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5973 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 576/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5942 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 7.4506e-12\n",
            "Epoch 577/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5952 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 578/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 579/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 580/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5934 - accuracy: 0.7061 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 581/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5942 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 582/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7032 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 583/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5947 - accuracy: 0.7003 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 584/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5955 - accuracy: 0.6996 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 585/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5968 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 586/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5963 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 3.7253e-12\n",
            "Epoch 587/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5948 - accuracy: 0.7075 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 588/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 589/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5948 - accuracy: 0.7017 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 590/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 591/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7039 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 592/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7003 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 593/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7024 - val_loss: 0.5743 - val_accuracy: 0.7435 - lr: 1.8626e-12\n",
            "Epoch 593: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5923 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5919 - accuracy: 0.7127 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5925 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5950 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5943 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5938 - accuracy: 0.7149 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5924 - accuracy: 0.7048 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5940 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5946 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.8626e-12\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5907 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5938 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5936 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5944 - accuracy: 0.7048 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5937 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7055 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5919 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 9.3132e-13\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5955 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5968 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5955 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5925 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5943 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5887 - accuracy: 0.7142 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5912 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5937 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 4.6566e-13\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5934 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5919 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5933 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5973 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5947 - accuracy: 0.7069 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7055 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5918 - accuracy: 0.7135 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5909 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5952 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7069 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.3283e-13\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5912 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5945 - accuracy: 0.7055 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5922 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5941 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5940 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5947 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5937 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5961 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.1642e-13\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5940 - accuracy: 0.7127 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5926 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5942 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5927 - accuracy: 0.7127 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5943 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5918 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5948 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5950 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5938 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 5.8208e-14\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5916 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5937 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5948 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5951 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5942 - accuracy: 0.7069 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5953 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5924 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5949 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 2.9104e-14\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5913 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5941 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5931 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5939 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5942 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5965 - accuracy: 0.7069 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5940 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5951 - accuracy: 0.7055 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 1.4552e-14\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5929 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5937 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5938 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5931 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5948 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5944 - accuracy: 0.7120 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5940 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5920 - accuracy: 0.7106 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5929 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 7.2760e-15\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5946 - accuracy: 0.7113 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5953 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5954 - accuracy: 0.7084 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5951 - accuracy: 0.7135 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5980 - accuracy: 0.7048 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5945 - accuracy: 0.7062 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5936 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5900 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5929 - accuracy: 0.7077 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5929 - accuracy: 0.7091 - val_loss: 0.5804 - val_accuracy: 0.7341 - lr: 3.6380e-15\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6613 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6573 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6601 - accuracy: 0.6636 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6550 - accuracy: 0.6578 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6581 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6571 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.6570 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6592 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6558 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6575 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6575 - accuracy: 0.6644 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.8190e-15\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6550 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6560 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6597 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6578 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6609 - accuracy: 0.6578 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6573 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6570 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6599 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6573 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.6636 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 9.0949e-16\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6590 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6594 - accuracy: 0.6644 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6621 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6566 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6567 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6590 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6588 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6604 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6601 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6579 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 4.5475e-16\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6558 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6570 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6562 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6589 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6587 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6556 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6599 - accuracy: 0.6644 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6571 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6565 - accuracy: 0.6644 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6607 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.2737e-16\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6588 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6564 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6582 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6562 - accuracy: 0.6578 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6590 - accuracy: 0.6570 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6613 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6605 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6556 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6606 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6613 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.1369e-16\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.6636 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6589 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6550 - accuracy: 0.6653 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6603 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6607 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6583 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6587 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6565 - accuracy: 0.6653 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6601 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 5.6843e-17\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6585 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6582 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6571 - accuracy: 0.6578 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6594 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6569 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6577 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6576 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6581 - accuracy: 0.6636 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6632 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6607 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 2.8422e-17\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6598 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6626 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6592 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6554 - accuracy: 0.6570 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6554 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.6644 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6623 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6584 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6585 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6589 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 1.4211e-17\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6602 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6574 - accuracy: 0.6603 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6606 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6548 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6603 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6611 - accuracy: 0.6653 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6607 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6594 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6583 - accuracy: 0.6611 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6608 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 7.1054e-18\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6578 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6555 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6589 - accuracy: 0.6628 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6600 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6580 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6588 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6582 - accuracy: 0.6595 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6614 - accuracy: 0.6653 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 20ms/step - loss: 0.6549 - accuracy: 0.6586 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6586 - accuracy: 0.6619 - val_loss: 0.5943 - val_accuracy: 0.7375 - lr: 3.5527e-18\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7034 - accuracy: 0.6117 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7011 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7060 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7026 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7031 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7009 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7068 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7044 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7027 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.6015 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.7764e-18\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7052 - accuracy: 0.6139 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7044 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7040 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7036 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7072 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7036 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7033 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 19ms/step - loss: 0.7029 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7059 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7049 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 8.8818e-19\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7018 - accuracy: 0.6109 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7028 - accuracy: 0.6095 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7041 - accuracy: 0.6095 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7047 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7024 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7049 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7066 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7037 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7020 - accuracy: 0.6095 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 4.4409e-19\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7034 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.6117 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7038 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7059 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7005 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7018 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7044 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7038 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7037 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7058 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.2204e-19\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7041 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7007 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7047 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7063 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7010 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7042 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7041 - accuracy: 0.6131 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7024 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7024 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7043 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.1102e-19\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7034 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7041 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7017 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7067 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7042 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7016 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7033 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7043 - accuracy: 0.6095 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7060 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7057 - accuracy: 0.6015 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 5.5511e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7058 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7054 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7107 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7024 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7003 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7057 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7019 - accuracy: 0.6095 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7027 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7059 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7020 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 2.7756e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7063 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7061 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7028 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7037 - accuracy: 0.6124 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7085 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7051 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7035 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7060 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7068 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7057 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.3878e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7027 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7034 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7053 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7047 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7047 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7068 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7081 - accuracy: 0.6080 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7049 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7051 - accuracy: 0.6058 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7045 - accuracy: 0.6102 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7025 - accuracy: 0.6051 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7049 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7038 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7035 - accuracy: 0.6109 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7023 - accuracy: 0.6088 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7037 - accuracy: 0.6044 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7065 - accuracy: 0.6066 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7039 - accuracy: 0.6073 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.7077 - accuracy: 0.6036 - val_loss: 0.6738 - val_accuracy: 0.6297 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7193 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7174 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7177 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7168 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7127 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7144 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7156 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7210 - accuracy: 0.5839 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7169 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7136 - accuracy: 0.5847 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7150 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7184 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7147 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7164 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7153 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7155 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7144 - accuracy: 0.5839 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7163 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7163 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7162 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7169 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7155 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7125 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7152 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7139 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7145 - accuracy: 0.5774 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7153 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7182 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7149 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7155 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7136 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7150 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7170 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7147 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7159 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7149 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7156 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7143 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7174 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7137 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7165 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7189 - accuracy: 0.5774 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7142 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7163 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7162 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7165 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7169 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7164 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7161 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7170 - accuracy: 0.5745 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7140 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7183 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7173 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7159 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7187 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7164 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7162 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7146 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7194 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7154 - accuracy: 0.5847 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7154 - accuracy: 0.5839 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7206 - accuracy: 0.5760 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7160 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7148 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7137 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7164 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7171 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7128 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7153 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7163 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7150 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7166 - accuracy: 0.5832 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7147 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7135 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7159 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7134 - accuracy: 0.5839 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7134 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7160 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7136 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7188 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7191 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7144 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7160 - accuracy: 0.5767 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7136 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7163 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7170 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7151 - accuracy: 0.5839 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7126 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7112 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7170 - accuracy: 0.5847 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7147 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7162 - accuracy: 0.5818 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7147 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7155 - accuracy: 0.5789 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7152 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7154 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7152 - accuracy: 0.5781 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7162 - accuracy: 0.5810 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.7180 - accuracy: 0.5796 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7130 - accuracy: 0.5803 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7140 - accuracy: 0.5825 - val_loss: 0.7213 - val_accuracy: 0.6069 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7327 - accuracy: 0.5640 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7275 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7290 - accuracy: 0.5640 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7311 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7320 - accuracy: 0.5533 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7333 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7259 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7270 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7324 - accuracy: 0.5640 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7286 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7317 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7330 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7327 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7268 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7311 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7258 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7270 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7306 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7304 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7282 - accuracy: 0.5632 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7316 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7304 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7276 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7297 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7285 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7309 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7297 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7299 - accuracy: 0.5656 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7266 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7319 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7283 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7261 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7304 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7309 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7323 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7315 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7284 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7298 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7278 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7305 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7304 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7291 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7352 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7309 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7307 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7313 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7276 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7294 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7307 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7310 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7278 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7322 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7300 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7264 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7295 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7321 - accuracy: 0.5632 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7300 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7296 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7303 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7292 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7326 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7340 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7332 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7334 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7297 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7321 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7295 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7322 - accuracy: 0.5533 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7306 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7287 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7314 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7317 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7320 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7291 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7293 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7292 - accuracy: 0.5648 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7302 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7302 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7268 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7273 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7313 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7324 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7308 - accuracy: 0.5541 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7311 - accuracy: 0.5566 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7297 - accuracy: 0.5582 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7291 - accuracy: 0.5607 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7276 - accuracy: 0.5632 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7289 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7294 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7305 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7304 - accuracy: 0.5590 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7270 - accuracy: 0.5549 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7268 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7325 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7282 - accuracy: 0.5574 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7303 - accuracy: 0.5632 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7314 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7284 - accuracy: 0.5615 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7292 - accuracy: 0.5557 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7297 - accuracy: 0.5599 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7265 - accuracy: 0.5623 - val_loss: 0.7512 - val_accuracy: 0.5578 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7929 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7910 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7932 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7873 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7930 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7915 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7912 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7908 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7915 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7888 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7933 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7912 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7928 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7943 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7944 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7892 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7910 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7943 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7951 - accuracy: 0.5197 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7869 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7935 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7944 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7897 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7924 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7908 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7895 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7881 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7936 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7915 - accuracy: 0.5197 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7895 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7927 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7907 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7893 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7906 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7904 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7938 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7908 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7888 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7917 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7946 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7906 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7907 - accuracy: 0.5197 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7879 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7899 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7978 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7922 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7919 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7932 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7930 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7908 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7881 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7919 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7898 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7894 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7904 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7891 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7934 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7904 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7880 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7898 - accuracy: 0.5124 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7913 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7915 - accuracy: 0.5109 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7886 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7910 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7896 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7922 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7922 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7915 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7879 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7875 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7875 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7887 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7911 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7921 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7941 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7929 - accuracy: 0.5190 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7897 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7945 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7921 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7916 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7916 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7892 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7932 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7920 - accuracy: 0.5109 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7919 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7917 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7916 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7930 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7977 - accuracy: 0.5204 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7901 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7946 - accuracy: 0.5146 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7926 - accuracy: 0.5161 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7942 - accuracy: 0.5182 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7901 - accuracy: 0.5153 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7876 - accuracy: 0.5139 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7914 - accuracy: 0.5175 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7908 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7934 - accuracy: 0.5212 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7894 - accuracy: 0.5212 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7880 - accuracy: 0.5131 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7875 - accuracy: 0.5168 - val_loss: 0.8135 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7043 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7026 - accuracy: 0.5865 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7020 - accuracy: 0.5915 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7032 - accuracy: 0.5872 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7050 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7098 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7057 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7038 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7076 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7036 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7030 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7032 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7079 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7075 - accuracy: 0.5857 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7082 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7030 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7041 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7014 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7031 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7045 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7044 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7045 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7035 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7037 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7067 - accuracy: 0.5850 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7043 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7051 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7067 - accuracy: 0.5865 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7059 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7021 - accuracy: 0.5865 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7038 - accuracy: 0.5857 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7056 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7053 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7068 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7040 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7048 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7038 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7047 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7044 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7047 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7040 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7063 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7033 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7058 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7003 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7039 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7067 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7011 - accuracy: 0.5915 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7033 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7052 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7042 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7030 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7071 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7041 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7055 - accuracy: 0.5958 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7029 - accuracy: 0.5929 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7041 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7043 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7037 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7003 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7066 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7058 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7052 - accuracy: 0.5929 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7029 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7049 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7038 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7014 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7030 - accuracy: 0.5915 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7062 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7057 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7060 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7040 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7039 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7064 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7045 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7043 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7048 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7054 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7010 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7066 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7026 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7034 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7036 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7047 - accuracy: 0.5872 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7058 - accuracy: 0.5893 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7037 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7036 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7055 - accuracy: 0.5886 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7046 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7043 - accuracy: 0.5879 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5915 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7032 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5901 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7048 - accuracy: 0.5908 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7058 - accuracy: 0.5937 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7036 - accuracy: 0.5922 - val_loss: 0.7249 - val_accuracy: 0.5994 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7516 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7545 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7555 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7528 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7520 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7550 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7521 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7551 - accuracy: 0.5545 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7521 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7543 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7529 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7496 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7555 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7519 - accuracy: 0.5637 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7549 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7537 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7540 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7516 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7543 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7550 - accuracy: 0.5645 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7506 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7544 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7506 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7518 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7531 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7526 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7528 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7528 - accuracy: 0.5637 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7558 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7542 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7538 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7520 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7565 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7520 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7545 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7554 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7531 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7538 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7522 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7523 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7555 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7534 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7533 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7494 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7541 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7564 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7530 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7495 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7567 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7523 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7560 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7533 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7514 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7548 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7554 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7559 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7522 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7527 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7518 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7581 - accuracy: 0.5654 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7554 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7539 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7501 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7531 - accuracy: 0.5562 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7476 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7542 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7547 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7506 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7526 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7521 - accuracy: 0.5637 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7529 - accuracy: 0.5595 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7554 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7557 - accuracy: 0.5637 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7530 - accuracy: 0.5554 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7550 - accuracy: 0.5562 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7510 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7554 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7567 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7569 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7516 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7519 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7549 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7524 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7527 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7524 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7535 - accuracy: 0.5570 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7518 - accuracy: 0.5620 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7532 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7552 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7544 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7505 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7512 - accuracy: 0.5629 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7495 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7521 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7523 - accuracy: 0.5612 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7539 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7555 - accuracy: 0.5604 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7532 - accuracy: 0.5637 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7541 - accuracy: 0.5579 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7546 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7557 - accuracy: 0.5587 - val_loss: 0.7467 - val_accuracy: 0.5781 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4740 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4751 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4749 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4750 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4766 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4779 - accuracy: 0.8408 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4770 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4749 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4773 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4763 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4769 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4783 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4791 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.4775 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4777 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4792 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4805 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.4779 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.4752 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4751 - accuracy: 0.8415 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4756 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4782 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4783 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8336 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4785 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4788 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4759 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4771 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4766 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4779 - accuracy: 0.8401 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4776 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4779 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4752 - accuracy: 0.8394 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4781 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4787 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4754 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4749 - accuracy: 0.8329 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4803 - accuracy: 0.8401 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4768 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4784 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4774 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4774 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4757 - accuracy: 0.8394 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.4754 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4742 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4791 - accuracy: 0.8321 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4781 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4780 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4780 - accuracy: 0.8329 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4787 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4769 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4769 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4772 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4771 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4790 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4794 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4763 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4789 - accuracy: 0.8336 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4775 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4773 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4792 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4789 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4786 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4764 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4788 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4785 - accuracy: 0.8386 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4757 - accuracy: 0.8408 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4774 - accuracy: 0.8401 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4791 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4772 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4762 - accuracy: 0.8401 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4754 - accuracy: 0.8329 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4780 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4764 - accuracy: 0.8415 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4756 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4758 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4766 - accuracy: 0.8394 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4780 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4798 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4769 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4759 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4789 - accuracy: 0.8321 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4761 - accuracy: 0.8408 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4753 - accuracy: 0.8336 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4788 - accuracy: 0.8321 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4780 - accuracy: 0.8329 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4770 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4783 - accuracy: 0.8408 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4770 - accuracy: 0.8394 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4777 - accuracy: 0.8343 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4777 - accuracy: 0.8357 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4769 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4792 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4771 - accuracy: 0.8394 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4781 - accuracy: 0.8372 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4791 - accuracy: 0.8350 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4750 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4766 - accuracy: 0.8329 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4774 - accuracy: 0.8379 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4754 - accuracy: 0.8365 - val_loss: 0.3988 - val_accuracy: 0.9104 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5392 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5346 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5363 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5375 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5386 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5355 - accuracy: 0.7671 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5370 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5367 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5351 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5368 - accuracy: 0.7605 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5372 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5361 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5365 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5343 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5357 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5367 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5371 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5370 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5349 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5392 - accuracy: 0.7605 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5352 - accuracy: 0.7605 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5394 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5332 - accuracy: 0.7671 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5363 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5398 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5365 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5391 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5357 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5386 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5371 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5351 - accuracy: 0.7589 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5369 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5359 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5364 - accuracy: 0.7696 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5354 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5351 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5379 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5397 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5374 - accuracy: 0.7688 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5382 - accuracy: 0.7688 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5392 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5358 - accuracy: 0.7671 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5368 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5321 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5392 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5368 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5372 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5387 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5366 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5351 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5375 - accuracy: 0.7581 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5360 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5395 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5390 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5354 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5375 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5370 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5361 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5358 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5359 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5369 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5379 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5335 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5384 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5373 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5381 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5359 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5378 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5372 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5379 - accuracy: 0.7696 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5389 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5389 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5358 - accuracy: 0.7605 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5375 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5372 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5360 - accuracy: 0.7630 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5347 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5409 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5350 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5361 - accuracy: 0.7671 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5372 - accuracy: 0.7663 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5370 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5368 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5371 - accuracy: 0.7680 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5359 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5349 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5370 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5381 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5373 - accuracy: 0.7597 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5394 - accuracy: 0.7655 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5357 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5413 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5375 - accuracy: 0.7638 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5382 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5352 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5360 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5343 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5339 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5364 - accuracy: 0.7564 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5374 - accuracy: 0.7614 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5372 - accuracy: 0.7622 - val_loss: 0.4501 - val_accuracy: 0.8812 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4761 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4726 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4737 - accuracy: 0.8386 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4748 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4712 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4742 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4734 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4732 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4729 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4703 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4746 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.4710 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.4701 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4728 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4719 - accuracy: 0.8372 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4742 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4718 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4744 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4721 - accuracy: 0.8372 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4713 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4745 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4706 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4733 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4727 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4717 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4735 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4736 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4721 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4728 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4729 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4728 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4734 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4735 - accuracy: 0.8365 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4725 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4725 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4741 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4722 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4713 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4711 - accuracy: 0.8386 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4738 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4733 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4724 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4707 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4735 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4684 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4711 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4756 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4750 - accuracy: 0.8386 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4706 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4766 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4709 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4708 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4731 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4722 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4712 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4756 - accuracy: 0.8372 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4748 - accuracy: 0.8357 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4739 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4712 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4744 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4735 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4742 - accuracy: 0.8444 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4755 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4710 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4705 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4733 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4738 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8437 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4708 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4751 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4761 - accuracy: 0.8372 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4694 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4736 - accuracy: 0.8437 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4741 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4717 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4745 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4749 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4732 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4724 - accuracy: 0.8365 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4723 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4720 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4730 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4732 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4723 - accuracy: 0.8408 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4726 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4731 - accuracy: 0.8393 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4710 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4734 - accuracy: 0.8401 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4751 - accuracy: 0.8386 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4744 - accuracy: 0.8379 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4716 - accuracy: 0.8422 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4714 - accuracy: 0.8415 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4736 - accuracy: 0.8386 - val_loss: 0.3721 - val_accuracy: 0.9395 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5302 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5306 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5340 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5295 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5327 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5312 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5324 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5321 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5324 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5309 - accuracy: 0.7960 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5305 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5332 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5312 - accuracy: 0.7952 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5286 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5328 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5316 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5334 - accuracy: 0.7868 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5313 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5335 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5321 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5322 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5329 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5308 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5318 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5332 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5307 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5313 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5326 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5310 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5347 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5331 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5311 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5310 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5349 - accuracy: 0.7877 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5338 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5298 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5335 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5329 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5325 - accuracy: 0.7877 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5317 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5326 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5320 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5323 - accuracy: 0.7885 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5347 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5333 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5336 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5330 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5354 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5331 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5336 - accuracy: 0.7877 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5321 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5324 - accuracy: 0.7843 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5331 - accuracy: 0.7868 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5365 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5297 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5325 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5350 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5305 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5308 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5340 - accuracy: 0.7877 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5321 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5309 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5336 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5293 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5333 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5338 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5305 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5318 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5331 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5327 - accuracy: 0.7985 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5344 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5330 - accuracy: 0.7852 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5362 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5325 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5358 - accuracy: 0.7868 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5347 - accuracy: 0.7952 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5316 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5325 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5306 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5308 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5300 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5302 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5294 - accuracy: 0.7910 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5319 - accuracy: 0.7860 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5330 - accuracy: 0.7935 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5316 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.5309 - accuracy: 0.7902 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5347 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5323 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5357 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5329 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5339 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5308 - accuracy: 0.7927 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7893 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5344 - accuracy: 0.7918 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5337 - accuracy: 0.7943 - val_loss: 0.4683 - val_accuracy: 0.8638 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5566 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5582 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5582 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5548 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5553 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5563 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5566 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5572 - accuracy: 0.7591 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5580 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5551 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5589 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5613 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5568 - accuracy: 0.7606 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5544 - accuracy: 0.7693 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5594 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5568 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5595 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5535 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5572 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5555 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5548 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5572 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5562 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5570 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5579 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5539 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5538 - accuracy: 0.7693 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5550 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5567 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5557 - accuracy: 0.7686 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5571 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5581 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5559 - accuracy: 0.7606 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5540 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5548 - accuracy: 0.7686 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5566 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5563 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5580 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5566 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5551 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5563 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5555 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5615 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5579 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5587 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5554 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5558 - accuracy: 0.7686 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5562 - accuracy: 0.7693 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5542 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5564 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5563 - accuracy: 0.7686 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5557 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5573 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5544 - accuracy: 0.7715 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 26ms/step - loss: 0.5553 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5571 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5549 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5552 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5556 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5526 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5583 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5572 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5570 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5539 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5559 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5579 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5573 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5554 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5559 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5558 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5555 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5594 - accuracy: 0.7584 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5599 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5571 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5580 - accuracy: 0.7606 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5559 - accuracy: 0.7606 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5581 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5543 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5545 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5581 - accuracy: 0.7620 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5576 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5584 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5580 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5533 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5542 - accuracy: 0.7679 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5568 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5580 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5580 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5561 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5557 - accuracy: 0.7686 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7635 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7664 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5588 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5571 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5579 - accuracy: 0.7657 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5553 - accuracy: 0.7650 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5554 - accuracy: 0.7642 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 26ms/step - loss: 0.5570 - accuracy: 0.7672 - val_loss: 0.4884 - val_accuracy: 0.8222 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n"
          ]
        }
      ],
      "source": [
        "#For GRU\n",
        "models_gru = []\n",
        "histories_gru = []\n",
        "for i in range(len(datasets)):\n",
        "  history_gru = fit_model(model_gru,X_train_all[i],y_train_all[i]) #Call back that records events into history object\n",
        "  models_gru.append(model_gru)\n",
        "  histories_gru.append(history_gru)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPzTsOI2JGvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81292664-3d5b-4df9-a7b7-7418da72237c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 6s 29ms/step - loss: 0.6595 - accuracy: 0.6433 - val_loss: 0.5876 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6545 - accuracy: 0.6433 - val_loss: 0.5902 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6538 - accuracy: 0.6433 - val_loss: 0.5963 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6511 - accuracy: 0.6433 - val_loss: 0.5958 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6505 - accuracy: 0.6433 - val_loss: 0.5938 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6504 - accuracy: 0.6457 - val_loss: 0.5978 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6495 - accuracy: 0.6433 - val_loss: 0.5962 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6489 - accuracy: 0.6424 - val_loss: 0.5967 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6488 - accuracy: 0.6457 - val_loss: 0.6006 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6473 - accuracy: 0.6416 - val_loss: 0.5966 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6460 - accuracy: 0.6466 - val_loss: 0.5983 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6428 - accuracy: 0.6482 - val_loss: 0.6067 - val_accuracy: 0.7195 - lr: 5.0000e-04\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6427 - accuracy: 0.6524 - val_loss: 0.6087 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6442 - accuracy: 0.6515 - val_loss: 0.6046 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6444 - accuracy: 0.6449 - val_loss: 0.6094 - val_accuracy: 0.7195 - lr: 5.0000e-04\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6422 - accuracy: 0.6457 - val_loss: 0.6033 - val_accuracy: 0.7195 - lr: 5.0000e-04\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6416 - accuracy: 0.6499 - val_loss: 0.6097 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6423 - accuracy: 0.6441 - val_loss: 0.6034 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6410 - accuracy: 0.6474 - val_loss: 0.6071 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6418 - accuracy: 0.6449 - val_loss: 0.6131 - val_accuracy: 0.6997 - lr: 5.0000e-04\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6419 - accuracy: 0.6466 - val_loss: 0.6120 - val_accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6391 - accuracy: 0.6466 - val_loss: 0.6096 - val_accuracy: 0.7063 - lr: 2.5000e-04\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.6380 - accuracy: 0.6548 - val_loss: 0.6152 - val_accuracy: 0.6931 - lr: 2.5000e-04\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6353 - accuracy: 0.6540 - val_loss: 0.6134 - val_accuracy: 0.6997 - lr: 2.5000e-04\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6370 - accuracy: 0.6540 - val_loss: 0.6141 - val_accuracy: 0.6898 - lr: 2.5000e-04\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6359 - accuracy: 0.6515 - val_loss: 0.6155 - val_accuracy: 0.6898 - lr: 2.5000e-04\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6372 - accuracy: 0.6524 - val_loss: 0.6177 - val_accuracy: 0.6799 - lr: 2.5000e-04\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6361 - accuracy: 0.6548 - val_loss: 0.6184 - val_accuracy: 0.6799 - lr: 2.5000e-04\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6362 - accuracy: 0.6532 - val_loss: 0.6208 - val_accuracy: 0.6733 - lr: 2.5000e-04\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6370 - accuracy: 0.6548 - val_loss: 0.6184 - val_accuracy: 0.6766 - lr: 2.5000e-04\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6352 - accuracy: 0.6557 - val_loss: 0.6185 - val_accuracy: 0.6799 - lr: 2.5000e-04\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6332 - accuracy: 0.6532 - val_loss: 0.6157 - val_accuracy: 0.6832 - lr: 1.2500e-04\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6356 - accuracy: 0.6548 - val_loss: 0.6155 - val_accuracy: 0.6832 - lr: 1.2500e-04\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6345 - accuracy: 0.6532 - val_loss: 0.6176 - val_accuracy: 0.6799 - lr: 1.2500e-04\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6305 - accuracy: 0.6598 - val_loss: 0.6203 - val_accuracy: 0.6799 - lr: 1.2500e-04\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6345 - accuracy: 0.6557 - val_loss: 0.6206 - val_accuracy: 0.6799 - lr: 1.2500e-04\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6302 - accuracy: 0.6540 - val_loss: 0.6223 - val_accuracy: 0.6799 - lr: 1.2500e-04\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6303 - accuracy: 0.6524 - val_loss: 0.6230 - val_accuracy: 0.6766 - lr: 1.2500e-04\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6348 - accuracy: 0.6441 - val_loss: 0.6197 - val_accuracy: 0.6865 - lr: 1.2500e-04\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6340 - accuracy: 0.6548 - val_loss: 0.6195 - val_accuracy: 0.6832 - lr: 1.2500e-04\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6324 - accuracy: 0.6573 - val_loss: 0.6220 - val_accuracy: 0.6832 - lr: 1.2500e-04\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6333 - accuracy: 0.6532 - val_loss: 0.6204 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6320 - accuracy: 0.6581 - val_loss: 0.6218 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6326 - accuracy: 0.6507 - val_loss: 0.6211 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6288 - accuracy: 0.6565 - val_loss: 0.6228 - val_accuracy: 0.6865 - lr: 6.2500e-05\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6297 - accuracy: 0.6590 - val_loss: 0.6228 - val_accuracy: 0.6865 - lr: 6.2500e-05\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6300 - accuracy: 0.6540 - val_loss: 0.6234 - val_accuracy: 0.6865 - lr: 6.2500e-05\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6291 - accuracy: 0.6581 - val_loss: 0.6241 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6283 - accuracy: 0.6557 - val_loss: 0.6264 - val_accuracy: 0.6799 - lr: 6.2500e-05\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6306 - accuracy: 0.6507 - val_loss: 0.6244 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6272 - accuracy: 0.6590 - val_loss: 0.6259 - val_accuracy: 0.6832 - lr: 6.2500e-05\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6252 - accuracy: 0.6532 - val_loss: 0.6267 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6268 - accuracy: 0.6614 - val_loss: 0.6273 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6279 - accuracy: 0.6614 - val_loss: 0.6274 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6292 - accuracy: 0.6680 - val_loss: 0.6264 - val_accuracy: 0.6865 - lr: 3.1250e-05\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6296 - accuracy: 0.6499 - val_loss: 0.6263 - val_accuracy: 0.6865 - lr: 3.1250e-05\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6262 - accuracy: 0.6614 - val_loss: 0.6272 - val_accuracy: 0.6865 - lr: 3.1250e-05\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6273 - accuracy: 0.6565 - val_loss: 0.6277 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 19ms/step - loss: 0.6274 - accuracy: 0.6548 - val_loss: 0.6276 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6270 - accuracy: 0.6590 - val_loss: 0.6287 - val_accuracy: 0.6832 - lr: 3.1250e-05\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6247 - accuracy: 0.6614 - val_loss: 0.6291 - val_accuracy: 0.6799 - lr: 3.1250e-05\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6274 - accuracy: 0.6581 - val_loss: 0.6286 - val_accuracy: 0.6865 - lr: 1.5625e-05\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6261 - accuracy: 0.6557 - val_loss: 0.6286 - val_accuracy: 0.6832 - lr: 1.5625e-05\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6283 - accuracy: 0.6581 - val_loss: 0.6281 - val_accuracy: 0.6832 - lr: 1.5625e-05\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6268 - accuracy: 0.6598 - val_loss: 0.6285 - val_accuracy: 0.6865 - lr: 1.5625e-05\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6284 - accuracy: 0.6647 - val_loss: 0.6282 - val_accuracy: 0.6832 - lr: 1.5625e-05\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6258 - accuracy: 0.6573 - val_loss: 0.6284 - val_accuracy: 0.6865 - lr: 1.5625e-05\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6274 - accuracy: 0.6590 - val_loss: 0.6284 - val_accuracy: 0.6832 - lr: 1.5625e-05\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6262 - accuracy: 0.6548 - val_loss: 0.6286 - val_accuracy: 0.6865 - lr: 1.5625e-05\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6270 - accuracy: 0.6548 - val_loss: 0.6288 - val_accuracy: 0.6865 - lr: 1.5625e-05\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6284 - accuracy: 0.6614 - val_loss: 0.6286 - val_accuracy: 0.6898 - lr: 1.5625e-05\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6275 - accuracy: 0.6639 - val_loss: 0.6286 - val_accuracy: 0.6898 - lr: 7.8125e-06\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6305 - accuracy: 0.6557 - val_loss: 0.6282 - val_accuracy: 0.6865 - lr: 7.8125e-06\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6272 - accuracy: 0.6524 - val_loss: 0.6278 - val_accuracy: 0.6865 - lr: 7.8125e-06\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6262 - accuracy: 0.6565 - val_loss: 0.6279 - val_accuracy: 0.6865 - lr: 7.8125e-06\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6272 - accuracy: 0.6532 - val_loss: 0.6281 - val_accuracy: 0.6865 - lr: 7.8125e-06\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6247 - accuracy: 0.6573 - val_loss: 0.6283 - val_accuracy: 0.6865 - lr: 7.8125e-06\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6264 - accuracy: 0.6614 - val_loss: 0.6282 - val_accuracy: 0.6898 - lr: 7.8125e-06\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6276 - accuracy: 0.6614 - val_loss: 0.6284 - val_accuracy: 0.6898 - lr: 7.8125e-06\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6258 - accuracy: 0.6598 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 7.8125e-06\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6242 - accuracy: 0.6540 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 7.8125e-06\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6257 - accuracy: 0.6548 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6270 - accuracy: 0.6606 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6270 - accuracy: 0.6639 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6248 - accuracy: 0.6664 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6254 - accuracy: 0.6623 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6259 - accuracy: 0.6581 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6273 - accuracy: 0.6581 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6228 - accuracy: 0.6598 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6278 - accuracy: 0.6598 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6263 - accuracy: 0.6573 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 3.9063e-06\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6268 - accuracy: 0.6540 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6257 - accuracy: 0.6581 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6259 - accuracy: 0.6573 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6274 - accuracy: 0.6647 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6253 - accuracy: 0.6656 - val_loss: 0.6288 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6259 - accuracy: 0.6598 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6272 - accuracy: 0.6581 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6248 - accuracy: 0.6606 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 17ms/step - loss: 0.6262 - accuracy: 0.6590 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 18ms/step - loss: 0.6265 - accuracy: 0.6573 - val_loss: 0.6289 - val_accuracy: 0.6898 - lr: 1.9531e-06\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6146 - accuracy: 0.6952 - val_loss: 0.5980 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6116 - accuracy: 0.6888 - val_loss: 0.5974 - val_accuracy: 0.7291 - lr: 9.7656e-07\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6101 - accuracy: 0.7082 - val_loss: 0.5968 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6104 - accuracy: 0.6974 - val_loss: 0.5963 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6108 - accuracy: 0.6988 - val_loss: 0.5958 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6123 - accuracy: 0.6909 - val_loss: 0.5952 - val_accuracy: 0.7320 - lr: 9.7656e-07\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6098 - accuracy: 0.6938 - val_loss: 0.5947 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6108 - accuracy: 0.6960 - val_loss: 0.5943 - val_accuracy: 0.7349 - lr: 9.7656e-07\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6105 - accuracy: 0.6924 - val_loss: 0.5938 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6096 - accuracy: 0.6967 - val_loss: 0.5934 - val_accuracy: 0.7378 - lr: 9.7656e-07\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6083 - accuracy: 0.6938 - val_loss: 0.5929 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6109 - accuracy: 0.6974 - val_loss: 0.5925 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6080 - accuracy: 0.6960 - val_loss: 0.5921 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6075 - accuracy: 0.6967 - val_loss: 0.5917 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6064 - accuracy: 0.7017 - val_loss: 0.5914 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6070 - accuracy: 0.7046 - val_loss: 0.5910 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6082 - accuracy: 0.6988 - val_loss: 0.5907 - val_accuracy: 0.7406 - lr: 9.7656e-07\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6080 - accuracy: 0.7010 - val_loss: 0.5903 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6086 - accuracy: 0.6974 - val_loss: 0.5900 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6066 - accuracy: 0.7039 - val_loss: 0.5896 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6092 - accuracy: 0.6945 - val_loss: 0.5893 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6062 - accuracy: 0.7003 - val_loss: 0.5890 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6060 - accuracy: 0.6974 - val_loss: 0.5887 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6044 - accuracy: 0.7039 - val_loss: 0.5884 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6056 - accuracy: 0.6967 - val_loss: 0.5881 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6048 - accuracy: 0.6981 - val_loss: 0.5878 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6046 - accuracy: 0.7017 - val_loss: 0.5876 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6044 - accuracy: 0.7046 - val_loss: 0.5873 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6056 - accuracy: 0.7017 - val_loss: 0.5870 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6042 - accuracy: 0.7032 - val_loss: 0.5868 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6039 - accuracy: 0.6988 - val_loss: 0.5865 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6032 - accuracy: 0.7046 - val_loss: 0.5863 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6056 - accuracy: 0.7046 - val_loss: 0.5861 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6038 - accuracy: 0.7003 - val_loss: 0.5858 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6035 - accuracy: 0.7032 - val_loss: 0.5856 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6034 - accuracy: 0.7061 - val_loss: 0.5854 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.6036 - accuracy: 0.7032 - val_loss: 0.5852 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6033 - accuracy: 0.7082 - val_loss: 0.5850 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6049 - accuracy: 0.7024 - val_loss: 0.5848 - val_accuracy: 0.7435 - lr: 9.7656e-07\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6038 - accuracy: 0.7053 - val_loss: 0.5846 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6020 - accuracy: 0.7075 - val_loss: 0.5845 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6035 - accuracy: 0.7061 - val_loss: 0.5843 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6027 - accuracy: 0.7039 - val_loss: 0.5841 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6052 - accuracy: 0.7003 - val_loss: 0.5839 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6022 - accuracy: 0.7010 - val_loss: 0.5837 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6040 - accuracy: 0.7032 - val_loss: 0.5836 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6018 - accuracy: 0.7046 - val_loss: 0.5834 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6037 - accuracy: 0.7010 - val_loss: 0.5832 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6020 - accuracy: 0.7039 - val_loss: 0.5831 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6004 - accuracy: 0.7039 - val_loss: 0.5829 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6027 - accuracy: 0.7075 - val_loss: 0.5827 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6010 - accuracy: 0.7032 - val_loss: 0.5826 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6026 - accuracy: 0.7032 - val_loss: 0.5824 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6030 - accuracy: 0.7053 - val_loss: 0.5823 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6031 - accuracy: 0.7082 - val_loss: 0.5822 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6031 - accuracy: 0.7075 - val_loss: 0.5820 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6037 - accuracy: 0.7082 - val_loss: 0.5819 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6010 - accuracy: 0.7061 - val_loss: 0.5818 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.6018 - accuracy: 0.7075 - val_loss: 0.5816 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6006 - accuracy: 0.7075 - val_loss: 0.5815 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6008 - accuracy: 0.7068 - val_loss: 0.5814 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6017 - accuracy: 0.7039 - val_loss: 0.5813 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6012 - accuracy: 0.7046 - val_loss: 0.5811 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6028 - accuracy: 0.7003 - val_loss: 0.5810 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6024 - accuracy: 0.7039 - val_loss: 0.5809 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6012 - accuracy: 0.7068 - val_loss: 0.5808 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6011 - accuracy: 0.7032 - val_loss: 0.5807 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6024 - accuracy: 0.7053 - val_loss: 0.5806 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6003 - accuracy: 0.7053 - val_loss: 0.5805 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7061 - val_loss: 0.5804 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6002 - accuracy: 0.7061 - val_loss: 0.5802 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7068 - val_loss: 0.5801 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6013 - accuracy: 0.7053 - val_loss: 0.5800 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7046 - val_loss: 0.5799 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6010 - accuracy: 0.7068 - val_loss: 0.5798 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6009 - accuracy: 0.7053 - val_loss: 0.5797 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7068 - val_loss: 0.5796 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6017 - accuracy: 0.7082 - val_loss: 0.5795 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6009 - accuracy: 0.7068 - val_loss: 0.5794 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6013 - accuracy: 0.7024 - val_loss: 0.5794 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6001 - accuracy: 0.7075 - val_loss: 0.5793 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6026 - accuracy: 0.7097 - val_loss: 0.5792 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7046 - val_loss: 0.5791 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6018 - accuracy: 0.7068 - val_loss: 0.5791 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6004 - accuracy: 0.7032 - val_loss: 0.5790 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6001 - accuracy: 0.7104 - val_loss: 0.5789 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6021 - accuracy: 0.7061 - val_loss: 0.5788 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7053 - val_loss: 0.5787 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 17ms/step - loss: 0.5976 - accuracy: 0.7068 - val_loss: 0.5787 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6003 - accuracy: 0.7061 - val_loss: 0.5786 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7017 - val_loss: 0.5785 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6007 - accuracy: 0.7075 - val_loss: 0.5785 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6020 - accuracy: 0.7024 - val_loss: 0.5784 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6004 - accuracy: 0.7024 - val_loss: 0.5783 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6004 - accuracy: 0.7061 - val_loss: 0.5782 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5976 - accuracy: 0.7097 - val_loss: 0.5782 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5985 - accuracy: 0.7068 - val_loss: 0.5781 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6008 - accuracy: 0.7068 - val_loss: 0.5780 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6029 - accuracy: 0.7032 - val_loss: 0.5780 - val_accuracy: 0.7464 - lr: 9.7656e-07\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5991 - accuracy: 0.7097 - val_loss: 0.5779 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6001 - accuracy: 0.7082 - val_loss: 0.5779 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 102/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6001 - accuracy: 0.7111 - val_loss: 0.5778 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 103/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6003 - accuracy: 0.7053 - val_loss: 0.5777 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 104/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6007 - accuracy: 0.7075 - val_loss: 0.5777 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 105/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5988 - accuracy: 0.7082 - val_loss: 0.5776 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 106/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6006 - accuracy: 0.7024 - val_loss: 0.5776 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 107/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6006 - accuracy: 0.7075 - val_loss: 0.5775 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 108/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6020 - accuracy: 0.7046 - val_loss: 0.5774 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 109/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6001 - accuracy: 0.7053 - val_loss: 0.5774 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 110/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6013 - accuracy: 0.7053 - val_loss: 0.5773 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 111/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6007 - accuracy: 0.7061 - val_loss: 0.5773 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 112/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6007 - accuracy: 0.7053 - val_loss: 0.5772 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 113/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5989 - accuracy: 0.7061 - val_loss: 0.5772 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 114/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6010 - accuracy: 0.7097 - val_loss: 0.5771 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 115/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6006 - accuracy: 0.7053 - val_loss: 0.5771 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 116/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5996 - accuracy: 0.7068 - val_loss: 0.5770 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 117/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6003 - accuracy: 0.7061 - val_loss: 0.5770 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 118/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5991 - accuracy: 0.7082 - val_loss: 0.5769 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 119/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7061 - val_loss: 0.5769 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 120/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7061 - val_loss: 0.5768 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 121/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7097 - val_loss: 0.5768 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 122/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7082 - val_loss: 0.5767 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 123/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6007 - accuracy: 0.7068 - val_loss: 0.5767 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 124/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7075 - val_loss: 0.5767 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 125/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5987 - accuracy: 0.7061 - val_loss: 0.5766 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 126/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5993 - accuracy: 0.7104 - val_loss: 0.5766 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 127/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7075 - val_loss: 0.5765 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 128/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6026 - accuracy: 0.7068 - val_loss: 0.5765 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 129/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5997 - accuracy: 0.7118 - val_loss: 0.5764 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 130/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6011 - accuracy: 0.7075 - val_loss: 0.5764 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 131/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5993 - accuracy: 0.7068 - val_loss: 0.5764 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 132/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6009 - accuracy: 0.7068 - val_loss: 0.5763 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 133/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6008 - accuracy: 0.7061 - val_loss: 0.5763 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 134/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5987 - accuracy: 0.7097 - val_loss: 0.5762 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 135/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7053 - val_loss: 0.5762 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 136/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7068 - val_loss: 0.5762 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 137/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7017 - val_loss: 0.5761 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 138/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7082 - val_loss: 0.5761 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 139/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6012 - accuracy: 0.7046 - val_loss: 0.5760 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 140/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5995 - accuracy: 0.7053 - val_loss: 0.5760 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 141/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6011 - accuracy: 0.7046 - val_loss: 0.5760 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 142/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7068 - val_loss: 0.5759 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 143/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5991 - accuracy: 0.7061 - val_loss: 0.5759 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 144/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7046 - val_loss: 0.5759 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 145/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6004 - accuracy: 0.7089 - val_loss: 0.5758 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 146/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7017 - val_loss: 0.5758 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 147/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5981 - accuracy: 0.7068 - val_loss: 0.5758 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 148/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5988 - accuracy: 0.7082 - val_loss: 0.5757 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 149/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5992 - accuracy: 0.7039 - val_loss: 0.5757 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 150/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7097 - val_loss: 0.5757 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 151/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6000 - accuracy: 0.7046 - val_loss: 0.5756 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 152/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5992 - accuracy: 0.7075 - val_loss: 0.5756 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 153/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6004 - accuracy: 0.7053 - val_loss: 0.5756 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 154/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5998 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 155/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5988 - accuracy: 0.7104 - val_loss: 0.5755 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 156/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5995 - accuracy: 0.7039 - val_loss: 0.5755 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 157/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6002 - accuracy: 0.7082 - val_loss: 0.5754 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 158/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7046 - val_loss: 0.5754 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 159/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7068 - val_loss: 0.5754 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 160/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7068 - val_loss: 0.5753 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 161/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5990 - accuracy: 0.7068 - val_loss: 0.5753 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 162/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5980 - accuracy: 0.7082 - val_loss: 0.5753 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 163/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5991 - accuracy: 0.7046 - val_loss: 0.5753 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 164/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5982 - accuracy: 0.7046 - val_loss: 0.5752 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 165/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5993 - accuracy: 0.7089 - val_loss: 0.5752 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 166/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.6019 - accuracy: 0.7032 - val_loss: 0.5752 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 167/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7068 - val_loss: 0.5751 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 168/10000\n",
            "87/87 [==============================] - 2s 17ms/step - loss: 0.5984 - accuracy: 0.7089 - val_loss: 0.5751 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 169/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6005 - accuracy: 0.7068 - val_loss: 0.5751 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 170/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5973 - accuracy: 0.7104 - val_loss: 0.5751 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 171/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6002 - accuracy: 0.7046 - val_loss: 0.5751 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 172/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6003 - accuracy: 0.7061 - val_loss: 0.5750 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 173/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5999 - accuracy: 0.7061 - val_loss: 0.5750 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 174/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7053 - val_loss: 0.5750 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 175/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5992 - accuracy: 0.7111 - val_loss: 0.5749 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 176/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5995 - accuracy: 0.7075 - val_loss: 0.5749 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 177/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7053 - val_loss: 0.5749 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 178/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7075 - val_loss: 0.5749 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 179/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5994 - accuracy: 0.7068 - val_loss: 0.5748 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 180/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7089 - val_loss: 0.5748 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 181/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7097 - val_loss: 0.5748 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 182/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7046 - val_loss: 0.5748 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 183/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5997 - accuracy: 0.7089 - val_loss: 0.5747 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 184/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5988 - accuracy: 0.7053 - val_loss: 0.5747 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 185/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5980 - accuracy: 0.7061 - val_loss: 0.5747 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 186/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5964 - accuracy: 0.7082 - val_loss: 0.5747 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 187/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7046 - val_loss: 0.5747 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 188/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7097 - val_loss: 0.5746 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 189/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7075 - val_loss: 0.5746 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 190/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6003 - accuracy: 0.7003 - val_loss: 0.5746 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 191/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5974 - accuracy: 0.7089 - val_loss: 0.5746 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 192/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5979 - accuracy: 0.7118 - val_loss: 0.5746 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 193/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5973 - accuracy: 0.7068 - val_loss: 0.5745 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 194/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.6000 - accuracy: 0.7104 - val_loss: 0.5745 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 195/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7082 - val_loss: 0.5745 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 196/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5983 - accuracy: 0.7053 - val_loss: 0.5745 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 197/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7104 - val_loss: 0.5744 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 198/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5979 - accuracy: 0.7089 - val_loss: 0.5744 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 199/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5997 - accuracy: 0.7075 - val_loss: 0.5744 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 200/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5965 - accuracy: 0.7082 - val_loss: 0.5744 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 201/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5976 - accuracy: 0.7068 - val_loss: 0.5744 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 202/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7082 - val_loss: 0.5743 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 203/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 204/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7053 - val_loss: 0.5743 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 205/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5743 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 206/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7046 - val_loss: 0.5743 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 207/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5998 - accuracy: 0.7061 - val_loss: 0.5742 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 208/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5993 - accuracy: 0.7075 - val_loss: 0.5742 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 209/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5982 - accuracy: 0.7075 - val_loss: 0.5742 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 210/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7068 - val_loss: 0.5742 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 211/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7053 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 212/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5988 - accuracy: 0.7104 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 213/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5989 - accuracy: 0.7089 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 214/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5997 - accuracy: 0.7061 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 215/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7082 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 216/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7039 - val_loss: 0.5741 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 217/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7039 - val_loss: 0.5740 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 218/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5994 - accuracy: 0.7082 - val_loss: 0.5740 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 219/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7068 - val_loss: 0.5740 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 220/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5988 - accuracy: 0.7111 - val_loss: 0.5740 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 221/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5993 - accuracy: 0.7104 - val_loss: 0.5740 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 222/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7039 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 223/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5973 - accuracy: 0.7061 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 224/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 225/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5996 - accuracy: 0.7068 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 226/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5999 - accuracy: 0.7068 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 227/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7053 - val_loss: 0.5739 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 228/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7075 - val_loss: 0.5738 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 229/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7097 - val_loss: 0.5738 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 230/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.5738 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 231/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.6001 - accuracy: 0.7053 - val_loss: 0.5738 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 232/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5986 - accuracy: 0.7075 - val_loss: 0.5738 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 233/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5963 - accuracy: 0.7104 - val_loss: 0.5737 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 234/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5997 - accuracy: 0.7111 - val_loss: 0.5737 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 235/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7061 - val_loss: 0.5737 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 236/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5979 - accuracy: 0.7068 - val_loss: 0.5737 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 237/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5994 - accuracy: 0.7068 - val_loss: 0.5737 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 238/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7053 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 239/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 240/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 241/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7089 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 242/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5991 - accuracy: 0.7075 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 243/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7082 - val_loss: 0.5736 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 244/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7068 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 245/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5998 - accuracy: 0.7075 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 246/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5972 - accuracy: 0.7061 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 247/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5985 - accuracy: 0.7089 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 248/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7104 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 249/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5998 - accuracy: 0.7111 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 250/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7089 - val_loss: 0.5735 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 251/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7075 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 252/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5999 - accuracy: 0.7082 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 253/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5993 - accuracy: 0.7061 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 254/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5984 - accuracy: 0.7061 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 255/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7068 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 256/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7061 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 257/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5989 - accuracy: 0.7046 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 258/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7039 - val_loss: 0.5734 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 259/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7082 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 260/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7104 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 261/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7046 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 262/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7089 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 263/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7061 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 264/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5982 - accuracy: 0.7089 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 265/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5989 - accuracy: 0.7053 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 266/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7089 - val_loss: 0.5733 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 267/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7089 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 268/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7075 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 269/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7061 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 270/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7082 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 271/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5998 - accuracy: 0.7053 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 272/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7061 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 273/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7082 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 274/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7061 - val_loss: 0.5732 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 275/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7075 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 276/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5991 - accuracy: 0.7046 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 277/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7104 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 278/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7075 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 279/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7089 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 280/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7075 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 281/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7068 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 282/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5964 - accuracy: 0.7082 - val_loss: 0.5731 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 283/10000\n",
            "87/87 [==============================] - 2s 18ms/step - loss: 0.5986 - accuracy: 0.7053 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 284/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5983 - accuracy: 0.7046 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 285/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7061 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 286/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7061 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 287/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7061 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 288/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7097 - val_loss: 0.5730 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 289/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5993 - accuracy: 0.7061 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 290/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7068 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 291/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7032 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 292/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5971 - accuracy: 0.7089 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 293/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5999 - accuracy: 0.7082 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 294/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5995 - accuracy: 0.7075 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 295/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7082 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 296/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7082 - val_loss: 0.5729 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 297/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7075 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 298/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5989 - accuracy: 0.7053 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 299/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7068 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 300/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7111 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 301/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7053 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 302/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5981 - accuracy: 0.7053 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 303/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7046 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 304/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7068 - val_loss: 0.5728 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 305/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5976 - accuracy: 0.7082 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 306/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7061 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 307/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7089 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 308/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7082 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 309/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 310/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7097 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 311/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7075 - val_loss: 0.5727 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 312/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5981 - accuracy: 0.7068 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 313/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5994 - accuracy: 0.7104 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 314/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5976 - accuracy: 0.7104 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 315/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5963 - accuracy: 0.7075 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 316/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5951 - accuracy: 0.7046 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 317/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7068 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 318/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7075 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 319/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7082 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 320/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7089 - val_loss: 0.5726 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 321/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7089 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 322/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5984 - accuracy: 0.7068 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 323/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7068 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 324/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7046 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 325/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5968 - accuracy: 0.7068 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 326/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5961 - accuracy: 0.7061 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 327/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7068 - val_loss: 0.5725 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 328/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5973 - accuracy: 0.7089 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 329/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7097 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 330/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5968 - accuracy: 0.7104 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 331/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7053 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 332/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7104 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 333/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5999 - accuracy: 0.7082 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 334/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7075 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 335/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5960 - accuracy: 0.7111 - val_loss: 0.5724 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 336/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7111 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 337/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5966 - accuracy: 0.7089 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 338/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5979 - accuracy: 0.7075 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 339/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5972 - accuracy: 0.7089 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 340/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5969 - accuracy: 0.7082 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 341/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7061 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 342/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5961 - accuracy: 0.7061 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 343/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5976 - accuracy: 0.7075 - val_loss: 0.5723 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 344/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7082 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 345/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7075 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 346/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5964 - accuracy: 0.7075 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 347/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7082 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 348/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7068 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 349/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5958 - accuracy: 0.7111 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 350/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5974 - accuracy: 0.7097 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 351/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5986 - accuracy: 0.7068 - val_loss: 0.5722 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 352/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7089 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 353/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5977 - accuracy: 0.7061 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 354/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5979 - accuracy: 0.7097 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 355/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 356/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5980 - accuracy: 0.7061 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 357/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7039 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 358/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5958 - accuracy: 0.7082 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 359/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7075 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 360/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7075 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 361/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7082 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 9.7656e-07\n",
            "Epoch 362/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7068 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 363/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5957 - accuracy: 0.7068 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 364/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7068 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 365/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7061 - val_loss: 0.5721 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 366/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5956 - accuracy: 0.7068 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 367/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5955 - accuracy: 0.7053 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 368/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 369/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5970 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 370/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 371/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5979 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 372/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 373/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5985 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 374/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7068 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 4.8828e-07\n",
            "Epoch 375/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.6003 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 376/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5961 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 377/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 378/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5982 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 379/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5993 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 380/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 381/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5962 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 382/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 383/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 384/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7053 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 2.4414e-07\n",
            "Epoch 385/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7053 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 386/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5970 - accuracy: 0.7053 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 387/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 388/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 389/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 390/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 391/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7104 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 392/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 393/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 394/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5984 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 1.2207e-07\n",
            "Epoch 395/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5976 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 396/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7104 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 397/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 398/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5959 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 399/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 400/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 401/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7068 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 402/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 403/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5985 - accuracy: 0.7046 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 404/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 405/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5974 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 406/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5967 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 407/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7097 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 408/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 409/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5957 - accuracy: 0.7046 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 6.1035e-08\n",
            "Epoch 410/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5947 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 411/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7075 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 412/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5953 - accuracy: 0.7089 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 413/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5971 - accuracy: 0.7053 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 414/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5980 - accuracy: 0.7061 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 415/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5975 - accuracy: 0.7118 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 416/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5987 - accuracy: 0.7046 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 417/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.6001 - accuracy: 0.7046 - val_loss: 0.5720 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 418/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 419/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5983 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.0518e-08\n",
            "Epoch 420/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 421/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5990 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 422/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5987 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 423/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 424/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 425/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5948 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 426/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 427/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 428/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 429/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.5259e-08\n",
            "Epoch 430/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5957 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 431/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5995 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 432/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 433/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 434/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 435/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 436/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5990 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 437/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5996 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 438/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5968 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 439/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7118 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.6294e-09\n",
            "Epoch 440/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 441/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 442/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5978 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 443/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 444/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 445/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 446/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5951 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 447/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 448/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 449/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5976 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.8147e-09\n",
            "Epoch 450/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5983 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 451/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 452/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 453/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 454/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7046 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 455/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 456/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5958 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 457/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5956 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 458/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 459/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.9073e-09\n",
            "Epoch 460/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 461/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5945 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 462/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 463/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5974 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 464/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5943 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 465/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7111 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 466/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5980 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 467/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5953 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 468/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5946 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 469/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5980 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 9.5367e-10\n",
            "Epoch 470/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5965 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 471/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5952 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 472/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 473/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.5958 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 474/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 475/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5958 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 476/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 477/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 478/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7039 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 479/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 4.7684e-10\n",
            "Epoch 480/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5990 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 481/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5975 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 482/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 483/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5992 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 484/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5971 - accuracy: 0.7046 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 485/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5957 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 486/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 487/10000\n",
            "87/87 [==============================] - 2s 19ms/step - loss: 0.5983 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 488/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 489/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5983 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.3842e-10\n",
            "Epoch 490/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5953 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 491/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5948 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 492/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5958 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 493/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 494/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5954 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 495/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5974 - accuracy: 0.7111 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 496/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 497/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 498/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5977 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 499/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7104 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.1921e-10\n",
            "Epoch 500/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5978 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 501/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 502/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5957 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 503/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5978 - accuracy: 0.7032 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 504/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 505/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5959 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 506/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5974 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 507/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5940 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 508/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 509/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 5.9605e-11\n",
            "Epoch 510/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 511/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 512/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5983 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 513/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5946 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 514/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 515/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 516/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 517/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 518/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 519/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 2.9802e-11\n",
            "Epoch 520/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5984 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 521/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 522/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 523/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5968 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 524/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 525/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5964 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 526/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 527/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 528/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 529/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.4901e-11\n",
            "Epoch 530/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7111 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 531/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 532/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5968 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 533/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5956 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 534/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 535/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 536/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 537/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 538/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 539/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 7.4506e-12\n",
            "Epoch 540/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 541/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5955 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 542/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 543/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7097 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 544/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7068 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 545/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7046 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 546/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 547/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7061 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 548/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7039 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 549/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 3.7253e-12\n",
            "Epoch 550/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5988 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 551/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7111 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 552/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7046 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 553/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 554/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5958 - accuracy: 0.7032 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 555/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5982 - accuracy: 0.7089 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 556/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7075 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 557/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7046 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 558/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5975 - accuracy: 0.7082 - val_loss: 0.5719 - val_accuracy: 0.7493 - lr: 1.8626e-12\n",
            "Epoch 558: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5957 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5941 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5951 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5957 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5952 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5991 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5966 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5989 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.8626e-12\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5957 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5978 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5963 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5968 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5975 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.5961 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7055 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 9.3132e-13\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5972 - accuracy: 0.7048 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5966 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5975 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.5955 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5988 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5946 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5959 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5955 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 4.6566e-13\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5960 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5963 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5969 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5972 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5968 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5956 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.3283e-13\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5962 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5947 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5971 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5958 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5966 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5987 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5967 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.1642e-13\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5984 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5972 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5984 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5956 - accuracy: 0.7055 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 5.8208e-14\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5951 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5971 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5971 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5956 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5976 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5952 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5970 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 2.9104e-14\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5971 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5981 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5974 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5968 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5942 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5952 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5983 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5971 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 1.4552e-14\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5956 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5980 - accuracy: 0.7077 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5981 - accuracy: 0.7069 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5963 - accuracy: 0.7113 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5973 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7098 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 7.2760e-15\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.5971 - accuracy: 0.7062 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5974 - accuracy: 0.7120 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5973 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5962 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5967 - accuracy: 0.7084 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5961 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5965 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5977 - accuracy: 0.7106 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.7062 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.5969 - accuracy: 0.7091 - val_loss: 0.5750 - val_accuracy: 0.7370 - lr: 3.6380e-15\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6558 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6548 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6562 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6549 - accuracy: 0.6561 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6538 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6545 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6576 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6565 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6628 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6547 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6541 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.8190e-15\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6540 - accuracy: 0.6561 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6574 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6562 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6550 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6555 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6527 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6573 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6540 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 9.0949e-16\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6565 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6545 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6562 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6541 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6541 - accuracy: 0.6628 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6531 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6558 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6544 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6529 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 4.5475e-16\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6542 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6517 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6546 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6543 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6563 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6554 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6546 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6535 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6558 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6563 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.2737e-16\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6553 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6573 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6580 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6546 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6534 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6566 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6552 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6567 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6539 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.1369e-16\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6574 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6536 - accuracy: 0.6628 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6544 - accuracy: 0.6661 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6531 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6559 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6540 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6532 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6543 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6564 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6530 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 5.6843e-17\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6534 - accuracy: 0.6636 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6570 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6557 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6564 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6558 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6558 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6560 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6529 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6543 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6563 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 2.8422e-17\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6535 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6524 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6530 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6534 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6533 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6532 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6562 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6568 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6535 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6555 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 1.4211e-17\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6546 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6516 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6529 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6573 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6550 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6533 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 27ms/step - loss: 0.6559 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6555 - accuracy: 0.6570 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6536 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6543 - accuracy: 0.6595 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 7.1054e-18\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6546 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6570 - accuracy: 0.6603 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6530 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.6559 - accuracy: 0.6586 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6540 - accuracy: 0.6644 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6544 - accuracy: 0.6619 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6553 - accuracy: 0.6636 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.6534 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6520 - accuracy: 0.6636 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.6577 - accuracy: 0.6611 - val_loss: 0.5945 - val_accuracy: 0.7342 - lr: 3.5527e-18\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.6975 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7005 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.6990 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6988 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7028 - accuracy: 0.6139 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6981 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7005 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7009 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7002 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6993 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6988 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.7764e-18\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6995 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6992 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6995 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6992 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7006 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7006 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6990 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7020 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6978 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6994 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 8.8818e-19\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6995 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7000 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7006 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7000 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7001 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7006 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7001 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6988 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7004 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7005 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 4.4409e-19\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6998 - accuracy: 0.6066 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6988 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7012 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6989 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7014 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7008 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7007 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7032 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7027 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6997 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.2204e-19\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7008 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6995 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6991 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7005 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7011 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6998 - accuracy: 0.6139 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6979 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7001 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6982 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7018 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.1102e-19\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6986 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6997 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6992 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7018 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6992 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7007 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7003 - accuracy: 0.6146 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7016 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7000 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6992 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 5.5511e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6995 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6981 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6985 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7014 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6993 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7002 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7014 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6991 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6993 - accuracy: 0.6161 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6974 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 2.7756e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6979 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6999 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7007 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6999 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7005 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7004 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7005 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6990 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6986 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6992 - accuracy: 0.6080 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.3878e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6992 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7003 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7010 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7007 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7005 - accuracy: 0.6117 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6985 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7004 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7016 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7021 - accuracy: 0.6124 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7017 - accuracy: 0.6073 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7003 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7003 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7013 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7008 - accuracy: 0.6131 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7004 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7011 - accuracy: 0.6088 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6997 - accuracy: 0.6109 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6992 - accuracy: 0.6102 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.6996 - accuracy: 0.6095 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.7018 - accuracy: 0.6073 - val_loss: 0.6695 - val_accuracy: 0.6414 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7135 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7146 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7140 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7135 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7152 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7159 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7159 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7159 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7128 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7161 - accuracy: 0.5745 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7161 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7135 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7166 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7148 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7163 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7142 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7145 - accuracy: 0.5825 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7150 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7153 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7150 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7146 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7173 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7154 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7143 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7138 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7157 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7131 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7142 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.7140 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7134 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7168 - accuracy: 0.5738 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7171 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.7133 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7151 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7163 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7154 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7163 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7160 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7148 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7142 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7176 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7168 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7159 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7141 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7155 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.7134 - accuracy: 0.5825 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7156 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7150 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7152 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7138 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7150 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7157 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7146 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7131 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7136 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7127 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7139 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7154 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7146 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7146 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7167 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7140 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7151 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7166 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7149 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7139 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7153 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7174 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7156 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7136 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7154 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7151 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7133 - accuracy: 0.5760 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7130 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7153 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7154 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7155 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7162 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7136 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7143 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7144 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7141 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7147 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7134 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7162 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7159 - accuracy: 0.5789 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7151 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7148 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7157 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7139 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7165 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7153 - accuracy: 0.5803 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7162 - accuracy: 0.5810 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7152 - accuracy: 0.5760 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7143 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7150 - accuracy: 0.5796 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7141 - accuracy: 0.5847 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.7164 - accuracy: 0.5760 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7154 - accuracy: 0.5781 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7157 - accuracy: 0.5774 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7172 - accuracy: 0.5767 - val_loss: 0.7133 - val_accuracy: 0.6098 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7335 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7321 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7310 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7342 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7316 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7300 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7308 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7313 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7324 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7312 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7293 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7329 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7304 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7327 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7305 - accuracy: 0.5673 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7318 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7318 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7312 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7317 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7290 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7303 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7280 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7303 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7322 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7302 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7302 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7305 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7318 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7306 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7301 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7316 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7308 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7317 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7319 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7315 - accuracy: 0.5582 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7333 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7342 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7323 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7288 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7316 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7290 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7302 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7309 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7315 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7310 - accuracy: 0.5590 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7303 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7323 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7310 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7277 - accuracy: 0.5665 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7329 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7311 - accuracy: 0.5665 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7313 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7315 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7332 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7314 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7313 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7316 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7289 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7290 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7311 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7298 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7312 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7316 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7319 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7317 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7309 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7324 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7333 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7306 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7326 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7311 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7307 - accuracy: 0.5665 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7299 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7320 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7293 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7316 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7299 - accuracy: 0.5673 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7304 - accuracy: 0.5590 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7323 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7300 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7302 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7291 - accuracy: 0.5656 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7317 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7318 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7341 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7320 - accuracy: 0.5582 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7315 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7303 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7299 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7307 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7330 - accuracy: 0.5599 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7314 - accuracy: 0.5582 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7315 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7297 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7318 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7296 - accuracy: 0.5615 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7294 - accuracy: 0.5648 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7291 - accuracy: 0.5640 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7322 - accuracy: 0.5623 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7299 - accuracy: 0.5632 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7304 - accuracy: 0.5607 - val_loss: 0.7321 - val_accuracy: 0.5644 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 26ms/step - loss: 0.7821 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7829 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7822 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7838 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7838 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7862 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7843 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7840 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7843 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7836 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7826 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7835 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7855 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7847 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7847 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7848 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7847 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7840 - accuracy: 0.5197 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7818 - accuracy: 0.5270 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7830 - accuracy: 0.5204 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7818 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7831 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7838 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7851 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7821 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7818 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7847 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7840 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7817 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7814 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7839 - accuracy: 0.5277 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7850 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7850 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7852 - accuracy: 0.5263 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7852 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7826 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7862 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7824 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7820 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7833 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7827 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7835 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7849 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7841 - accuracy: 0.5197 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7837 - accuracy: 0.5212 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7820 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7838 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7835 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7842 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7855 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7863 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7847 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7825 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7831 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7841 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7864 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7830 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7850 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7839 - accuracy: 0.5263 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7826 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7851 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7833 - accuracy: 0.5219 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7833 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7820 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7827 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7852 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7863 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7804 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7801 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7833 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7825 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7814 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7841 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7849 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7827 - accuracy: 0.5285 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7846 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7843 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7837 - accuracy: 0.5212 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7819 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7851 - accuracy: 0.5204 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7828 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7842 - accuracy: 0.5190 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7843 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7824 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7833 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7835 - accuracy: 0.5204 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7852 - accuracy: 0.5197 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7863 - accuracy: 0.5263 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7832 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7827 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7842 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7838 - accuracy: 0.5248 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.7817 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7836 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7840 - accuracy: 0.5204 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7833 - accuracy: 0.5255 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7856 - accuracy: 0.5241 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7848 - accuracy: 0.5197 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7846 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7839 - accuracy: 0.5226 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7829 - accuracy: 0.5234 - val_loss: 0.8098 - val_accuracy: 0.4956 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7014 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7023 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7004 - accuracy: 0.5893 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7025 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6983 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7014 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7008 - accuracy: 0.5958 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6999 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7008 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7017 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7022 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7016 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.6991 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7024 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7005 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7013 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7007 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7036 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7014 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7039 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7011 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7010 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7008 - accuracy: 0.5901 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7024 - accuracy: 0.5901 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7024 - accuracy: 0.5886 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7009 - accuracy: 0.5958 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7024 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7034 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7004 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7026 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7008 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5901 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7006 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7026 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7015 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7025 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.6995 - accuracy: 0.5973 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7023 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7018 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7027 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7025 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6993 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7002 - accuracy: 0.5958 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7018 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7019 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7008 - accuracy: 0.5886 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6995 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7020 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7002 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7008 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7018 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.6995 - accuracy: 0.5901 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7013 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7011 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7015 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7014 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7015 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7024 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7016 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7028 - accuracy: 0.5901 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7001 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7020 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7020 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6993 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7009 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7008 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7000 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7007 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7018 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7012 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7010 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7020 - accuracy: 0.5958 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7010 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7026 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7001 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7016 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7024 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7025 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5893 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7014 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7041 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7035 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7035 - accuracy: 0.5908 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7009 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7025 - accuracy: 0.5915 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7038 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.6999 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7009 - accuracy: 0.5944 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7001 - accuracy: 0.5886 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7013 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7019 - accuracy: 0.5922 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7010 - accuracy: 0.5951 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.6991 - accuracy: 0.5965 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.7025 - accuracy: 0.5929 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7021 - accuracy: 0.5937 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.7024 - accuracy: 0.5872 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.7023 - accuracy: 0.5958 - val_loss: 0.7133 - val_accuracy: 0.6052 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7417 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7469 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7453 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7460 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7466 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7420 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7469 - accuracy: 0.5620 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7427 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7445 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7446 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7426 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7440 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7454 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7455 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7457 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7438 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7457 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7469 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7442 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7447 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7430 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7457 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7426 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7417 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7451 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7452 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7450 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7445 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7455 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7439 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7458 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7448 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7447 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7435 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7473 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7460 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7456 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7423 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7424 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7449 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7445 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7438 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7449 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7457 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7432 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7421 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7453 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7436 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7435 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7462 - accuracy: 0.5704 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7459 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7467 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7435 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7466 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7443 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7456 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7444 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7445 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7437 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7452 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7449 - accuracy: 0.5604 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7455 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7434 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7459 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7441 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7439 - accuracy: 0.5637 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7431 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7452 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7441 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7443 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7452 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7459 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7470 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7432 - accuracy: 0.5695 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7454 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7441 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7443 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7465 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7455 - accuracy: 0.5687 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7437 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.7447 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7445 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7438 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7454 - accuracy: 0.5629 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7458 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7446 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7467 - accuracy: 0.5654 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7447 - accuracy: 0.5695 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7471 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7435 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7444 - accuracy: 0.5679 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7454 - accuracy: 0.5662 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7440 - accuracy: 0.5670 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7418 - accuracy: 0.5645 - val_loss: 0.7419 - val_accuracy: 0.5748 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4822 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4833 - accuracy: 0.8314 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4812 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4824 - accuracy: 0.8379 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4821 - accuracy: 0.8321 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4810 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4829 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4837 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4829 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4815 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4833 - accuracy: 0.8394 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4821 - accuracy: 0.8386 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4842 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8321 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4838 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4826 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4825 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4819 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4831 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4830 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4844 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4818 - accuracy: 0.8379 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4838 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4836 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4831 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4821 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4827 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4829 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4830 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4819 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4829 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4820 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4824 - accuracy: 0.8379 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4824 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4820 - accuracy: 0.8386 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4833 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4837 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4839 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4835 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4828 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4843 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4816 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4812 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4833 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4832 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4824 - accuracy: 0.8386 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4835 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4833 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4835 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4818 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4826 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4833 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4830 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4828 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4826 - accuracy: 0.8379 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4842 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4833 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4834 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4835 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4818 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4841 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4827 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4820 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4818 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4825 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4841 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4831 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4823 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4830 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4829 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4821 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4826 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4836 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4836 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4810 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4822 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4841 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4821 - accuracy: 0.8379 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4840 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4827 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4845 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4824 - accuracy: 0.8314 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4814 - accuracy: 0.8357 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4826 - accuracy: 0.8386 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4842 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4832 - accuracy: 0.8386 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4834 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4823 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4841 - accuracy: 0.8343 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4829 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4846 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4839 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4824 - accuracy: 0.8321 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4845 - accuracy: 0.8336 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4847 - accuracy: 0.8300 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4832 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4792 - accuracy: 0.8372 - val_loss: 0.3890 - val_accuracy: 0.9249 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.5405 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5416 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5418 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5434 - accuracy: 0.7655 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5409 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5419 - accuracy: 0.7754 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5411 - accuracy: 0.7671 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5400 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5422 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5414 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5423 - accuracy: 0.7647 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5413 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5421 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5412 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5413 - accuracy: 0.7721 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5400 - accuracy: 0.7655 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5412 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5425 - accuracy: 0.7630 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5408 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5431 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5394 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5406 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5424 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.5407 - accuracy: 0.7746 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5424 - accuracy: 0.7638 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5429 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5407 - accuracy: 0.7647 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5424 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5410 - accuracy: 0.7721 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5429 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5407 - accuracy: 0.7729 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.5436 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5408 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5421 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5407 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5419 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5433 - accuracy: 0.7655 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5402 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5422 - accuracy: 0.7671 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5428 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5420 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5403 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5415 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5430 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5413 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5412 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5404 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5413 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5418 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5420 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5415 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5402 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5413 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5394 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5419 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5430 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5423 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5443 - accuracy: 0.7638 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5397 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5394 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5422 - accuracy: 0.7671 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5401 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5421 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5417 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5399 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5407 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5416 - accuracy: 0.7721 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5431 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5387 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5395 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5402 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5409 - accuracy: 0.7721 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5417 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5420 - accuracy: 0.7655 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5403 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5415 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5408 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5423 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5411 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5405 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5411 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5428 - accuracy: 0.7704 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5404 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5435 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5396 - accuracy: 0.7696 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5427 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5417 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5395 - accuracy: 0.7729 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5402 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5410 - accuracy: 0.7663 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5404 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5384 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5407 - accuracy: 0.7721 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5419 - accuracy: 0.7680 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5416 - accuracy: 0.7655 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5445 - accuracy: 0.7688 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5424 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5422 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5404 - accuracy: 0.7713 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5437 - accuracy: 0.7638 - val_loss: 0.4614 - val_accuracy: 0.8746 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4758 - accuracy: 0.8444 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4761 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4760 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4761 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4761 - accuracy: 0.8365 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4766 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4766 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4764 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4755 - accuracy: 0.8422 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4760 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4766 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4770 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4748 - accuracy: 0.8372 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4757 - accuracy: 0.8422 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4767 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4764 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4759 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4761 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4743 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4766 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4763 - accuracy: 0.8357 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4747 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4758 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4763 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4781 - accuracy: 0.8379 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4768 - accuracy: 0.8372 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4769 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4768 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4762 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4748 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4780 - accuracy: 0.8365 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4750 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4769 - accuracy: 0.8372 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4762 - accuracy: 0.8372 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4743 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4760 - accuracy: 0.8365 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4775 - accuracy: 0.8379 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4770 - accuracy: 0.8429 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4783 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4764 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4757 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4764 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4754 - accuracy: 0.8422 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4770 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4749 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4774 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4750 - accuracy: 0.8437 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4758 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4778 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.4773 - accuracy: 0.8372 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4750 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4773 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4763 - accuracy: 0.8422 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4771 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4752 - accuracy: 0.8444 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4762 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4763 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4771 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4756 - accuracy: 0.8437 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4754 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4756 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4758 - accuracy: 0.8422 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4766 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.4746 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4785 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4753 - accuracy: 0.8444 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4765 - accuracy: 0.8437 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4769 - accuracy: 0.8429 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4751 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4772 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4751 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4760 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4747 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4768 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4753 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4748 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4763 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4760 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4754 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4761 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4768 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4766 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4753 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4762 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4763 - accuracy: 0.8386 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4763 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4771 - accuracy: 0.8429 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4753 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.4783 - accuracy: 0.8393 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4769 - accuracy: 0.8379 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4761 - accuracy: 0.8408 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4766 - accuracy: 0.8401 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4763 - accuracy: 0.8429 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.4752 - accuracy: 0.8415 - val_loss: 0.3809 - val_accuracy: 0.9452 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5343 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5331 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5328 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5312 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5331 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5312 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5306 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5327 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5330 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5314 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5312 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5323 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 0.5338 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5314 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5313 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5295 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5324 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5312 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5333 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5322 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5309 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5324 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5319 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5328 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5320 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5325 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.5325 - accuracy: 0.7835 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5317 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5328 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5342 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5325 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5325 - accuracy: 0.7910 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5328 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5318 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5318 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5330 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5338 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5336 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5330 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5313 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5333 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5319 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5310 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5322 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5311 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5315 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5309 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5329 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5315 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5317 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5312 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5309 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5329 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5305 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5311 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5326 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5316 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5318 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5309 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5317 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5313 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5339 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5330 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5309 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5338 - accuracy: 0.7910 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5342 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5336 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5326 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5314 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5324 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5334 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5320 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5306 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5323 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5305 - accuracy: 0.7918 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5323 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5322 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5313 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5308 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5325 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5330 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5341 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5331 - accuracy: 0.7877 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5354 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5349 - accuracy: 0.7843 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5310 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.5281 - accuracy: 0.7885 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5344 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5306 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5307 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5316 - accuracy: 0.7852 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5326 - accuracy: 0.7860 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5336 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5328 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5321 - accuracy: 0.7902 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5317 - accuracy: 0.7893 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.5320 - accuracy: 0.7868 - val_loss: 0.4714 - val_accuracy: 0.8671 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5535 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5510 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5520 - accuracy: 0.7613 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5516 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5531 - accuracy: 0.7679 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5505 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5513 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5518 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5510 - accuracy: 0.7620 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5524 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5513 - accuracy: 0.7672 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5497 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5532 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5504 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5513 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5518 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5503 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5511 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5521 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5523 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5545 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5513 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5515 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5528 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5507 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5508 - accuracy: 0.7686 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5514 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5510 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5500 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5512 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5541 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5501 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5497 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5515 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5504 - accuracy: 0.7693 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5507 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5505 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5522 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5510 - accuracy: 0.7672 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5518 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5532 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5497 - accuracy: 0.7679 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5512 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5506 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5525 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5508 - accuracy: 0.7620 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5526 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5526 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5527 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5512 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5521 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5527 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5523 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5516 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5506 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5498 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5518 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5507 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5502 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5519 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5493 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5528 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5512 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5504 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5523 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5528 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5524 - accuracy: 0.7599 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5522 - accuracy: 0.7635 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5523 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5518 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5523 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5510 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5518 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5519 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.5523 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5518 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5538 - accuracy: 0.7620 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5522 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5516 - accuracy: 0.7679 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5508 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5507 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5500 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5522 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5527 - accuracy: 0.7672 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5533 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5493 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5513 - accuracy: 0.7628 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5536 - accuracy: 0.7664 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7672 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7642 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5516 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 2s 25ms/step - loss: 0.5519 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5511 - accuracy: 0.7657 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 2s 24ms/step - loss: 0.5501 - accuracy: 0.7650 - val_loss: 0.4816 - val_accuracy: 0.8280 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n"
          ]
        }
      ],
      "source": [
        "#For LSTM\n",
        "models_lstm = []\n",
        "histories_lstm = []\n",
        "for i in range(len(datasets)):\n",
        "  history_lstm = fit_model(model_lstm,X_train_all[i],y_train_all[i]) #Call back that records events into history object\n",
        "  models_lstm.append(model_lstm)\n",
        "  histories_lstm.append(history_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOvZ3XRwRAMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1511c2fc-7cf5-493c-b9be-52fc273c93aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 1.0723 - accuracy: 0.6362 - val_loss: 1.1407 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0558 - accuracy: 0.6376 - val_loss: 1.1387 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0978 - accuracy: 0.6297 - val_loss: 1.1363 - val_accuracy: 0.5793 - lr: 9.7656e-07\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0714 - accuracy: 0.6405 - val_loss: 1.1341 - val_accuracy: 0.5793 - lr: 9.7656e-07\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 1.0445 - accuracy: 0.6376 - val_loss: 1.1319 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0529 - accuracy: 0.6225 - val_loss: 1.1296 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 1.0769 - accuracy: 0.6390 - val_loss: 1.1274 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0749 - accuracy: 0.6311 - val_loss: 1.1254 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0117 - accuracy: 0.6549 - val_loss: 1.1231 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0562 - accuracy: 0.6318 - val_loss: 1.1209 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0264 - accuracy: 0.6326 - val_loss: 1.1188 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0086 - accuracy: 0.6513 - val_loss: 1.1167 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0411 - accuracy: 0.6376 - val_loss: 1.1147 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0396 - accuracy: 0.6419 - val_loss: 1.1127 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0595 - accuracy: 0.6390 - val_loss: 1.1103 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0522 - accuracy: 0.6326 - val_loss: 1.1085 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0371 - accuracy: 0.6527 - val_loss: 1.1068 - val_accuracy: 0.5821 - lr: 9.7656e-07\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0470 - accuracy: 0.6261 - val_loss: 1.1047 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0310 - accuracy: 0.6362 - val_loss: 1.1028 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0325 - accuracy: 0.6419 - val_loss: 1.1009 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0531 - accuracy: 0.6347 - val_loss: 1.0989 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0019 - accuracy: 0.6398 - val_loss: 1.0969 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0338 - accuracy: 0.6290 - val_loss: 1.0949 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9833 - accuracy: 0.6434 - val_loss: 1.0930 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0470 - accuracy: 0.6434 - val_loss: 1.0907 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0450 - accuracy: 0.6239 - val_loss: 1.0886 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0128 - accuracy: 0.6326 - val_loss: 1.0868 - val_accuracy: 0.5850 - lr: 9.7656e-07\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0503 - accuracy: 0.6282 - val_loss: 1.0846 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9878 - accuracy: 0.6405 - val_loss: 1.0829 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9837 - accuracy: 0.6520 - val_loss: 1.0811 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0273 - accuracy: 0.6282 - val_loss: 1.0791 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9977 - accuracy: 0.6419 - val_loss: 1.0774 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 1.0255 - accuracy: 0.6390 - val_loss: 1.0756 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0145 - accuracy: 0.6427 - val_loss: 1.0739 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9735 - accuracy: 0.6470 - val_loss: 1.0718 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0066 - accuracy: 0.6376 - val_loss: 1.0699 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9978 - accuracy: 0.6470 - val_loss: 1.0681 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0152 - accuracy: 0.6427 - val_loss: 1.0664 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9554 - accuracy: 0.6311 - val_loss: 1.0645 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9579 - accuracy: 0.6463 - val_loss: 1.0630 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 1.0187 - accuracy: 0.6304 - val_loss: 1.0613 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9549 - accuracy: 0.6398 - val_loss: 1.0595 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9727 - accuracy: 0.6520 - val_loss: 1.0576 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9623 - accuracy: 0.6527 - val_loss: 1.0561 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9917 - accuracy: 0.6448 - val_loss: 1.0544 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9661 - accuracy: 0.6455 - val_loss: 1.0526 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9789 - accuracy: 0.6513 - val_loss: 1.0508 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9634 - accuracy: 0.6419 - val_loss: 1.0490 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9726 - accuracy: 0.6463 - val_loss: 1.0474 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9751 - accuracy: 0.6369 - val_loss: 1.0455 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9777 - accuracy: 0.6448 - val_loss: 1.0436 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9311 - accuracy: 0.6455 - val_loss: 1.0420 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9547 - accuracy: 0.6405 - val_loss: 1.0405 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9493 - accuracy: 0.6434 - val_loss: 1.0390 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9530 - accuracy: 0.6463 - val_loss: 1.0373 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9675 - accuracy: 0.6599 - val_loss: 1.0356 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9598 - accuracy: 0.6448 - val_loss: 1.0337 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 102/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9613 - accuracy: 0.6419 - val_loss: 1.0320 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 103/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.9266 - accuracy: 0.6542 - val_loss: 1.0305 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 104/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9345 - accuracy: 0.6477 - val_loss: 1.0288 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 105/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9442 - accuracy: 0.6470 - val_loss: 1.0272 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 106/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9886 - accuracy: 0.6405 - val_loss: 1.0253 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 107/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9528 - accuracy: 0.6347 - val_loss: 1.0237 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 108/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9653 - accuracy: 0.6390 - val_loss: 1.0220 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 109/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9377 - accuracy: 0.6419 - val_loss: 1.0205 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 110/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9416 - accuracy: 0.6470 - val_loss: 1.0189 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 111/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9366 - accuracy: 0.6333 - val_loss: 1.0172 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 112/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9341 - accuracy: 0.6520 - val_loss: 1.0157 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 113/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9036 - accuracy: 0.6671 - val_loss: 1.0142 - val_accuracy: 0.5879 - lr: 9.7656e-07\n",
            "Epoch 114/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9225 - accuracy: 0.6513 - val_loss: 1.0124 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 115/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9421 - accuracy: 0.6419 - val_loss: 1.0108 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 116/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9269 - accuracy: 0.6484 - val_loss: 1.0091 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 117/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9442 - accuracy: 0.6448 - val_loss: 1.0074 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 118/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9531 - accuracy: 0.6463 - val_loss: 1.0059 - val_accuracy: 0.5908 - lr: 9.7656e-07\n",
            "Epoch 119/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9227 - accuracy: 0.6434 - val_loss: 1.0042 - val_accuracy: 0.5937 - lr: 9.7656e-07\n",
            "Epoch 120/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.9080 - accuracy: 0.6383 - val_loss: 1.0027 - val_accuracy: 0.5937 - lr: 9.7656e-07\n",
            "Epoch 121/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9274 - accuracy: 0.6340 - val_loss: 1.0011 - val_accuracy: 0.5937 - lr: 9.7656e-07\n",
            "Epoch 122/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9337 - accuracy: 0.6484 - val_loss: 0.9997 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 123/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9329 - accuracy: 0.6390 - val_loss: 0.9978 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 124/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8803 - accuracy: 0.6513 - val_loss: 0.9966 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 125/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9376 - accuracy: 0.6556 - val_loss: 0.9953 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 126/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8747 - accuracy: 0.6635 - val_loss: 0.9941 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 127/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9158 - accuracy: 0.6484 - val_loss: 0.9925 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 128/10000\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.8734 - accuracy: 0.6520 - val_loss: 0.9910 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 129/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8811 - accuracy: 0.6650 - val_loss: 0.9894 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 130/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9229 - accuracy: 0.6463 - val_loss: 0.9879 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 131/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9031 - accuracy: 0.6427 - val_loss: 0.9864 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 132/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9079 - accuracy: 0.6506 - val_loss: 0.9849 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 133/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9078 - accuracy: 0.6326 - val_loss: 0.9834 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 134/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9202 - accuracy: 0.6455 - val_loss: 0.9820 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 135/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8801 - accuracy: 0.6599 - val_loss: 0.9806 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 136/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8740 - accuracy: 0.6434 - val_loss: 0.9791 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 137/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9124 - accuracy: 0.6491 - val_loss: 0.9777 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 138/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8898 - accuracy: 0.6542 - val_loss: 0.9765 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 139/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9456 - accuracy: 0.6405 - val_loss: 0.9750 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 140/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9042 - accuracy: 0.6470 - val_loss: 0.9736 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 141/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8524 - accuracy: 0.6556 - val_loss: 0.9722 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 142/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8769 - accuracy: 0.6520 - val_loss: 0.9706 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 143/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8848 - accuracy: 0.6477 - val_loss: 0.9689 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 144/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8872 - accuracy: 0.6419 - val_loss: 0.9673 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 145/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8908 - accuracy: 0.6578 - val_loss: 0.9660 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 146/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8723 - accuracy: 0.6419 - val_loss: 0.9646 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 147/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8763 - accuracy: 0.6427 - val_loss: 0.9632 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 148/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9154 - accuracy: 0.6405 - val_loss: 0.9618 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 149/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8972 - accuracy: 0.6549 - val_loss: 0.9604 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 150/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8705 - accuracy: 0.6585 - val_loss: 0.9591 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 151/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.9128 - accuracy: 0.6405 - val_loss: 0.9574 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 152/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8793 - accuracy: 0.6441 - val_loss: 0.9562 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 153/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8865 - accuracy: 0.6599 - val_loss: 0.9548 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 154/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8476 - accuracy: 0.6635 - val_loss: 0.9536 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 155/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8587 - accuracy: 0.6628 - val_loss: 0.9524 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 156/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8770 - accuracy: 0.6470 - val_loss: 0.9511 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 157/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8518 - accuracy: 0.6441 - val_loss: 0.9497 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 158/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8518 - accuracy: 0.6506 - val_loss: 0.9484 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 159/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8597 - accuracy: 0.6412 - val_loss: 0.9470 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 160/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8517 - accuracy: 0.6542 - val_loss: 0.9458 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 161/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8566 - accuracy: 0.6527 - val_loss: 0.9444 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 162/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8391 - accuracy: 0.6635 - val_loss: 0.9431 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 163/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8765 - accuracy: 0.6383 - val_loss: 0.9416 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 164/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8446 - accuracy: 0.6455 - val_loss: 0.9404 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 165/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8186 - accuracy: 0.6599 - val_loss: 0.9390 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 166/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8566 - accuracy: 0.6455 - val_loss: 0.9378 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 167/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8630 - accuracy: 0.6535 - val_loss: 0.9367 - val_accuracy: 0.5965 - lr: 9.7656e-07\n",
            "Epoch 168/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8393 - accuracy: 0.6585 - val_loss: 0.9354 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 169/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8547 - accuracy: 0.6542 - val_loss: 0.9340 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 170/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8488 - accuracy: 0.6513 - val_loss: 0.9328 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 171/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8396 - accuracy: 0.6549 - val_loss: 0.9313 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 172/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8511 - accuracy: 0.6556 - val_loss: 0.9298 - val_accuracy: 0.5994 - lr: 9.7656e-07\n",
            "Epoch 173/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8592 - accuracy: 0.6614 - val_loss: 0.9284 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 174/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8342 - accuracy: 0.6563 - val_loss: 0.9271 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 175/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8324 - accuracy: 0.6599 - val_loss: 0.9260 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 176/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8503 - accuracy: 0.6499 - val_loss: 0.9250 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 177/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8248 - accuracy: 0.6513 - val_loss: 0.9238 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 178/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8493 - accuracy: 0.6592 - val_loss: 0.9224 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 179/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8229 - accuracy: 0.6643 - val_loss: 0.9212 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 180/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8221 - accuracy: 0.6599 - val_loss: 0.9202 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 181/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8645 - accuracy: 0.6427 - val_loss: 0.9186 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 182/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8429 - accuracy: 0.6499 - val_loss: 0.9173 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 183/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8098 - accuracy: 0.6571 - val_loss: 0.9161 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 184/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8233 - accuracy: 0.6542 - val_loss: 0.9150 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 185/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8153 - accuracy: 0.6542 - val_loss: 0.9139 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 186/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8420 - accuracy: 0.6499 - val_loss: 0.9124 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 187/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.8390 - accuracy: 0.6506 - val_loss: 0.9113 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 188/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8165 - accuracy: 0.6585 - val_loss: 0.9101 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 189/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8397 - accuracy: 0.6513 - val_loss: 0.9086 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 190/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8350 - accuracy: 0.6520 - val_loss: 0.9074 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 191/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8139 - accuracy: 0.6477 - val_loss: 0.9062 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 192/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8155 - accuracy: 0.6664 - val_loss: 0.9048 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 193/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8362 - accuracy: 0.6405 - val_loss: 0.9037 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 194/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7892 - accuracy: 0.6823 - val_loss: 0.9028 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 195/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8264 - accuracy: 0.6607 - val_loss: 0.9017 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 196/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8055 - accuracy: 0.6671 - val_loss: 0.9004 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 197/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8253 - accuracy: 0.6491 - val_loss: 0.8990 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 198/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8064 - accuracy: 0.6643 - val_loss: 0.8979 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 199/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8292 - accuracy: 0.6542 - val_loss: 0.8967 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 200/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7977 - accuracy: 0.6765 - val_loss: 0.8954 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 201/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8310 - accuracy: 0.6513 - val_loss: 0.8940 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 202/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8018 - accuracy: 0.6520 - val_loss: 0.8928 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 203/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8268 - accuracy: 0.6463 - val_loss: 0.8916 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 204/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8264 - accuracy: 0.6455 - val_loss: 0.8904 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 205/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7965 - accuracy: 0.6571 - val_loss: 0.8893 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 206/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8113 - accuracy: 0.6671 - val_loss: 0.8881 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 207/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8087 - accuracy: 0.6527 - val_loss: 0.8868 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 208/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8048 - accuracy: 0.6556 - val_loss: 0.8858 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 209/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7956 - accuracy: 0.6434 - val_loss: 0.8848 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 210/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7848 - accuracy: 0.6563 - val_loss: 0.8838 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 211/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7963 - accuracy: 0.6527 - val_loss: 0.8829 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 212/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8170 - accuracy: 0.6455 - val_loss: 0.8818 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 213/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7962 - accuracy: 0.6556 - val_loss: 0.8807 - val_accuracy: 0.6052 - lr: 9.7656e-07\n",
            "Epoch 214/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7942 - accuracy: 0.6585 - val_loss: 0.8797 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 215/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7944 - accuracy: 0.6556 - val_loss: 0.8787 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 216/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8000 - accuracy: 0.6671 - val_loss: 0.8777 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 217/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7604 - accuracy: 0.6693 - val_loss: 0.8767 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 218/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7936 - accuracy: 0.6513 - val_loss: 0.8754 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 219/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7913 - accuracy: 0.6571 - val_loss: 0.8744 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 220/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8184 - accuracy: 0.6535 - val_loss: 0.8732 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 221/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7732 - accuracy: 0.6607 - val_loss: 0.8721 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 222/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7807 - accuracy: 0.6563 - val_loss: 0.8711 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 223/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7957 - accuracy: 0.6578 - val_loss: 0.8700 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 224/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7689 - accuracy: 0.6664 - val_loss: 0.8690 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 225/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8002 - accuracy: 0.6650 - val_loss: 0.8679 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 226/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8041 - accuracy: 0.6571 - val_loss: 0.8668 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 227/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7741 - accuracy: 0.6744 - val_loss: 0.8658 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 228/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7663 - accuracy: 0.6506 - val_loss: 0.8649 - val_accuracy: 0.6023 - lr: 9.7656e-07\n",
            "Epoch 229/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8088 - accuracy: 0.6513 - val_loss: 0.8637 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 230/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.8176 - accuracy: 0.6556 - val_loss: 0.8626 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 231/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7975 - accuracy: 0.6390 - val_loss: 0.8614 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 232/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7940 - accuracy: 0.6527 - val_loss: 0.8606 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 233/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7866 - accuracy: 0.6635 - val_loss: 0.8595 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 234/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7936 - accuracy: 0.6650 - val_loss: 0.8583 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 235/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7853 - accuracy: 0.6628 - val_loss: 0.8573 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 236/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7689 - accuracy: 0.6664 - val_loss: 0.8566 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 237/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7696 - accuracy: 0.6607 - val_loss: 0.8556 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 238/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7552 - accuracy: 0.6657 - val_loss: 0.8547 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 239/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.8056 - accuracy: 0.6585 - val_loss: 0.8537 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 240/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7474 - accuracy: 0.6765 - val_loss: 0.8529 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 241/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7787 - accuracy: 0.6592 - val_loss: 0.8521 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 242/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7765 - accuracy: 0.6571 - val_loss: 0.8510 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 243/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7852 - accuracy: 0.6484 - val_loss: 0.8500 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 244/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7531 - accuracy: 0.6722 - val_loss: 0.8490 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 245/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7548 - accuracy: 0.6585 - val_loss: 0.8480 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 246/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7831 - accuracy: 0.6621 - val_loss: 0.8470 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 247/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7579 - accuracy: 0.6729 - val_loss: 0.8460 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 248/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7643 - accuracy: 0.6592 - val_loss: 0.8451 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 249/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7565 - accuracy: 0.6563 - val_loss: 0.8440 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 250/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7920 - accuracy: 0.6499 - val_loss: 0.8430 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 251/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7603 - accuracy: 0.6592 - val_loss: 0.8422 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 252/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7695 - accuracy: 0.6549 - val_loss: 0.8411 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 253/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7516 - accuracy: 0.6599 - val_loss: 0.8402 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 254/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7614 - accuracy: 0.6650 - val_loss: 0.8394 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 255/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7730 - accuracy: 0.6513 - val_loss: 0.8385 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 256/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7486 - accuracy: 0.6801 - val_loss: 0.8376 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 257/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7507 - accuracy: 0.6686 - val_loss: 0.8364 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 258/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7531 - accuracy: 0.6664 - val_loss: 0.8354 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 259/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7271 - accuracy: 0.6787 - val_loss: 0.8343 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 260/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7540 - accuracy: 0.6700 - val_loss: 0.8334 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 261/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7528 - accuracy: 0.6628 - val_loss: 0.8325 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 262/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7322 - accuracy: 0.6657 - val_loss: 0.8317 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 263/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7523 - accuracy: 0.6535 - val_loss: 0.8309 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 264/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7426 - accuracy: 0.6657 - val_loss: 0.8301 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 265/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7351 - accuracy: 0.6722 - val_loss: 0.8293 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 266/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7316 - accuracy: 0.6715 - val_loss: 0.8286 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 267/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7609 - accuracy: 0.6744 - val_loss: 0.8278 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 268/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7477 - accuracy: 0.6722 - val_loss: 0.8269 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 269/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7637 - accuracy: 0.6571 - val_loss: 0.8260 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 270/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7483 - accuracy: 0.6628 - val_loss: 0.8251 - val_accuracy: 0.6081 - lr: 9.7656e-07\n",
            "Epoch 271/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7517 - accuracy: 0.6722 - val_loss: 0.8241 - val_accuracy: 0.6110 - lr: 9.7656e-07\n",
            "Epoch 272/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7288 - accuracy: 0.6679 - val_loss: 0.8234 - val_accuracy: 0.6110 - lr: 9.7656e-07\n",
            "Epoch 273/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7533 - accuracy: 0.6592 - val_loss: 0.8225 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 274/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7410 - accuracy: 0.6808 - val_loss: 0.8216 - val_accuracy: 0.6110 - lr: 9.7656e-07\n",
            "Epoch 275/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7411 - accuracy: 0.6693 - val_loss: 0.8209 - val_accuracy: 0.6110 - lr: 9.7656e-07\n",
            "Epoch 276/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7344 - accuracy: 0.6707 - val_loss: 0.8200 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 277/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7281 - accuracy: 0.6664 - val_loss: 0.8193 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 278/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7282 - accuracy: 0.6621 - val_loss: 0.8186 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 279/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7405 - accuracy: 0.6585 - val_loss: 0.8175 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 280/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7288 - accuracy: 0.6715 - val_loss: 0.8168 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 281/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7403 - accuracy: 0.6650 - val_loss: 0.8158 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 282/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7204 - accuracy: 0.6657 - val_loss: 0.8149 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 283/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7562 - accuracy: 0.6614 - val_loss: 0.8140 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 284/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7305 - accuracy: 0.6556 - val_loss: 0.8132 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 285/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7666 - accuracy: 0.6592 - val_loss: 0.8124 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 286/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7257 - accuracy: 0.6772 - val_loss: 0.8118 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 287/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7171 - accuracy: 0.6823 - val_loss: 0.8109 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 288/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.7458 - accuracy: 0.6650 - val_loss: 0.8103 - val_accuracy: 0.6138 - lr: 9.7656e-07\n",
            "Epoch 289/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7480 - accuracy: 0.6650 - val_loss: 0.8093 - val_accuracy: 0.6167 - lr: 9.7656e-07\n",
            "Epoch 290/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7510 - accuracy: 0.6715 - val_loss: 0.8084 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 291/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7141 - accuracy: 0.6780 - val_loss: 0.8076 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 292/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7252 - accuracy: 0.6671 - val_loss: 0.8069 - val_accuracy: 0.6167 - lr: 9.7656e-07\n",
            "Epoch 293/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7609 - accuracy: 0.6592 - val_loss: 0.8060 - val_accuracy: 0.6167 - lr: 9.7656e-07\n",
            "Epoch 294/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7086 - accuracy: 0.6607 - val_loss: 0.8053 - val_accuracy: 0.6167 - lr: 9.7656e-07\n",
            "Epoch 295/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7332 - accuracy: 0.6794 - val_loss: 0.8045 - val_accuracy: 0.6167 - lr: 9.7656e-07\n",
            "Epoch 296/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7307 - accuracy: 0.6542 - val_loss: 0.8037 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 297/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7371 - accuracy: 0.6664 - val_loss: 0.8028 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 298/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7095 - accuracy: 0.6758 - val_loss: 0.8019 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 299/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7270 - accuracy: 0.6549 - val_loss: 0.8013 - val_accuracy: 0.6196 - lr: 9.7656e-07\n",
            "Epoch 300/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7276 - accuracy: 0.6671 - val_loss: 0.8004 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 301/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7280 - accuracy: 0.6715 - val_loss: 0.7997 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 302/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7189 - accuracy: 0.6621 - val_loss: 0.7989 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 303/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7128 - accuracy: 0.6621 - val_loss: 0.7982 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 304/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7235 - accuracy: 0.6578 - val_loss: 0.7974 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 305/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7279 - accuracy: 0.6736 - val_loss: 0.7966 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 306/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.7194 - accuracy: 0.6607 - val_loss: 0.7957 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 307/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7038 - accuracy: 0.6744 - val_loss: 0.7949 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 308/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7228 - accuracy: 0.6556 - val_loss: 0.7942 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 309/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7193 - accuracy: 0.6477 - val_loss: 0.7933 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 310/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7340 - accuracy: 0.6614 - val_loss: 0.7926 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 311/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7187 - accuracy: 0.6715 - val_loss: 0.7918 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 312/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7079 - accuracy: 0.6808 - val_loss: 0.7912 - val_accuracy: 0.6225 - lr: 9.7656e-07\n",
            "Epoch 313/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7405 - accuracy: 0.6592 - val_loss: 0.7905 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 314/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7331 - accuracy: 0.6628 - val_loss: 0.7896 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 315/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7080 - accuracy: 0.6808 - val_loss: 0.7888 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 316/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7113 - accuracy: 0.6585 - val_loss: 0.7879 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 317/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7042 - accuracy: 0.6765 - val_loss: 0.7872 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 318/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7022 - accuracy: 0.6715 - val_loss: 0.7866 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 319/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7193 - accuracy: 0.6744 - val_loss: 0.7859 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 320/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7227 - accuracy: 0.6571 - val_loss: 0.7853 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 321/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7098 - accuracy: 0.6664 - val_loss: 0.7846 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 322/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7249 - accuracy: 0.6571 - val_loss: 0.7839 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 323/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7160 - accuracy: 0.6722 - val_loss: 0.7830 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 324/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6960 - accuracy: 0.6765 - val_loss: 0.7823 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 325/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.6982 - accuracy: 0.6744 - val_loss: 0.7815 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 326/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7152 - accuracy: 0.6722 - val_loss: 0.7807 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 327/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7062 - accuracy: 0.6844 - val_loss: 0.7801 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 328/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6986 - accuracy: 0.6679 - val_loss: 0.7795 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 329/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6805 - accuracy: 0.6844 - val_loss: 0.7789 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 330/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6936 - accuracy: 0.6931 - val_loss: 0.7783 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 331/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.6924 - accuracy: 0.6693 - val_loss: 0.7775 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 332/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7221 - accuracy: 0.6628 - val_loss: 0.7768 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 333/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7180 - accuracy: 0.6628 - val_loss: 0.7761 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 334/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7205 - accuracy: 0.6592 - val_loss: 0.7753 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 335/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7061 - accuracy: 0.6700 - val_loss: 0.7747 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 336/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7192 - accuracy: 0.6657 - val_loss: 0.7739 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 337/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7124 - accuracy: 0.6563 - val_loss: 0.7732 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 338/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7190 - accuracy: 0.6686 - val_loss: 0.7726 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 339/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6861 - accuracy: 0.6916 - val_loss: 0.7720 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 340/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.7006 - accuracy: 0.6657 - val_loss: 0.7713 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 341/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6892 - accuracy: 0.6700 - val_loss: 0.7706 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 342/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7081 - accuracy: 0.6585 - val_loss: 0.7700 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 343/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6928 - accuracy: 0.6700 - val_loss: 0.7693 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 344/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6941 - accuracy: 0.6707 - val_loss: 0.7687 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 345/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.6736 - val_loss: 0.7679 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 346/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6868 - accuracy: 0.6830 - val_loss: 0.7674 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 347/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6683 - accuracy: 0.6866 - val_loss: 0.7669 - val_accuracy: 0.6254 - lr: 9.7656e-07\n",
            "Epoch 348/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6827 - accuracy: 0.6693 - val_loss: 0.7663 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 349/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6901 - accuracy: 0.6780 - val_loss: 0.7657 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 350/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6968 - accuracy: 0.6780 - val_loss: 0.7652 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 351/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6943 - accuracy: 0.6715 - val_loss: 0.7647 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 352/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7000 - accuracy: 0.6614 - val_loss: 0.7640 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 353/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6746 - accuracy: 0.6787 - val_loss: 0.7633 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 354/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6665 - accuracy: 0.6974 - val_loss: 0.7627 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 355/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7119 - accuracy: 0.6736 - val_loss: 0.7620 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 356/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6866 - accuracy: 0.6772 - val_loss: 0.7615 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 357/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6984 - accuracy: 0.6715 - val_loss: 0.7610 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 358/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6849 - accuracy: 0.6801 - val_loss: 0.7605 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 359/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6872 - accuracy: 0.6780 - val_loss: 0.7601 - val_accuracy: 0.6282 - lr: 9.7656e-07\n",
            "Epoch 360/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6984 - accuracy: 0.6679 - val_loss: 0.7594 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 361/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.6614 - val_loss: 0.7588 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 362/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6642 - accuracy: 0.6844 - val_loss: 0.7583 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 363/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6807 - accuracy: 0.6715 - val_loss: 0.7578 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 364/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7029 - accuracy: 0.6751 - val_loss: 0.7572 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 365/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6708 - accuracy: 0.6751 - val_loss: 0.7567 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 366/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6824 - accuracy: 0.6801 - val_loss: 0.7560 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 367/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6945 - accuracy: 0.6823 - val_loss: 0.7553 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 368/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6807 - accuracy: 0.6794 - val_loss: 0.7549 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 369/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6724 - accuracy: 0.6787 - val_loss: 0.7544 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 370/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6772 - accuracy: 0.6801 - val_loss: 0.7538 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 371/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6754 - accuracy: 0.6794 - val_loss: 0.7533 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 372/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6814 - accuracy: 0.6751 - val_loss: 0.7529 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 373/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6808 - accuracy: 0.6916 - val_loss: 0.7523 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 374/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6790 - accuracy: 0.6794 - val_loss: 0.7517 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 375/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6759 - accuracy: 0.6888 - val_loss: 0.7512 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 376/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6673 - accuracy: 0.6823 - val_loss: 0.7506 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 377/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6458 - accuracy: 0.6916 - val_loss: 0.7499 - val_accuracy: 0.6311 - lr: 9.7656e-07\n",
            "Epoch 378/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.7069 - accuracy: 0.6563 - val_loss: 0.7492 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 379/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6965 - accuracy: 0.6657 - val_loss: 0.7486 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 380/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6728 - accuracy: 0.6823 - val_loss: 0.7481 - val_accuracy: 0.6369 - lr: 9.7656e-07\n",
            "Epoch 381/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6572 - accuracy: 0.6787 - val_loss: 0.7478 - val_accuracy: 0.6369 - lr: 9.7656e-07\n",
            "Epoch 382/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6606 - accuracy: 0.6909 - val_loss: 0.7472 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 383/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6893 - accuracy: 0.6679 - val_loss: 0.7465 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 384/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6713 - accuracy: 0.6758 - val_loss: 0.7459 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 385/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6836 - accuracy: 0.6758 - val_loss: 0.7454 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 386/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6765 - accuracy: 0.6751 - val_loss: 0.7449 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 387/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6737 - accuracy: 0.6693 - val_loss: 0.7444 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 388/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6556 - accuracy: 0.6852 - val_loss: 0.7439 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 389/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6700 - accuracy: 0.6700 - val_loss: 0.7434 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 390/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6723 - accuracy: 0.6801 - val_loss: 0.7429 - val_accuracy: 0.6340 - lr: 9.7656e-07\n",
            "Epoch 391/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6718 - accuracy: 0.6816 - val_loss: 0.7423 - val_accuracy: 0.6369 - lr: 9.7656e-07\n",
            "Epoch 392/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6679 - accuracy: 0.6765 - val_loss: 0.7417 - val_accuracy: 0.6398 - lr: 9.7656e-07\n",
            "Epoch 393/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6787 - accuracy: 0.6722 - val_loss: 0.7413 - val_accuracy: 0.6398 - lr: 9.7656e-07\n",
            "Epoch 394/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6620 - accuracy: 0.6772 - val_loss: 0.7406 - val_accuracy: 0.6427 - lr: 9.7656e-07\n",
            "Epoch 395/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6680 - accuracy: 0.6808 - val_loss: 0.7402 - val_accuracy: 0.6427 - lr: 9.7656e-07\n",
            "Epoch 396/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6765 - accuracy: 0.6650 - val_loss: 0.7397 - val_accuracy: 0.6427 - lr: 9.7656e-07\n",
            "Epoch 397/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6733 - accuracy: 0.6751 - val_loss: 0.7392 - val_accuracy: 0.6427 - lr: 9.7656e-07\n",
            "Epoch 398/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6658 - accuracy: 0.6765 - val_loss: 0.7386 - val_accuracy: 0.6455 - lr: 9.7656e-07\n",
            "Epoch 399/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6529 - accuracy: 0.6852 - val_loss: 0.7380 - val_accuracy: 0.6455 - lr: 9.7656e-07\n",
            "Epoch 400/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.6690 - accuracy: 0.6686 - val_loss: 0.7375 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 401/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6645 - accuracy: 0.6787 - val_loss: 0.7369 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 402/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6909 - val_loss: 0.7366 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 403/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6686 - accuracy: 0.6744 - val_loss: 0.7362 - val_accuracy: 0.6455 - lr: 9.7656e-07\n",
            "Epoch 404/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6392 - accuracy: 0.6866 - val_loss: 0.7357 - val_accuracy: 0.6455 - lr: 9.7656e-07\n",
            "Epoch 405/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6659 - accuracy: 0.6765 - val_loss: 0.7352 - val_accuracy: 0.6455 - lr: 9.7656e-07\n",
            "Epoch 406/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6764 - accuracy: 0.6751 - val_loss: 0.7346 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 407/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6488 - accuracy: 0.6751 - val_loss: 0.7340 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 408/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6654 - accuracy: 0.6758 - val_loss: 0.7335 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 409/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6530 - accuracy: 0.6859 - val_loss: 0.7330 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 410/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6741 - accuracy: 0.6549 - val_loss: 0.7326 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 411/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6557 - accuracy: 0.6902 - val_loss: 0.7321 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 412/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6687 - accuracy: 0.6787 - val_loss: 0.7316 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 413/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6810 - accuracy: 0.6707 - val_loss: 0.7311 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 414/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.6629 - accuracy: 0.6671 - val_loss: 0.7307 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 415/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6651 - accuracy: 0.6801 - val_loss: 0.7303 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 416/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6435 - accuracy: 0.6996 - val_loss: 0.7300 - val_accuracy: 0.6484 - lr: 9.7656e-07\n",
            "Epoch 417/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6618 - accuracy: 0.6823 - val_loss: 0.7296 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 418/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6753 - accuracy: 0.6643 - val_loss: 0.7289 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 419/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6548 - accuracy: 0.6852 - val_loss: 0.7284 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 420/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6598 - accuracy: 0.6816 - val_loss: 0.7280 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 421/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6445 - accuracy: 0.6859 - val_loss: 0.7275 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 422/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6535 - accuracy: 0.6816 - val_loss: 0.7271 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 423/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.6837 - val_loss: 0.7267 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 424/10000\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.6499 - accuracy: 0.6859 - val_loss: 0.7262 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 425/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6577 - accuracy: 0.6837 - val_loss: 0.7258 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 426/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6501 - accuracy: 0.6859 - val_loss: 0.7253 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 427/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6396 - accuracy: 0.6909 - val_loss: 0.7249 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 428/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6625 - accuracy: 0.6736 - val_loss: 0.7245 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 429/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6401 - accuracy: 0.6664 - val_loss: 0.7239 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 430/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6421 - accuracy: 0.6895 - val_loss: 0.7235 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 431/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6314 - accuracy: 0.7003 - val_loss: 0.7231 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 432/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6529 - accuracy: 0.6751 - val_loss: 0.7228 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 433/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6441 - accuracy: 0.6880 - val_loss: 0.7225 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 434/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6438 - accuracy: 0.6916 - val_loss: 0.7222 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 435/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6420 - accuracy: 0.6945 - val_loss: 0.7218 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 436/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6627 - accuracy: 0.6736 - val_loss: 0.7213 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 437/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6500 - accuracy: 0.6729 - val_loss: 0.7209 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 438/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6555 - accuracy: 0.6772 - val_loss: 0.7203 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 439/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6646 - accuracy: 0.6758 - val_loss: 0.7199 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 440/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6515 - accuracy: 0.6686 - val_loss: 0.7194 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 441/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6364 - accuracy: 0.6837 - val_loss: 0.7190 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 442/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6579 - accuracy: 0.6888 - val_loss: 0.7186 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 443/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6536 - accuracy: 0.6852 - val_loss: 0.7182 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 444/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6463 - accuracy: 0.6938 - val_loss: 0.7179 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 445/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6502 - accuracy: 0.6700 - val_loss: 0.7174 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 446/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6418 - accuracy: 0.6744 - val_loss: 0.7170 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 447/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6379 - accuracy: 0.7032 - val_loss: 0.7166 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 448/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6448 - accuracy: 0.6880 - val_loss: 0.7163 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 449/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6398 - accuracy: 0.6823 - val_loss: 0.7159 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 450/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6504 - accuracy: 0.6758 - val_loss: 0.7154 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 451/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6366 - accuracy: 0.6996 - val_loss: 0.7150 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 452/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6240 - accuracy: 0.6981 - val_loss: 0.7147 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 453/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6407 - accuracy: 0.6916 - val_loss: 0.7142 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 454/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6363 - accuracy: 0.6852 - val_loss: 0.7138 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 455/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6399 - accuracy: 0.6866 - val_loss: 0.7134 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 456/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6600 - accuracy: 0.6794 - val_loss: 0.7130 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 457/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.6794 - val_loss: 0.7126 - val_accuracy: 0.6513 - lr: 9.7656e-07\n",
            "Epoch 458/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6487 - accuracy: 0.6873 - val_loss: 0.7121 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 459/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6629 - accuracy: 0.6736 - val_loss: 0.7117 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 460/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6280 - accuracy: 0.6952 - val_loss: 0.7112 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 461/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6371 - accuracy: 0.6808 - val_loss: 0.7108 - val_accuracy: 0.6542 - lr: 9.7656e-07\n",
            "Epoch 462/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6633 - accuracy: 0.6744 - val_loss: 0.7103 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 463/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6555 - accuracy: 0.6787 - val_loss: 0.7099 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 464/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6541 - accuracy: 0.6794 - val_loss: 0.7095 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 465/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6354 - accuracy: 0.6736 - val_loss: 0.7089 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 466/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6431 - accuracy: 0.6902 - val_loss: 0.7085 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 467/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6440 - accuracy: 0.6931 - val_loss: 0.7081 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 468/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6612 - accuracy: 0.6758 - val_loss: 0.7077 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 469/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6407 - accuracy: 0.6902 - val_loss: 0.7072 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 470/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6316 - accuracy: 0.6931 - val_loss: 0.7068 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 471/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6593 - accuracy: 0.6664 - val_loss: 0.7064 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 472/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6328 - accuracy: 0.6844 - val_loss: 0.7061 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 473/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6414 - accuracy: 0.6794 - val_loss: 0.7057 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 474/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6411 - accuracy: 0.6844 - val_loss: 0.7052 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 475/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6361 - accuracy: 0.6866 - val_loss: 0.7047 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 476/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6330 - accuracy: 0.6924 - val_loss: 0.7044 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 477/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6222 - accuracy: 0.6888 - val_loss: 0.7041 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 478/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6405 - accuracy: 0.6866 - val_loss: 0.7037 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 479/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6354 - accuracy: 0.6938 - val_loss: 0.7034 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 480/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6278 - accuracy: 0.6852 - val_loss: 0.7030 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 481/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6500 - accuracy: 0.6794 - val_loss: 0.7025 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 482/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6189 - accuracy: 0.6924 - val_loss: 0.7023 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 483/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6336 - accuracy: 0.6722 - val_loss: 0.7020 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 484/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6352 - accuracy: 0.6765 - val_loss: 0.7017 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 485/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6333 - accuracy: 0.6981 - val_loss: 0.7014 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 486/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6360 - accuracy: 0.6780 - val_loss: 0.7011 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 487/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6481 - accuracy: 0.6772 - val_loss: 0.7006 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 488/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6228 - accuracy: 0.6816 - val_loss: 0.7001 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 489/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6464 - accuracy: 0.6866 - val_loss: 0.6998 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 490/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6343 - accuracy: 0.6909 - val_loss: 0.6994 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 491/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6221 - accuracy: 0.6931 - val_loss: 0.6991 - val_accuracy: 0.6571 - lr: 9.7656e-07\n",
            "Epoch 492/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6139 - accuracy: 0.6960 - val_loss: 0.6988 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 493/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6357 - accuracy: 0.6873 - val_loss: 0.6986 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 494/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6354 - accuracy: 0.6844 - val_loss: 0.6983 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 495/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6471 - accuracy: 0.6852 - val_loss: 0.6979 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 496/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6400 - accuracy: 0.6880 - val_loss: 0.6974 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 497/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6438 - accuracy: 0.6707 - val_loss: 0.6971 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 498/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6268 - accuracy: 0.6931 - val_loss: 0.6968 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 499/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6351 - accuracy: 0.6931 - val_loss: 0.6963 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 500/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6428 - accuracy: 0.6902 - val_loss: 0.6962 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 501/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6311 - accuracy: 0.6823 - val_loss: 0.6960 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 502/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6184 - accuracy: 0.6859 - val_loss: 0.6957 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 503/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6338 - accuracy: 0.6837 - val_loss: 0.6953 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 504/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6315 - accuracy: 0.6880 - val_loss: 0.6948 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 505/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6400 - accuracy: 0.6837 - val_loss: 0.6944 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 506/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6281 - accuracy: 0.6924 - val_loss: 0.6940 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 507/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6435 - accuracy: 0.6844 - val_loss: 0.6937 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 508/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6302 - accuracy: 0.6888 - val_loss: 0.6933 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 509/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6182 - accuracy: 0.6967 - val_loss: 0.6931 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 510/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6331 - accuracy: 0.6895 - val_loss: 0.6928 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 511/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6214 - accuracy: 0.7053 - val_loss: 0.6926 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 512/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6141 - accuracy: 0.6981 - val_loss: 0.6924 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 513/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6192 - accuracy: 0.7010 - val_loss: 0.6921 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 514/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6201 - accuracy: 0.6988 - val_loss: 0.6918 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 515/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6154 - accuracy: 0.6895 - val_loss: 0.6915 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 516/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6210 - accuracy: 0.6837 - val_loss: 0.6912 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 517/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6166 - accuracy: 0.6938 - val_loss: 0.6909 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 518/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6208 - accuracy: 0.6981 - val_loss: 0.6905 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 519/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6303 - accuracy: 0.6852 - val_loss: 0.6902 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 520/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6084 - accuracy: 0.6960 - val_loss: 0.6899 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 521/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6158 - accuracy: 0.6938 - val_loss: 0.6895 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 522/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6368 - accuracy: 0.6960 - val_loss: 0.6893 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 523/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6116 - accuracy: 0.6909 - val_loss: 0.6891 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 524/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6293 - accuracy: 0.6873 - val_loss: 0.6887 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 525/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6225 - accuracy: 0.6945 - val_loss: 0.6884 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 526/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6348 - accuracy: 0.6823 - val_loss: 0.6881 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 527/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6209 - accuracy: 0.6873 - val_loss: 0.6878 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 528/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6284 - accuracy: 0.6780 - val_loss: 0.6875 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 529/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6104 - accuracy: 0.6960 - val_loss: 0.6872 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 530/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6074 - accuracy: 0.6945 - val_loss: 0.6869 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 531/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6157 - accuracy: 0.6938 - val_loss: 0.6865 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 532/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6254 - accuracy: 0.6880 - val_loss: 0.6863 - val_accuracy: 0.6599 - lr: 9.7656e-07\n",
            "Epoch 533/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6198 - accuracy: 0.6780 - val_loss: 0.6859 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 534/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6074 - accuracy: 0.6938 - val_loss: 0.6856 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 535/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6217 - accuracy: 0.6794 - val_loss: 0.6853 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 536/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6208 - accuracy: 0.6873 - val_loss: 0.6850 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 537/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5932 - accuracy: 0.7046 - val_loss: 0.6847 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 538/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6323 - accuracy: 0.6888 - val_loss: 0.6844 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 539/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6079 - accuracy: 0.6952 - val_loss: 0.6841 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 540/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5906 - accuracy: 0.7176 - val_loss: 0.6839 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 541/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6277 - accuracy: 0.6880 - val_loss: 0.6835 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 542/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6104 - accuracy: 0.6960 - val_loss: 0.6832 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 543/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6021 - accuracy: 0.7089 - val_loss: 0.6830 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 544/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6085 - accuracy: 0.6981 - val_loss: 0.6826 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 545/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6142 - accuracy: 0.6938 - val_loss: 0.6824 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 546/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6295 - accuracy: 0.6952 - val_loss: 0.6822 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 547/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6090 - accuracy: 0.6996 - val_loss: 0.6818 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 548/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5935 - accuracy: 0.7003 - val_loss: 0.6815 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 549/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5979 - accuracy: 0.7039 - val_loss: 0.6813 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 550/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6095 - accuracy: 0.6988 - val_loss: 0.6810 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 551/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6021 - accuracy: 0.7010 - val_loss: 0.6807 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 552/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5951 - accuracy: 0.7075 - val_loss: 0.6805 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 553/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6290 - accuracy: 0.6938 - val_loss: 0.6803 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 554/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6051 - accuracy: 0.6852 - val_loss: 0.6801 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 555/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6037 - accuracy: 0.7032 - val_loss: 0.6798 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 556/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6129 - accuracy: 0.6916 - val_loss: 0.6795 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 557/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6243 - accuracy: 0.6895 - val_loss: 0.6792 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 558/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6162 - accuracy: 0.6794 - val_loss: 0.6789 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 559/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6189 - accuracy: 0.6895 - val_loss: 0.6787 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 560/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6029 - accuracy: 0.6974 - val_loss: 0.6785 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 561/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6125 - accuracy: 0.6873 - val_loss: 0.6782 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 562/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6189 - accuracy: 0.6909 - val_loss: 0.6779 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 563/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6138 - accuracy: 0.6844 - val_loss: 0.6776 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 564/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6179 - accuracy: 0.7046 - val_loss: 0.6774 - val_accuracy: 0.6628 - lr: 9.7656e-07\n",
            "Epoch 565/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6085 - accuracy: 0.6952 - val_loss: 0.6772 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 566/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6066 - accuracy: 0.6924 - val_loss: 0.6770 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 567/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6005 - accuracy: 0.7003 - val_loss: 0.6768 - val_accuracy: 0.6657 - lr: 9.7656e-07\n",
            "Epoch 568/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6004 - accuracy: 0.6938 - val_loss: 0.6764 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 569/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6195 - accuracy: 0.6873 - val_loss: 0.6762 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 570/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6104 - accuracy: 0.6952 - val_loss: 0.6759 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 571/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6052 - accuracy: 0.7010 - val_loss: 0.6757 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 572/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6164 - accuracy: 0.6859 - val_loss: 0.6754 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 573/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6102 - accuracy: 0.6816 - val_loss: 0.6752 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 574/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6271 - accuracy: 0.6916 - val_loss: 0.6749 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 575/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6174 - accuracy: 0.7111 - val_loss: 0.6746 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 576/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6053 - accuracy: 0.6988 - val_loss: 0.6743 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 577/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6073 - accuracy: 0.7024 - val_loss: 0.6740 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 578/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6170 - accuracy: 0.7024 - val_loss: 0.6737 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 579/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5975 - accuracy: 0.7061 - val_loss: 0.6735 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 580/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6188 - accuracy: 0.6924 - val_loss: 0.6732 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 581/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6025 - accuracy: 0.7039 - val_loss: 0.6730 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 582/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6049 - accuracy: 0.6924 - val_loss: 0.6727 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 583/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6061 - accuracy: 0.6902 - val_loss: 0.6726 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 584/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6163 - accuracy: 0.6996 - val_loss: 0.6723 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 585/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5968 - accuracy: 0.6902 - val_loss: 0.6723 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 586/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6023 - accuracy: 0.7053 - val_loss: 0.6721 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 587/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6180 - accuracy: 0.6988 - val_loss: 0.6718 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 588/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5778 - accuracy: 0.7046 - val_loss: 0.6716 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 589/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5983 - accuracy: 0.7024 - val_loss: 0.6714 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 590/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5963 - accuracy: 0.7039 - val_loss: 0.6712 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 591/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6066 - accuracy: 0.6967 - val_loss: 0.6708 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 592/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6105 - accuracy: 0.6967 - val_loss: 0.6706 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 593/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6138 - accuracy: 0.7024 - val_loss: 0.6705 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 594/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5900 - accuracy: 0.7024 - val_loss: 0.6702 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 595/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6005 - accuracy: 0.7017 - val_loss: 0.6699 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 596/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5972 - accuracy: 0.7089 - val_loss: 0.6696 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 597/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6034 - accuracy: 0.7017 - val_loss: 0.6694 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 598/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6025 - accuracy: 0.6960 - val_loss: 0.6691 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 599/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6078 - accuracy: 0.7024 - val_loss: 0.6689 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 600/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5976 - accuracy: 0.6888 - val_loss: 0.6686 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 601/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6072 - accuracy: 0.6916 - val_loss: 0.6685 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 602/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5968 - accuracy: 0.7053 - val_loss: 0.6683 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 603/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6079 - accuracy: 0.7053 - val_loss: 0.6682 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 604/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6003 - accuracy: 0.6924 - val_loss: 0.6680 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 605/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5906 - accuracy: 0.7039 - val_loss: 0.6678 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 606/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6064 - accuracy: 0.7024 - val_loss: 0.6677 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 607/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6113 - accuracy: 0.7046 - val_loss: 0.6674 - val_accuracy: 0.6686 - lr: 9.7656e-07\n",
            "Epoch 608/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5930 - accuracy: 0.7003 - val_loss: 0.6672 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 609/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5959 - accuracy: 0.6967 - val_loss: 0.6670 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 610/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5995 - accuracy: 0.7046 - val_loss: 0.6669 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 611/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6002 - accuracy: 0.6873 - val_loss: 0.6666 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 612/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6202 - accuracy: 0.6787 - val_loss: 0.6664 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 613/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6039 - accuracy: 0.6981 - val_loss: 0.6662 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 614/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5989 - accuracy: 0.6938 - val_loss: 0.6660 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 615/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5948 - accuracy: 0.7039 - val_loss: 0.6657 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 616/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6002 - accuracy: 0.6960 - val_loss: 0.6654 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 617/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6103 - accuracy: 0.6916 - val_loss: 0.6652 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 618/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5924 - accuracy: 0.7219 - val_loss: 0.6649 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 619/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5913 - accuracy: 0.7161 - val_loss: 0.6648 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 620/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6053 - accuracy: 0.6952 - val_loss: 0.6647 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 621/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5886 - accuracy: 0.7118 - val_loss: 0.6646 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 622/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6106 - accuracy: 0.6758 - val_loss: 0.6643 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 623/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5989 - accuracy: 0.7075 - val_loss: 0.6640 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 624/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6058 - accuracy: 0.6981 - val_loss: 0.6638 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 625/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5878 - accuracy: 0.7125 - val_loss: 0.6636 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 626/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6063 - accuracy: 0.6938 - val_loss: 0.6634 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 627/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5873 - accuracy: 0.7082 - val_loss: 0.6633 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 628/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5924 - accuracy: 0.7053 - val_loss: 0.6631 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 629/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5827 - accuracy: 0.7017 - val_loss: 0.6629 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 630/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5923 - accuracy: 0.7125 - val_loss: 0.6627 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 631/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6076 - accuracy: 0.6938 - val_loss: 0.6625 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 632/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5949 - accuracy: 0.7017 - val_loss: 0.6624 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 633/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6021 - accuracy: 0.6902 - val_loss: 0.6621 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 634/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5925 - accuracy: 0.6960 - val_loss: 0.6619 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 635/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5824 - accuracy: 0.7197 - val_loss: 0.6618 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 636/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6065 - accuracy: 0.6931 - val_loss: 0.6617 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 637/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5842 - accuracy: 0.7140 - val_loss: 0.6615 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 638/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5792 - accuracy: 0.7097 - val_loss: 0.6615 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 639/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5855 - accuracy: 0.6981 - val_loss: 0.6613 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 640/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5923 - accuracy: 0.7010 - val_loss: 0.6612 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 641/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5906 - accuracy: 0.6981 - val_loss: 0.6610 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 642/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5877 - accuracy: 0.7147 - val_loss: 0.6608 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 643/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5989 - accuracy: 0.6960 - val_loss: 0.6606 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 644/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5869 - accuracy: 0.6960 - val_loss: 0.6604 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 645/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.6029 - accuracy: 0.7053 - val_loss: 0.6601 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 646/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5950 - accuracy: 0.6945 - val_loss: 0.6599 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 647/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5932 - accuracy: 0.6938 - val_loss: 0.6597 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 648/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5790 - accuracy: 0.7097 - val_loss: 0.6594 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 649/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5992 - accuracy: 0.6873 - val_loss: 0.6592 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 650/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5836 - accuracy: 0.7082 - val_loss: 0.6590 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 651/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5836 - accuracy: 0.7205 - val_loss: 0.6588 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 652/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5710 - accuracy: 0.7255 - val_loss: 0.6587 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 653/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5847 - accuracy: 0.7140 - val_loss: 0.6586 - val_accuracy: 0.6715 - lr: 9.7656e-07\n",
            "Epoch 654/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5848 - accuracy: 0.7075 - val_loss: 0.6583 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 655/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5994 - accuracy: 0.6938 - val_loss: 0.6582 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 656/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5906 - accuracy: 0.7024 - val_loss: 0.6581 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 657/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5938 - accuracy: 0.7053 - val_loss: 0.6579 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 658/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5835 - accuracy: 0.7176 - val_loss: 0.6578 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 659/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5853 - accuracy: 0.7003 - val_loss: 0.6576 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 660/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5929 - accuracy: 0.7024 - val_loss: 0.6574 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 661/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5923 - accuracy: 0.7068 - val_loss: 0.6573 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 662/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5992 - accuracy: 0.6931 - val_loss: 0.6570 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 663/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.6027 - accuracy: 0.7010 - val_loss: 0.6567 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 664/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5990 - accuracy: 0.6931 - val_loss: 0.6564 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 665/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5807 - accuracy: 0.7024 - val_loss: 0.6562 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 666/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5768 - accuracy: 0.7053 - val_loss: 0.6560 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 667/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5888 - accuracy: 0.7032 - val_loss: 0.6559 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 668/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5940 - accuracy: 0.7061 - val_loss: 0.6557 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 669/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5755 - accuracy: 0.7183 - val_loss: 0.6556 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 670/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5894 - accuracy: 0.7147 - val_loss: 0.6555 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 671/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5779 - accuracy: 0.7226 - val_loss: 0.6554 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 672/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5791 - accuracy: 0.7125 - val_loss: 0.6552 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 673/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5714 - accuracy: 0.7140 - val_loss: 0.6550 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 674/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5850 - accuracy: 0.7147 - val_loss: 0.6549 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 675/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5876 - accuracy: 0.6960 - val_loss: 0.6548 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 676/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5779 - accuracy: 0.7118 - val_loss: 0.6546 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 677/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5729 - accuracy: 0.7024 - val_loss: 0.6544 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 678/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5806 - accuracy: 0.7089 - val_loss: 0.6542 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 679/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5774 - accuracy: 0.7104 - val_loss: 0.6540 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 680/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5727 - accuracy: 0.7176 - val_loss: 0.6540 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 681/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5735 - accuracy: 0.7039 - val_loss: 0.6538 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 682/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5859 - accuracy: 0.7169 - val_loss: 0.6536 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 683/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5886 - accuracy: 0.7226 - val_loss: 0.6535 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 684/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5788 - accuracy: 0.6981 - val_loss: 0.6534 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 685/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5760 - accuracy: 0.7075 - val_loss: 0.6533 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 686/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5912 - accuracy: 0.7075 - val_loss: 0.6532 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 687/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5901 - accuracy: 0.7082 - val_loss: 0.6531 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 688/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5866 - accuracy: 0.7097 - val_loss: 0.6528 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 689/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5898 - accuracy: 0.7147 - val_loss: 0.6527 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 690/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5830 - accuracy: 0.7176 - val_loss: 0.6527 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 691/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5676 - accuracy: 0.7169 - val_loss: 0.6525 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 692/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5811 - accuracy: 0.7104 - val_loss: 0.6524 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 693/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5659 - accuracy: 0.7133 - val_loss: 0.6523 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 694/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5786 - accuracy: 0.7032 - val_loss: 0.6521 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 695/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5855 - accuracy: 0.6967 - val_loss: 0.6519 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 696/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5960 - accuracy: 0.7010 - val_loss: 0.6516 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 697/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5818 - accuracy: 0.7089 - val_loss: 0.6516 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 698/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5832 - accuracy: 0.7133 - val_loss: 0.6514 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 699/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5841 - accuracy: 0.6981 - val_loss: 0.6513 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 700/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5694 - accuracy: 0.7125 - val_loss: 0.6510 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 701/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5817 - accuracy: 0.7068 - val_loss: 0.6509 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 702/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5880 - accuracy: 0.7061 - val_loss: 0.6507 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 703/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5870 - accuracy: 0.7039 - val_loss: 0.6505 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 704/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5654 - accuracy: 0.7169 - val_loss: 0.6504 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 705/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5683 - accuracy: 0.7197 - val_loss: 0.6503 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 706/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5861 - accuracy: 0.7118 - val_loss: 0.6502 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 707/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5657 - accuracy: 0.7104 - val_loss: 0.6500 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 708/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5715 - accuracy: 0.7233 - val_loss: 0.6499 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 709/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5908 - accuracy: 0.7024 - val_loss: 0.6498 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 710/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5831 - accuracy: 0.7140 - val_loss: 0.6496 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 711/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5771 - accuracy: 0.7219 - val_loss: 0.6495 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 712/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5644 - accuracy: 0.7169 - val_loss: 0.6493 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 713/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5719 - accuracy: 0.7075 - val_loss: 0.6491 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 714/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5682 - accuracy: 0.7169 - val_loss: 0.6490 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 715/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5617 - accuracy: 0.7269 - val_loss: 0.6489 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 716/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5820 - accuracy: 0.7118 - val_loss: 0.6488 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 717/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5731 - accuracy: 0.7248 - val_loss: 0.6487 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 718/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5795 - accuracy: 0.7097 - val_loss: 0.6485 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 719/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5650 - accuracy: 0.7032 - val_loss: 0.6484 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 720/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5739 - accuracy: 0.7125 - val_loss: 0.6483 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 721/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5785 - accuracy: 0.7010 - val_loss: 0.6482 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 722/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5661 - accuracy: 0.7233 - val_loss: 0.6482 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 723/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5834 - accuracy: 0.7154 - val_loss: 0.6481 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 724/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5757 - accuracy: 0.7075 - val_loss: 0.6480 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 725/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5690 - accuracy: 0.7219 - val_loss: 0.6479 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 726/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5880 - accuracy: 0.7075 - val_loss: 0.6477 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 727/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5696 - accuracy: 0.7183 - val_loss: 0.6476 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 728/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5725 - accuracy: 0.7205 - val_loss: 0.6475 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 729/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.7140 - val_loss: 0.6474 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 730/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5694 - accuracy: 0.7140 - val_loss: 0.6473 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 731/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5665 - accuracy: 0.7104 - val_loss: 0.6472 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 732/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5736 - accuracy: 0.7097 - val_loss: 0.6471 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 733/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5791 - accuracy: 0.7125 - val_loss: 0.6470 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 734/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5692 - accuracy: 0.7183 - val_loss: 0.6469 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 735/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5645 - accuracy: 0.7255 - val_loss: 0.6469 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 736/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.7125 - val_loss: 0.6467 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 737/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5925 - accuracy: 0.7082 - val_loss: 0.6466 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 738/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5681 - accuracy: 0.7104 - val_loss: 0.6465 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 739/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5734 - accuracy: 0.7147 - val_loss: 0.6463 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 740/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5625 - accuracy: 0.7169 - val_loss: 0.6462 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 741/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5841 - accuracy: 0.6988 - val_loss: 0.6461 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 742/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5796 - accuracy: 0.6888 - val_loss: 0.6460 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 743/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5771 - accuracy: 0.7039 - val_loss: 0.6458 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 744/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5763 - accuracy: 0.7118 - val_loss: 0.6457 - val_accuracy: 0.6744 - lr: 9.7656e-07\n",
            "Epoch 745/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5845 - accuracy: 0.7003 - val_loss: 0.6456 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 746/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5741 - accuracy: 0.7125 - val_loss: 0.6455 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 747/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5726 - accuracy: 0.7147 - val_loss: 0.6454 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 748/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5811 - accuracy: 0.7053 - val_loss: 0.6452 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 749/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5648 - accuracy: 0.7226 - val_loss: 0.6452 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 750/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5699 - accuracy: 0.7133 - val_loss: 0.6451 - val_accuracy: 0.6801 - lr: 9.7656e-07\n",
            "Epoch 751/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5684 - accuracy: 0.7197 - val_loss: 0.6449 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 752/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5719 - accuracy: 0.7097 - val_loss: 0.6448 - val_accuracy: 0.6772 - lr: 9.7656e-07\n",
            "Epoch 753/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5790 - accuracy: 0.7075 - val_loss: 0.6446 - val_accuracy: 0.6830 - lr: 9.7656e-07\n",
            "Epoch 754/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5719 - accuracy: 0.7133 - val_loss: 0.6445 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 755/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5758 - accuracy: 0.7075 - val_loss: 0.6443 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 756/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5819 - accuracy: 0.7147 - val_loss: 0.6442 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 757/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5834 - accuracy: 0.7003 - val_loss: 0.6440 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 758/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5710 - accuracy: 0.7169 - val_loss: 0.6438 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 759/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5732 - accuracy: 0.7169 - val_loss: 0.6437 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 760/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5705 - accuracy: 0.7248 - val_loss: 0.6436 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 761/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5701 - accuracy: 0.7046 - val_loss: 0.6436 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 762/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5714 - accuracy: 0.7097 - val_loss: 0.6434 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 763/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5732 - accuracy: 0.7154 - val_loss: 0.6433 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 764/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5694 - accuracy: 0.7111 - val_loss: 0.6431 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 765/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5664 - accuracy: 0.7183 - val_loss: 0.6430 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 766/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.7176 - val_loss: 0.6430 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 767/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5668 - accuracy: 0.7183 - val_loss: 0.6429 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 768/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5749 - accuracy: 0.7169 - val_loss: 0.6427 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 769/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5718 - accuracy: 0.7118 - val_loss: 0.6426 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 770/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5702 - accuracy: 0.7205 - val_loss: 0.6425 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 771/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5766 - accuracy: 0.7068 - val_loss: 0.6424 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 772/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5762 - accuracy: 0.7053 - val_loss: 0.6423 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 773/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5710 - accuracy: 0.7212 - val_loss: 0.6422 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 774/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5722 - accuracy: 0.7176 - val_loss: 0.6422 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 775/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5620 - accuracy: 0.7190 - val_loss: 0.6422 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 776/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5708 - accuracy: 0.7197 - val_loss: 0.6421 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 777/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5803 - accuracy: 0.7061 - val_loss: 0.6420 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 778/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5733 - accuracy: 0.7089 - val_loss: 0.6420 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 779/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5669 - accuracy: 0.7233 - val_loss: 0.6419 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 780/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5645 - accuracy: 0.7154 - val_loss: 0.6417 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 781/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5613 - accuracy: 0.7190 - val_loss: 0.6416 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 782/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5717 - accuracy: 0.7183 - val_loss: 0.6415 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 783/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5651 - accuracy: 0.7341 - val_loss: 0.6414 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 784/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5780 - accuracy: 0.7169 - val_loss: 0.6412 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 785/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5666 - accuracy: 0.7154 - val_loss: 0.6411 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 786/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5726 - accuracy: 0.7161 - val_loss: 0.6409 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 787/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5683 - accuracy: 0.7140 - val_loss: 0.6408 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 788/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5780 - accuracy: 0.7061 - val_loss: 0.6407 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 789/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5754 - accuracy: 0.7183 - val_loss: 0.6405 - val_accuracy: 0.6859 - lr: 9.7656e-07\n",
            "Epoch 790/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5613 - accuracy: 0.7284 - val_loss: 0.6403 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 791/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5700 - accuracy: 0.7118 - val_loss: 0.6401 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 792/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5702 - accuracy: 0.7190 - val_loss: 0.6400 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 793/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.7147 - val_loss: 0.6400 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 794/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5723 - accuracy: 0.7197 - val_loss: 0.6399 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 795/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5664 - accuracy: 0.7205 - val_loss: 0.6398 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 796/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5666 - accuracy: 0.7147 - val_loss: 0.6398 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 797/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5599 - accuracy: 0.7277 - val_loss: 0.6398 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 798/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5584 - accuracy: 0.7176 - val_loss: 0.6397 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 799/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5665 - accuracy: 0.7111 - val_loss: 0.6396 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 800/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5692 - accuracy: 0.7154 - val_loss: 0.6395 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 801/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5619 - accuracy: 0.7190 - val_loss: 0.6394 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 802/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5650 - accuracy: 0.7284 - val_loss: 0.6393 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 803/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5622 - accuracy: 0.7305 - val_loss: 0.6391 - val_accuracy: 0.6888 - lr: 9.7656e-07\n",
            "Epoch 804/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5595 - accuracy: 0.7140 - val_loss: 0.6391 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 805/10000\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.5704 - accuracy: 0.7111 - val_loss: 0.6390 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 806/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5653 - accuracy: 0.7248 - val_loss: 0.6390 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 807/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5691 - accuracy: 0.7320 - val_loss: 0.6389 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 808/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5681 - accuracy: 0.7118 - val_loss: 0.6388 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 809/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5575 - accuracy: 0.7241 - val_loss: 0.6386 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 810/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5580 - accuracy: 0.7255 - val_loss: 0.6385 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 811/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5710 - accuracy: 0.7032 - val_loss: 0.6384 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 812/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5740 - accuracy: 0.7140 - val_loss: 0.6382 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 813/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.7320 - val_loss: 0.6381 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 814/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5829 - accuracy: 0.7010 - val_loss: 0.6380 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 815/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5562 - accuracy: 0.7241 - val_loss: 0.6379 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 816/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5716 - accuracy: 0.7118 - val_loss: 0.6379 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 817/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5699 - accuracy: 0.7133 - val_loss: 0.6377 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 818/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5756 - accuracy: 0.7032 - val_loss: 0.6376 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 819/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5662 - accuracy: 0.7241 - val_loss: 0.6376 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 820/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5740 - accuracy: 0.7097 - val_loss: 0.6375 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 821/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5627 - accuracy: 0.7284 - val_loss: 0.6374 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 822/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5712 - accuracy: 0.7068 - val_loss: 0.6373 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 823/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5584 - accuracy: 0.7190 - val_loss: 0.6373 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 824/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5716 - accuracy: 0.7068 - val_loss: 0.6371 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 825/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5672 - accuracy: 0.7183 - val_loss: 0.6371 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 826/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5686 - accuracy: 0.7089 - val_loss: 0.6370 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 827/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5598 - accuracy: 0.7241 - val_loss: 0.6369 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 828/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5599 - accuracy: 0.7205 - val_loss: 0.6368 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 829/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5601 - accuracy: 0.7212 - val_loss: 0.6367 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 830/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5618 - accuracy: 0.7089 - val_loss: 0.6367 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 831/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5717 - accuracy: 0.7255 - val_loss: 0.6367 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 832/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5740 - accuracy: 0.7097 - val_loss: 0.6365 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 833/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5459 - accuracy: 0.7298 - val_loss: 0.6365 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 834/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5566 - accuracy: 0.7154 - val_loss: 0.6365 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 835/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.7262 - val_loss: 0.6365 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 836/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5704 - accuracy: 0.7161 - val_loss: 0.6364 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 837/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5713 - accuracy: 0.7248 - val_loss: 0.6363 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 838/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5641 - accuracy: 0.7097 - val_loss: 0.6362 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 839/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5562 - accuracy: 0.7313 - val_loss: 0.6362 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 840/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5667 - accuracy: 0.7089 - val_loss: 0.6361 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 841/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5662 - accuracy: 0.7255 - val_loss: 0.6360 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 842/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5648 - accuracy: 0.7154 - val_loss: 0.6358 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 843/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5749 - accuracy: 0.7024 - val_loss: 0.6357 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 844/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5580 - accuracy: 0.7219 - val_loss: 0.6357 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 845/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5678 - accuracy: 0.7133 - val_loss: 0.6357 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 846/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5627 - accuracy: 0.7277 - val_loss: 0.6357 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 847/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5577 - accuracy: 0.7262 - val_loss: 0.6357 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 848/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5642 - accuracy: 0.7161 - val_loss: 0.6356 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 849/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5677 - accuracy: 0.7190 - val_loss: 0.6356 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 850/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5585 - accuracy: 0.7241 - val_loss: 0.6355 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 851/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5718 - accuracy: 0.7024 - val_loss: 0.6355 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 852/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5739 - accuracy: 0.7075 - val_loss: 0.6354 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 853/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5680 - accuracy: 0.7262 - val_loss: 0.6353 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 854/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5640 - accuracy: 0.7176 - val_loss: 0.6353 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 855/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.7291 - val_loss: 0.6352 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 856/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5611 - accuracy: 0.7262 - val_loss: 0.6351 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 857/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5622 - accuracy: 0.7327 - val_loss: 0.6350 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 858/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5434 - accuracy: 0.7385 - val_loss: 0.6350 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 859/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5524 - accuracy: 0.7197 - val_loss: 0.6349 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 860/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5657 - accuracy: 0.7241 - val_loss: 0.6348 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 861/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5741 - accuracy: 0.7017 - val_loss: 0.6346 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 862/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5547 - accuracy: 0.7255 - val_loss: 0.6346 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 863/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5654 - accuracy: 0.7248 - val_loss: 0.6346 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 864/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5638 - accuracy: 0.7133 - val_loss: 0.6345 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 865/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5472 - accuracy: 0.7428 - val_loss: 0.6344 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 866/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5560 - accuracy: 0.7190 - val_loss: 0.6344 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 867/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7154 - val_loss: 0.6343 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 868/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5550 - accuracy: 0.7133 - val_loss: 0.6342 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 869/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5609 - accuracy: 0.7226 - val_loss: 0.6341 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 870/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5708 - accuracy: 0.7104 - val_loss: 0.6341 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 871/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5540 - accuracy: 0.7147 - val_loss: 0.6340 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 872/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5592 - accuracy: 0.7320 - val_loss: 0.6340 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 873/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5518 - accuracy: 0.7140 - val_loss: 0.6339 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 874/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5592 - accuracy: 0.7183 - val_loss: 0.6338 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 875/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5589 - accuracy: 0.7197 - val_loss: 0.6336 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 876/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5689 - accuracy: 0.7140 - val_loss: 0.6335 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 877/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5660 - accuracy: 0.7233 - val_loss: 0.6334 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 878/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5527 - accuracy: 0.7392 - val_loss: 0.6334 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 879/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5734 - accuracy: 0.7024 - val_loss: 0.6333 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 880/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5566 - accuracy: 0.7298 - val_loss: 0.6332 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 881/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5587 - accuracy: 0.7140 - val_loss: 0.6331 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 882/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5638 - accuracy: 0.7233 - val_loss: 0.6331 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 883/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.7169 - val_loss: 0.6330 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 884/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5546 - accuracy: 0.7205 - val_loss: 0.6330 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 885/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5601 - accuracy: 0.7226 - val_loss: 0.6330 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 886/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5552 - accuracy: 0.7190 - val_loss: 0.6329 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 887/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5538 - accuracy: 0.7212 - val_loss: 0.6328 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 888/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5560 - accuracy: 0.7298 - val_loss: 0.6328 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 889/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5576 - accuracy: 0.7262 - val_loss: 0.6326 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 890/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5572 - accuracy: 0.7313 - val_loss: 0.6325 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 891/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5559 - accuracy: 0.7291 - val_loss: 0.6325 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 892/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5634 - accuracy: 0.7169 - val_loss: 0.6324 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 893/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5531 - accuracy: 0.7190 - val_loss: 0.6323 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 894/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5582 - accuracy: 0.7248 - val_loss: 0.6322 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 895/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5523 - accuracy: 0.7169 - val_loss: 0.6322 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 896/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5567 - accuracy: 0.7190 - val_loss: 0.6322 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 897/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5572 - accuracy: 0.7161 - val_loss: 0.6321 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 898/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5610 - accuracy: 0.7169 - val_loss: 0.6320 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 899/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5619 - accuracy: 0.7161 - val_loss: 0.6319 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 900/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.7370 - val_loss: 0.6317 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 901/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5412 - accuracy: 0.7205 - val_loss: 0.6317 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 902/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5598 - accuracy: 0.7118 - val_loss: 0.6317 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 903/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5609 - accuracy: 0.7183 - val_loss: 0.6316 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 904/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5457 - accuracy: 0.7233 - val_loss: 0.6315 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 905/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5574 - accuracy: 0.7226 - val_loss: 0.6316 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 906/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5565 - accuracy: 0.7205 - val_loss: 0.6315 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 907/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5484 - accuracy: 0.7226 - val_loss: 0.6314 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 908/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5507 - accuracy: 0.7248 - val_loss: 0.6314 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 909/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5526 - accuracy: 0.7176 - val_loss: 0.6313 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 910/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5637 - accuracy: 0.7212 - val_loss: 0.6312 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 911/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5663 - accuracy: 0.7118 - val_loss: 0.6312 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 912/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5641 - accuracy: 0.7169 - val_loss: 0.6311 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 913/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5556 - accuracy: 0.7341 - val_loss: 0.6310 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 914/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.7327 - val_loss: 0.6310 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 915/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5481 - accuracy: 0.7305 - val_loss: 0.6310 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 916/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5534 - accuracy: 0.7176 - val_loss: 0.6309 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 917/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5600 - accuracy: 0.7118 - val_loss: 0.6308 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 918/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5478 - accuracy: 0.7262 - val_loss: 0.6307 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 919/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5480 - accuracy: 0.7219 - val_loss: 0.6307 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 920/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5616 - accuracy: 0.7262 - val_loss: 0.6306 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 921/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5618 - accuracy: 0.7097 - val_loss: 0.6306 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 922/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5647 - accuracy: 0.7219 - val_loss: 0.6305 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 923/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5520 - accuracy: 0.7154 - val_loss: 0.6304 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 924/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5639 - accuracy: 0.7219 - val_loss: 0.6304 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 925/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5520 - accuracy: 0.7183 - val_loss: 0.6303 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 926/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5559 - accuracy: 0.7320 - val_loss: 0.6302 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 927/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5575 - accuracy: 0.7197 - val_loss: 0.6301 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 928/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5457 - accuracy: 0.7241 - val_loss: 0.6301 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 929/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5537 - accuracy: 0.7233 - val_loss: 0.6300 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 930/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5565 - accuracy: 0.7262 - val_loss: 0.6300 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 931/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5629 - accuracy: 0.7169 - val_loss: 0.6299 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 932/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5637 - accuracy: 0.7190 - val_loss: 0.6299 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 933/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5519 - accuracy: 0.7219 - val_loss: 0.6298 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 934/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5536 - accuracy: 0.7032 - val_loss: 0.6298 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 935/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5443 - accuracy: 0.7298 - val_loss: 0.6297 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 936/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5486 - accuracy: 0.7226 - val_loss: 0.6296 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 937/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5524 - accuracy: 0.7233 - val_loss: 0.6295 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 938/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5509 - accuracy: 0.7363 - val_loss: 0.6294 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 939/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5552 - accuracy: 0.7241 - val_loss: 0.6293 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 940/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5547 - accuracy: 0.7226 - val_loss: 0.6294 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 941/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5556 - accuracy: 0.7334 - val_loss: 0.6294 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 942/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5575 - accuracy: 0.7385 - val_loss: 0.6293 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 943/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5539 - accuracy: 0.7176 - val_loss: 0.6293 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 944/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5428 - accuracy: 0.7255 - val_loss: 0.6293 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 945/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5508 - accuracy: 0.7298 - val_loss: 0.6293 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 946/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5493 - accuracy: 0.7291 - val_loss: 0.6292 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 947/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5684 - accuracy: 0.7133 - val_loss: 0.6291 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 948/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5505 - accuracy: 0.7284 - val_loss: 0.6290 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 949/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5559 - accuracy: 0.7356 - val_loss: 0.6290 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 950/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5549 - accuracy: 0.7183 - val_loss: 0.6290 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 951/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5613 - accuracy: 0.7133 - val_loss: 0.6289 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 952/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5468 - accuracy: 0.7233 - val_loss: 0.6288 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 953/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5395 - accuracy: 0.7363 - val_loss: 0.6288 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 954/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5541 - accuracy: 0.7262 - val_loss: 0.6287 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 955/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5618 - accuracy: 0.7205 - val_loss: 0.6285 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 956/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5460 - accuracy: 0.7291 - val_loss: 0.6285 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 957/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5461 - accuracy: 0.7320 - val_loss: 0.6284 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 958/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5420 - accuracy: 0.7334 - val_loss: 0.6284 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 959/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5418 - accuracy: 0.7370 - val_loss: 0.6283 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 960/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5543 - accuracy: 0.7241 - val_loss: 0.6283 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 961/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5475 - accuracy: 0.7334 - val_loss: 0.6283 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 962/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5573 - accuracy: 0.7197 - val_loss: 0.6282 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 963/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5563 - accuracy: 0.7226 - val_loss: 0.6281 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 964/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5447 - accuracy: 0.7305 - val_loss: 0.6280 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 965/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5468 - accuracy: 0.7284 - val_loss: 0.6280 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 966/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5427 - accuracy: 0.7262 - val_loss: 0.6279 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 967/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5454 - accuracy: 0.7269 - val_loss: 0.6279 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 968/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5562 - accuracy: 0.7241 - val_loss: 0.6278 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 969/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5570 - accuracy: 0.7248 - val_loss: 0.6278 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 970/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5410 - accuracy: 0.7298 - val_loss: 0.6278 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 971/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5548 - accuracy: 0.7190 - val_loss: 0.6277 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 972/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5563 - accuracy: 0.7313 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 973/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5450 - accuracy: 0.7219 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 974/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5463 - accuracy: 0.7334 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 975/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5586 - accuracy: 0.7161 - val_loss: 0.6276 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 976/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5491 - accuracy: 0.7320 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 977/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5540 - accuracy: 0.7255 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 978/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5538 - accuracy: 0.7197 - val_loss: 0.6277 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 979/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5569 - accuracy: 0.7140 - val_loss: 0.6275 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 980/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5361 - accuracy: 0.7327 - val_loss: 0.6276 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 981/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5403 - accuracy: 0.7356 - val_loss: 0.6275 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 982/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5488 - accuracy: 0.7399 - val_loss: 0.6274 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 983/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5535 - accuracy: 0.7241 - val_loss: 0.6274 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 984/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5470 - accuracy: 0.7421 - val_loss: 0.6274 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 985/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5371 - accuracy: 0.7349 - val_loss: 0.6273 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 986/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5546 - accuracy: 0.7205 - val_loss: 0.6273 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 987/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5431 - accuracy: 0.7421 - val_loss: 0.6272 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 988/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5534 - accuracy: 0.7241 - val_loss: 0.6272 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 989/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5429 - accuracy: 0.7233 - val_loss: 0.6271 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 990/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5403 - accuracy: 0.7370 - val_loss: 0.6271 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 991/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5668 - accuracy: 0.7190 - val_loss: 0.6270 - val_accuracy: 0.6916 - lr: 9.7656e-07\n",
            "Epoch 992/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5404 - accuracy: 0.7277 - val_loss: 0.6270 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 993/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5507 - accuracy: 0.7248 - val_loss: 0.6270 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 994/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5485 - accuracy: 0.7147 - val_loss: 0.6269 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 995/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5449 - accuracy: 0.7392 - val_loss: 0.6269 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 996/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5556 - accuracy: 0.7298 - val_loss: 0.6269 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 997/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5465 - accuracy: 0.7291 - val_loss: 0.6269 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 998/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5547 - accuracy: 0.7421 - val_loss: 0.6269 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 999/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5565 - accuracy: 0.7248 - val_loss: 0.6268 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1000/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5458 - accuracy: 0.7291 - val_loss: 0.6267 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1001/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5507 - accuracy: 0.7327 - val_loss: 0.6268 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1002/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5544 - accuracy: 0.7284 - val_loss: 0.6267 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1003/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5499 - accuracy: 0.7313 - val_loss: 0.6266 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1004/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5457 - accuracy: 0.7363 - val_loss: 0.6266 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1005/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5355 - accuracy: 0.7291 - val_loss: 0.6267 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1006/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5561 - accuracy: 0.7313 - val_loss: 0.6267 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1007/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5458 - accuracy: 0.7435 - val_loss: 0.6266 - val_accuracy: 0.6945 - lr: 9.7656e-07\n",
            "Epoch 1008/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5557 - accuracy: 0.7183 - val_loss: 0.6265 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1009/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5550 - accuracy: 0.7284 - val_loss: 0.6265 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1010/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5485 - accuracy: 0.7147 - val_loss: 0.6264 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1011/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5476 - accuracy: 0.7219 - val_loss: 0.6264 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1012/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5350 - accuracy: 0.7349 - val_loss: 0.6263 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1013/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5455 - accuracy: 0.7305 - val_loss: 0.6263 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1014/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5522 - accuracy: 0.7305 - val_loss: 0.6262 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1015/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5385 - accuracy: 0.7370 - val_loss: 0.6263 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1016/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5400 - accuracy: 0.7450 - val_loss: 0.6263 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1017/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5433 - accuracy: 0.7334 - val_loss: 0.6262 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1018/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5460 - accuracy: 0.7205 - val_loss: 0.6262 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1019/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5362 - accuracy: 0.7298 - val_loss: 0.6262 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1020/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5570 - accuracy: 0.7154 - val_loss: 0.6261 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1021/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5353 - accuracy: 0.7378 - val_loss: 0.6261 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1022/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5452 - accuracy: 0.7327 - val_loss: 0.6261 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1023/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5404 - accuracy: 0.7363 - val_loss: 0.6260 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1024/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5444 - accuracy: 0.7241 - val_loss: 0.6260 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1025/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5441 - accuracy: 0.7233 - val_loss: 0.6260 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1026/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5579 - accuracy: 0.7118 - val_loss: 0.6260 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1027/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5540 - accuracy: 0.7255 - val_loss: 0.6259 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1028/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5496 - accuracy: 0.7255 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1029/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5356 - accuracy: 0.7349 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1030/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5419 - accuracy: 0.7284 - val_loss: 0.6259 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1031/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5544 - accuracy: 0.7219 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1032/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5512 - accuracy: 0.7255 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1033/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5335 - accuracy: 0.7298 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1034/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5626 - accuracy: 0.7176 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1035/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5531 - accuracy: 0.7154 - val_loss: 0.6257 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1036/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5432 - accuracy: 0.7284 - val_loss: 0.6257 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1037/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5449 - accuracy: 0.7349 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1038/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5437 - accuracy: 0.7320 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1039/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5534 - accuracy: 0.7097 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1040/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7313 - val_loss: 0.6258 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1041/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5437 - accuracy: 0.7219 - val_loss: 0.6257 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1042/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5396 - accuracy: 0.7385 - val_loss: 0.6257 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1043/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5431 - accuracy: 0.7399 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1044/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5343 - accuracy: 0.7363 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1045/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5398 - accuracy: 0.7233 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 9.7656e-07\n",
            "Epoch 1046/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5339 - accuracy: 0.7392 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1047/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5405 - accuracy: 0.7291 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1048/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5391 - accuracy: 0.7341 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1049/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5472 - accuracy: 0.7370 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1050/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5469 - accuracy: 0.7392 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1051/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5561 - accuracy: 0.7169 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1052/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5505 - accuracy: 0.7212 - val_loss: 0.6256 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1053/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5338 - accuracy: 0.7378 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1054/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5372 - accuracy: 0.7378 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1055/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.7197 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1056/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5506 - accuracy: 0.7255 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1057/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5509 - accuracy: 0.7212 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1058/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5440 - accuracy: 0.7219 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1059/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5382 - accuracy: 0.7233 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1060/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5516 - accuracy: 0.7197 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 4.8828e-07\n",
            "Epoch 1061/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5476 - accuracy: 0.7284 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1062/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5421 - accuracy: 0.7298 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1063/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5545 - accuracy: 0.7255 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1064/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5419 - accuracy: 0.7305 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1065/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5467 - accuracy: 0.7269 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1066/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5439 - accuracy: 0.7363 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1067/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5373 - accuracy: 0.7212 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1068/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5421 - accuracy: 0.7399 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1069/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5495 - accuracy: 0.7313 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1070/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5442 - accuracy: 0.7356 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1071/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5469 - accuracy: 0.7255 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1072/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5499 - accuracy: 0.7255 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1073/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5503 - accuracy: 0.7248 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1074/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5543 - accuracy: 0.7219 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1075/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5350 - accuracy: 0.7378 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1076/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5392 - accuracy: 0.7385 - val_loss: 0.6255 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1077/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5486 - accuracy: 0.7341 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.4414e-07\n",
            "Epoch 1078/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5384 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1079/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5514 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1080/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5544 - accuracy: 0.7154 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1081/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5523 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1082/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5376 - accuracy: 0.7356 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1083/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5451 - accuracy: 0.7399 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1084/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5355 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1085/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5298 - accuracy: 0.7450 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1086/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5425 - accuracy: 0.7298 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1087/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5492 - accuracy: 0.7219 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.2207e-07\n",
            "Epoch 1088/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5487 - accuracy: 0.7241 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1089/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5462 - accuracy: 0.7233 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1090/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5405 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1091/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5324 - accuracy: 0.7572 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1092/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5381 - accuracy: 0.7478 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1093/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5448 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1094/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1095/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5474 - accuracy: 0.7183 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1096/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5475 - accuracy: 0.7298 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1097/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5518 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 6.1035e-08\n",
            "Epoch 1098/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5421 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1099/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5355 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1100/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5394 - accuracy: 0.7262 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1101/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5350 - accuracy: 0.7349 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1102/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5470 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1103/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5378 - accuracy: 0.7226 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1104/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5441 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1105/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5543 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1106/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5424 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1107/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5477 - accuracy: 0.7219 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.0518e-08\n",
            "Epoch 1108/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5444 - accuracy: 0.7399 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1109/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5477 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1110/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5566 - accuracy: 0.7176 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1111/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5552 - accuracy: 0.7262 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1112/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5414 - accuracy: 0.7248 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1113/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5565 - accuracy: 0.7089 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1114/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5443 - accuracy: 0.7183 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1115/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5399 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1116/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5329 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1117/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5447 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.5259e-08\n",
            "Epoch 1118/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5394 - accuracy: 0.7464 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1119/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5465 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1120/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5529 - accuracy: 0.7125 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1121/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5476 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1122/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5341 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1123/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5373 - accuracy: 0.7370 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1124/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5446 - accuracy: 0.7176 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1125/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5346 - accuracy: 0.7399 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1126/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5424 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1127/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5415 - accuracy: 0.7370 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.6294e-09\n",
            "Epoch 1128/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5500 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1129/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5427 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1130/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5407 - accuracy: 0.7255 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1131/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1132/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5471 - accuracy: 0.7248 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1133/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5356 - accuracy: 0.7428 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1134/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1135/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5495 - accuracy: 0.7349 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1136/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5410 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1137/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5362 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 3.8147e-09\n",
            "Epoch 1138/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5448 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1139/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5421 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1140/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5441 - accuracy: 0.7269 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1141/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5383 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1142/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5617 - accuracy: 0.7183 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1143/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5570 - accuracy: 0.7219 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1144/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5288 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1145/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5506 - accuracy: 0.7370 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1146/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5360 - accuracy: 0.7269 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1147/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5426 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.9073e-09\n",
            "Epoch 1148/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5472 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1149/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5537 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1150/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5394 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1151/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5492 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1152/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5416 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1153/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5450 - accuracy: 0.7197 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1154/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5409 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1155/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5365 - accuracy: 0.7478 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1156/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5518 - accuracy: 0.7298 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1157/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5486 - accuracy: 0.7241 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 9.5367e-10\n",
            "Epoch 1158/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5582 - accuracy: 0.7169 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1159/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5513 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1160/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5422 - accuracy: 0.7392 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1161/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5563 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1162/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5411 - accuracy: 0.7385 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1163/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5461 - accuracy: 0.7212 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1164/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5506 - accuracy: 0.7197 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1165/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5491 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1166/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5306 - accuracy: 0.7385 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1167/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5338 - accuracy: 0.7385 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 4.7684e-10\n",
            "Epoch 1168/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5495 - accuracy: 0.7269 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1169/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5439 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1170/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5469 - accuracy: 0.7255 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1171/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5469 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1172/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5419 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1173/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5521 - accuracy: 0.7255 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1174/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5285 - accuracy: 0.7478 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1175/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5367 - accuracy: 0.7378 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1176/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5417 - accuracy: 0.7428 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1177/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5533 - accuracy: 0.7305 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.3842e-10\n",
            "Epoch 1178/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5425 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1179/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5447 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1180/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.5314 - accuracy: 0.7478 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1181/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5515 - accuracy: 0.7169 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1182/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5466 - accuracy: 0.7269 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1183/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5458 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1184/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1185/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5513 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1186/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5582 - accuracy: 0.7169 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1187/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5388 - accuracy: 0.7255 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.1921e-10\n",
            "Epoch 1188/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5503 - accuracy: 0.7298 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1189/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5477 - accuracy: 0.7305 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1190/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5417 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1191/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5418 - accuracy: 0.7269 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1192/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5339 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1193/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5480 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1194/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5463 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1195/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5424 - accuracy: 0.7385 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1196/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5570 - accuracy: 0.7219 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1197/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5405 - accuracy: 0.7205 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 5.9605e-11\n",
            "Epoch 1198/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5484 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1199/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5528 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1200/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5401 - accuracy: 0.7341 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1201/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5505 - accuracy: 0.7169 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1202/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5414 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1203/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7291 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1204/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5569 - accuracy: 0.7248 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1205/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5443 - accuracy: 0.7320 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1206/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5441 - accuracy: 0.7298 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1207/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5474 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 2.9802e-11\n",
            "Epoch 1208/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5478 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1209/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5462 - accuracy: 0.7205 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1210/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5439 - accuracy: 0.7363 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1211/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5501 - accuracy: 0.7241 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1212/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.7226 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1213/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5456 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1214/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5350 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1215/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5418 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1216/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5405 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1217/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5528 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 1.4901e-11\n",
            "Epoch 1218/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5454 - accuracy: 0.7341 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1219/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5356 - accuracy: 0.7313 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1220/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5435 - accuracy: 0.7284 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1221/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5417 - accuracy: 0.7327 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1222/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5536 - accuracy: 0.7226 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1223/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5441 - accuracy: 0.7277 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1224/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5366 - accuracy: 0.7341 - val_loss: 0.6254 - val_accuracy: 0.6974 - lr: 7.4506e-12\n",
            "Epoch 1224: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5717 - accuracy: 0.7171 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5895 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5754 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5895 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5716 - accuracy: 0.7077 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5789 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5831 - accuracy: 0.7019 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5861 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5806 - accuracy: 0.7120 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5815 - accuracy: 0.7243 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 11ms/step - loss: 0.5836 - accuracy: 0.7113 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 7.4506e-12\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5909 - accuracy: 0.7012 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5808 - accuracy: 0.7026 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5669 - accuracy: 0.7207 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5791 - accuracy: 0.7004 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5738 - accuracy: 0.7127 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5820 - accuracy: 0.6939 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5856 - accuracy: 0.7091 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5888 - accuracy: 0.6910 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5817 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5771 - accuracy: 0.7113 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 3.7253e-12\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5763 - accuracy: 0.7142 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5827 - accuracy: 0.7120 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5765 - accuracy: 0.7192 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5786 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5798 - accuracy: 0.7106 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5723 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5827 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5825 - accuracy: 0.7033 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5669 - accuracy: 0.7200 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5807 - accuracy: 0.7091 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.8626e-12\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5795 - accuracy: 0.7091 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5730 - accuracy: 0.7106 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5897 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5829 - accuracy: 0.7113 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5673 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5801 - accuracy: 0.7135 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5672 - accuracy: 0.7185 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5987 - accuracy: 0.6968 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5736 - accuracy: 0.7185 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5893 - accuracy: 0.6932 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 9.3132e-13\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5653 - accuracy: 0.7258 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5838 - accuracy: 0.7012 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5847 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5926 - accuracy: 0.7055 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5869 - accuracy: 0.7041 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5889 - accuracy: 0.7055 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5791 - accuracy: 0.7026 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5955 - accuracy: 0.6889 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5749 - accuracy: 0.7185 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.7258 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 4.6566e-13\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5825 - accuracy: 0.7055 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5761 - accuracy: 0.7077 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5880 - accuracy: 0.6983 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5806 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5879 - accuracy: 0.7004 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5853 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5891 - accuracy: 0.6997 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5842 - accuracy: 0.7091 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5763 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5760 - accuracy: 0.7185 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.3283e-13\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5803 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.6997 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5819 - accuracy: 0.7164 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5861 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5782 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5683 - accuracy: 0.7200 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5845 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5772 - accuracy: 0.7084 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5731 - accuracy: 0.7171 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5764 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.1642e-13\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5712 - accuracy: 0.7178 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5697 - accuracy: 0.7171 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5936 - accuracy: 0.7004 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5809 - accuracy: 0.7069 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5769 - accuracy: 0.7135 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5813 - accuracy: 0.7019 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5762 - accuracy: 0.7149 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5766 - accuracy: 0.7142 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5706 - accuracy: 0.7171 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5710 - accuracy: 0.7149 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 5.8208e-14\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.7062 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5926 - accuracy: 0.7127 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5781 - accuracy: 0.7077 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5858 - accuracy: 0.6975 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5782 - accuracy: 0.7120 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5713 - accuracy: 0.6983 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5693 - accuracy: 0.7127 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5816 - accuracy: 0.6968 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5832 - accuracy: 0.7077 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5770 - accuracy: 0.7113 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 2.9104e-14\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.7019 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5890 - accuracy: 0.7098 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5874 - accuracy: 0.6954 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5803 - accuracy: 0.7033 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5787 - accuracy: 0.7135 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5787 - accuracy: 0.7091 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5780 - accuracy: 0.7012 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5703 - accuracy: 0.7156 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5834 - accuracy: 0.7004 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.5826 - accuracy: 0.7098 - val_loss: 0.6218 - val_accuracy: 0.6821 - lr: 1.4552e-14\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7332 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7215 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7395 - accuracy: 0.6236 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7212 - accuracy: 0.6228 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7184 - accuracy: 0.6320 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7160 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7146 - accuracy: 0.6378 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7238 - accuracy: 0.6386 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7329 - accuracy: 0.6370 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7203 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7274 - accuracy: 0.6245 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 7.2760e-15\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7254 - accuracy: 0.6195 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7493 - accuracy: 0.6153 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7229 - accuracy: 0.6270 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7252 - accuracy: 0.6295 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7295 - accuracy: 0.6270 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7239 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7307 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7391 - accuracy: 0.6095 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7148 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7183 - accuracy: 0.6253 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 3.6380e-15\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7129 - accuracy: 0.6261 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7218 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7123 - accuracy: 0.6320 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7344 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7207 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7355 - accuracy: 0.6245 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7274 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7211 - accuracy: 0.6211 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7385 - accuracy: 0.6145 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7088 - accuracy: 0.6328 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.8190e-15\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7339 - accuracy: 0.6228 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7101 - accuracy: 0.6353 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7232 - accuracy: 0.6195 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7108 - accuracy: 0.6345 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7218 - accuracy: 0.6261 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7283 - accuracy: 0.6195 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7296 - accuracy: 0.6162 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7217 - accuracy: 0.6311 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7256 - accuracy: 0.6270 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7170 - accuracy: 0.6236 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 9.0949e-16\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7339 - accuracy: 0.6070 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7205 - accuracy: 0.6112 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7228 - accuracy: 0.6328 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7265 - accuracy: 0.6187 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7170 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7235 - accuracy: 0.6170 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7242 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7141 - accuracy: 0.6245 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7309 - accuracy: 0.6095 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7145 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 4.5475e-16\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7152 - accuracy: 0.6395 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7355 - accuracy: 0.6228 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7246 - accuracy: 0.6370 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7223 - accuracy: 0.6311 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7070 - accuracy: 0.6220 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7136 - accuracy: 0.6228 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7272 - accuracy: 0.6270 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7155 - accuracy: 0.6345 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7274 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7273 - accuracy: 0.6295 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.2737e-16\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7290 - accuracy: 0.6253 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7265 - accuracy: 0.6261 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7198 - accuracy: 0.6153 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7186 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7027 - accuracy: 0.6395 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7284 - accuracy: 0.6162 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7250 - accuracy: 0.6236 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7301 - accuracy: 0.6270 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7175 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7369 - accuracy: 0.6162 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.1369e-16\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7256 - accuracy: 0.6187 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7124 - accuracy: 0.6353 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7357 - accuracy: 0.6236 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7225 - accuracy: 0.6295 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7201 - accuracy: 0.6328 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.7298 - accuracy: 0.6170 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7210 - accuracy: 0.6253 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7367 - accuracy: 0.6211 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7213 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7310 - accuracy: 0.6078 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 5.6843e-17\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7190 - accuracy: 0.6278 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7142 - accuracy: 0.6253 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7178 - accuracy: 0.6386 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7352 - accuracy: 0.6236 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7294 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7262 - accuracy: 0.6203 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7256 - accuracy: 0.6245 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7264 - accuracy: 0.6228 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7316 - accuracy: 0.6311 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7225 - accuracy: 0.6261 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 2.8422e-17\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7339 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7393 - accuracy: 0.6303 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7203 - accuracy: 0.6336 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7206 - accuracy: 0.6286 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7229 - accuracy: 0.6320 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7383 - accuracy: 0.6162 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7292 - accuracy: 0.6145 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7284 - accuracy: 0.6078 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.7149 - accuracy: 0.6353 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.7240 - accuracy: 0.6220 - val_loss: 0.7001 - val_accuracy: 0.6412 - lr: 1.4211e-17\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7544 - accuracy: 0.5985 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7678 - accuracy: 0.5898 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7570 - accuracy: 0.5905 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7568 - accuracy: 0.5883 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7414 - accuracy: 0.6095 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7577 - accuracy: 0.5971 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7598 - accuracy: 0.6007 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7537 - accuracy: 0.5891 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.7607 - accuracy: 0.5964 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7471 - accuracy: 0.6007 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7503 - accuracy: 0.6088 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 7.1054e-18\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7619 - accuracy: 0.6000 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7755 - accuracy: 0.5832 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7680 - accuracy: 0.5927 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7446 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7645 - accuracy: 0.5927 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7731 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7676 - accuracy: 0.5737 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7634 - accuracy: 0.6000 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7597 - accuracy: 0.6044 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7625 - accuracy: 0.5985 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 3.5527e-18\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7592 - accuracy: 0.6124 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7644 - accuracy: 0.5898 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7599 - accuracy: 0.5905 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7589 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7609 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7535 - accuracy: 0.6007 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7527 - accuracy: 0.6000 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7489 - accuracy: 0.6073 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7549 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7465 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.7764e-18\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7545 - accuracy: 0.6051 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7583 - accuracy: 0.5978 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7654 - accuracy: 0.5839 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7562 - accuracy: 0.6044 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7614 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7303 - accuracy: 0.6131 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7501 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7521 - accuracy: 0.6015 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7570 - accuracy: 0.5927 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7483 - accuracy: 0.6015 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 8.8818e-19\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7552 - accuracy: 0.6000 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7673 - accuracy: 0.5934 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7438 - accuracy: 0.6248 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7657 - accuracy: 0.6117 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7640 - accuracy: 0.5978 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.7658 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7554 - accuracy: 0.5971 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7817 - accuracy: 0.5883 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7666 - accuracy: 0.6029 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7544 - accuracy: 0.5927 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 4.4409e-19\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7646 - accuracy: 0.6029 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.7476 - accuracy: 0.5920 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7553 - accuracy: 0.5898 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7541 - accuracy: 0.5956 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7617 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7586 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7627 - accuracy: 0.5942 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7626 - accuracy: 0.5942 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7660 - accuracy: 0.5898 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7568 - accuracy: 0.5905 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.2204e-19\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7707 - accuracy: 0.5978 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7532 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7660 - accuracy: 0.5891 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7673 - accuracy: 0.5964 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7546 - accuracy: 0.5964 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7493 - accuracy: 0.5964 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7584 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7597 - accuracy: 0.5956 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7575 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7677 - accuracy: 0.5854 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.1102e-19\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7629 - accuracy: 0.6051 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.7527 - accuracy: 0.5891 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7547 - accuracy: 0.5985 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7662 - accuracy: 0.5912 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7592 - accuracy: 0.5956 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7731 - accuracy: 0.5847 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.5920 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7350 - accuracy: 0.6182 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7633 - accuracy: 0.5847 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7611 - accuracy: 0.6044 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 5.5511e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7531 - accuracy: 0.5949 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7498 - accuracy: 0.6117 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7663 - accuracy: 0.5985 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7612 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7631 - accuracy: 0.6182 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7654 - accuracy: 0.5920 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7691 - accuracy: 0.6029 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7606 - accuracy: 0.5993 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7679 - accuracy: 0.5905 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7521 - accuracy: 0.6015 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 2.7756e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7638 - accuracy: 0.5942 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7510 - accuracy: 0.5949 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7435 - accuracy: 0.5971 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7441 - accuracy: 0.6088 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7639 - accuracy: 0.5847 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7563 - accuracy: 0.6000 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7415 - accuracy: 0.6051 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7549 - accuracy: 0.6022 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.7617 - accuracy: 0.5759 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.7587 - accuracy: 0.5956 - val_loss: 0.7733 - val_accuracy: 0.5977 - lr: 1.3878e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7206 - accuracy: 0.6143 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7358 - accuracy: 0.5984 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7205 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7246 - accuracy: 0.6013 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7218 - accuracy: 0.6172 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7099 - accuracy: 0.6201 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7107 - accuracy: 0.6107 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7222 - accuracy: 0.6129 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7245 - accuracy: 0.6107 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7244 - accuracy: 0.6020 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7121 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7290 - accuracy: 0.6136 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7127 - accuracy: 0.6230 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7229 - accuracy: 0.6035 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7207 - accuracy: 0.6201 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7205 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7319 - accuracy: 0.6085 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7172 - accuracy: 0.6194 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7232 - accuracy: 0.6042 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7270 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7134 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7366 - accuracy: 0.6107 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7353 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7186 - accuracy: 0.6194 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7189 - accuracy: 0.6151 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7157 - accuracy: 0.6288 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7059 - accuracy: 0.6165 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7319 - accuracy: 0.6006 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7254 - accuracy: 0.6216 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7186 - accuracy: 0.6078 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7237 - accuracy: 0.6129 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7264 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7204 - accuracy: 0.6165 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7148 - accuracy: 0.6208 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7223 - accuracy: 0.6107 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7129 - accuracy: 0.6035 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7141 - accuracy: 0.6252 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7190 - accuracy: 0.6266 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7080 - accuracy: 0.6122 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7128 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7354 - accuracy: 0.6056 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7246 - accuracy: 0.6158 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7121 - accuracy: 0.6230 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7173 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7301 - accuracy: 0.6187 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7355 - accuracy: 0.6020 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7201 - accuracy: 0.6151 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7186 - accuracy: 0.6143 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7191 - accuracy: 0.6143 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7319 - accuracy: 0.6006 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7253 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7144 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7194 - accuracy: 0.6122 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6891 - accuracy: 0.6143 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7435 - accuracy: 0.5970 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7192 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7398 - accuracy: 0.5962 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7167 - accuracy: 0.6208 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7290 - accuracy: 0.6194 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7182 - accuracy: 0.6129 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7213 - accuracy: 0.6208 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7285 - accuracy: 0.6122 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7174 - accuracy: 0.6071 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7284 - accuracy: 0.6187 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7293 - accuracy: 0.6071 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7130 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7261 - accuracy: 0.6158 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7205 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7136 - accuracy: 0.6252 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7280 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7144 - accuracy: 0.6071 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7152 - accuracy: 0.6208 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7308 - accuracy: 0.6085 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7123 - accuracy: 0.6136 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7075 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7342 - accuracy: 0.6042 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7113 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7150 - accuracy: 0.6100 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7162 - accuracy: 0.6049 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7176 - accuracy: 0.6071 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7135 - accuracy: 0.6216 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7251 - accuracy: 0.6027 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7060 - accuracy: 0.6310 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7191 - accuracy: 0.6165 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7057 - accuracy: 0.6346 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7215 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7191 - accuracy: 0.6172 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7111 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7215 - accuracy: 0.6085 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7093 - accuracy: 0.6071 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7190 - accuracy: 0.6179 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7120 - accuracy: 0.6187 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7140 - accuracy: 0.6172 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7248 - accuracy: 0.6042 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7171 - accuracy: 0.6165 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7187 - accuracy: 0.6093 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7227 - accuracy: 0.6158 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.7283 - accuracy: 0.6013 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7193 - accuracy: 0.6172 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7162 - accuracy: 0.6114 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7290 - accuracy: 0.6085 - val_loss: 0.7901 - val_accuracy: 0.5723 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5870 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5798 - accuracy: 0.7126 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5696 - accuracy: 0.7176 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5817 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5831 - accuracy: 0.6961 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5783 - accuracy: 0.7110 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5805 - accuracy: 0.7151 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5675 - accuracy: 0.7151 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5776 - accuracy: 0.7060 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5823 - accuracy: 0.7044 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5808 - accuracy: 0.7110 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5747 - accuracy: 0.7060 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5857 - accuracy: 0.7036 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5729 - accuracy: 0.7192 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5738 - accuracy: 0.7184 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5803 - accuracy: 0.7077 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5852 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5950 - accuracy: 0.7011 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5740 - accuracy: 0.7036 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5804 - accuracy: 0.7052 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5695 - accuracy: 0.7044 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5860 - accuracy: 0.7077 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5822 - accuracy: 0.7027 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5882 - accuracy: 0.7077 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5844 - accuracy: 0.6986 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5657 - accuracy: 0.7201 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5880 - accuracy: 0.6936 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5654 - accuracy: 0.7110 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5845 - accuracy: 0.7093 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5838 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5850 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5743 - accuracy: 0.7126 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5784 - accuracy: 0.7135 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5733 - accuracy: 0.7077 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5823 - accuracy: 0.7052 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5915 - accuracy: 0.7002 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5793 - accuracy: 0.7217 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5799 - accuracy: 0.6969 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5812 - accuracy: 0.7102 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5748 - accuracy: 0.7135 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5907 - accuracy: 0.6953 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5900 - accuracy: 0.7019 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5769 - accuracy: 0.7192 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5818 - accuracy: 0.7093 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5802 - accuracy: 0.7102 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5738 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5688 - accuracy: 0.7176 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5875 - accuracy: 0.7126 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5752 - accuracy: 0.7168 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5928 - accuracy: 0.7110 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5814 - accuracy: 0.7118 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5732 - accuracy: 0.7209 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5822 - accuracy: 0.7052 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5779 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5705 - accuracy: 0.7283 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5962 - accuracy: 0.7002 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5830 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5956 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5820 - accuracy: 0.7044 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5813 - accuracy: 0.7159 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5883 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5764 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5786 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5827 - accuracy: 0.7093 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5827 - accuracy: 0.7168 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5915 - accuracy: 0.7002 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5814 - accuracy: 0.7077 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5861 - accuracy: 0.7036 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5852 - accuracy: 0.6986 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5825 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5811 - accuracy: 0.7192 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5865 - accuracy: 0.6936 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5796 - accuracy: 0.7093 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5728 - accuracy: 0.7126 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5840 - accuracy: 0.7159 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5824 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5692 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5819 - accuracy: 0.7052 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5816 - accuracy: 0.7019 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5901 - accuracy: 0.7019 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5761 - accuracy: 0.7151 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5821 - accuracy: 0.7044 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5807 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5961 - accuracy: 0.6961 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5886 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5906 - accuracy: 0.7085 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5810 - accuracy: 0.7052 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5787 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5832 - accuracy: 0.7011 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5802 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5862 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5820 - accuracy: 0.7118 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5795 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5820 - accuracy: 0.7118 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5837 - accuracy: 0.7069 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.6012 - accuracy: 0.7027 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5856 - accuracy: 0.7110 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5808 - accuracy: 0.7002 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5759 - accuracy: 0.7060 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5872 - accuracy: 0.7036 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5966 - accuracy: 0.6870 - val_loss: 0.8067 - val_accuracy: 0.5611 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8538 - accuracy: 0.5460 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8384 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8486 - accuracy: 0.5270 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8582 - accuracy: 0.5307 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8506 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8504 - accuracy: 0.5460 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8450 - accuracy: 0.5358 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8504 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8430 - accuracy: 0.5314 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8522 - accuracy: 0.5328 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8597 - accuracy: 0.5226 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8436 - accuracy: 0.5336 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8544 - accuracy: 0.5401 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8358 - accuracy: 0.5474 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8566 - accuracy: 0.5328 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8396 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8487 - accuracy: 0.5307 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8548 - accuracy: 0.5533 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8317 - accuracy: 0.5650 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8587 - accuracy: 0.5197 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8579 - accuracy: 0.5270 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8517 - accuracy: 0.5321 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8437 - accuracy: 0.5423 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8493 - accuracy: 0.5401 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8583 - accuracy: 0.5343 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8578 - accuracy: 0.5416 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8514 - accuracy: 0.5328 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8485 - accuracy: 0.5416 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8529 - accuracy: 0.5336 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8428 - accuracy: 0.5416 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8614 - accuracy: 0.5182 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8451 - accuracy: 0.5460 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8518 - accuracy: 0.5409 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8405 - accuracy: 0.5343 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8468 - accuracy: 0.5343 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8510 - accuracy: 0.5423 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8464 - accuracy: 0.5445 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8528 - accuracy: 0.5416 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8408 - accuracy: 0.5270 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8492 - accuracy: 0.5496 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8471 - accuracy: 0.5467 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8451 - accuracy: 0.5533 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8500 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8551 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8518 - accuracy: 0.5372 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8377 - accuracy: 0.5438 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8534 - accuracy: 0.5255 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8399 - accuracy: 0.5438 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8577 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8437 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8532 - accuracy: 0.5314 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8562 - accuracy: 0.5350 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8437 - accuracy: 0.5380 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8465 - accuracy: 0.5336 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8607 - accuracy: 0.5358 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8459 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8298 - accuracy: 0.5562 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8541 - accuracy: 0.5307 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8563 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8427 - accuracy: 0.5489 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8581 - accuracy: 0.5358 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8523 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8536 - accuracy: 0.5394 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8464 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8394 - accuracy: 0.5350 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8461 - accuracy: 0.5438 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8453 - accuracy: 0.5482 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8556 - accuracy: 0.5270 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8508 - accuracy: 0.5365 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8522 - accuracy: 0.5409 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8350 - accuracy: 0.5350 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8565 - accuracy: 0.5438 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8392 - accuracy: 0.5511 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8539 - accuracy: 0.5387 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8425 - accuracy: 0.5409 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8432 - accuracy: 0.5380 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8441 - accuracy: 0.5460 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8451 - accuracy: 0.5423 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.8476 - accuracy: 0.5569 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8549 - accuracy: 0.5321 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8344 - accuracy: 0.5401 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8420 - accuracy: 0.5474 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8588 - accuracy: 0.5350 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.8565 - accuracy: 0.5350 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8366 - accuracy: 0.5489 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8413 - accuracy: 0.5336 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8247 - accuracy: 0.5474 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8288 - accuracy: 0.5547 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8401 - accuracy: 0.5431 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8336 - accuracy: 0.5526 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8387 - accuracy: 0.5445 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8532 - accuracy: 0.5358 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8566 - accuracy: 0.5489 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8462 - accuracy: 0.5431 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8454 - accuracy: 0.5394 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8495 - accuracy: 0.5445 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8433 - accuracy: 0.5401 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8392 - accuracy: 0.5401 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8370 - accuracy: 0.5460 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.8493 - accuracy: 0.5474 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.8500 - accuracy: 0.5328 - val_loss: 0.9519 - val_accuracy: 0.4810 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6955 - accuracy: 0.6419 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6897 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6793 - accuracy: 0.6513 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6913 - accuracy: 0.6268 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6728 - accuracy: 0.6434 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6801 - accuracy: 0.6470 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6894 - accuracy: 0.6275 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6922 - accuracy: 0.6333 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6926 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6795 - accuracy: 0.6383 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6985 - accuracy: 0.6477 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6961 - accuracy: 0.6254 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6972 - accuracy: 0.6290 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6815 - accuracy: 0.6405 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6900 - accuracy: 0.6254 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6949 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6825 - accuracy: 0.6441 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6847 - accuracy: 0.6340 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6738 - accuracy: 0.6282 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6781 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6851 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6882 - accuracy: 0.6398 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6715 - accuracy: 0.6491 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6792 - accuracy: 0.6405 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6873 - accuracy: 0.6297 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6818 - accuracy: 0.6470 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6894 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6999 - accuracy: 0.6333 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6967 - accuracy: 0.6347 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6887 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6933 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6803 - accuracy: 0.6405 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6893 - accuracy: 0.6506 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6935 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6857 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.6787 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6907 - accuracy: 0.6326 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6968 - accuracy: 0.6304 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6835 - accuracy: 0.6484 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6887 - accuracy: 0.6297 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6984 - accuracy: 0.6218 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7047 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6848 - accuracy: 0.6419 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6846 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6791 - accuracy: 0.6441 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6848 - accuracy: 0.6398 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6740 - accuracy: 0.6448 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.6905 - accuracy: 0.6419 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6977 - accuracy: 0.6261 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6863 - accuracy: 0.6218 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6904 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6894 - accuracy: 0.6304 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6938 - accuracy: 0.6297 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7002 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6802 - accuracy: 0.6333 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6800 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6985 - accuracy: 0.6390 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6867 - accuracy: 0.6311 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6917 - accuracy: 0.6376 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6934 - accuracy: 0.6333 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7006 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6936 - accuracy: 0.6225 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7040 - accuracy: 0.6347 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6879 - accuracy: 0.6455 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6987 - accuracy: 0.6347 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6872 - accuracy: 0.6340 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6961 - accuracy: 0.6419 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6974 - accuracy: 0.6419 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6859 - accuracy: 0.6412 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6904 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6774 - accuracy: 0.6340 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6845 - accuracy: 0.6434 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6832 - accuracy: 0.6311 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6793 - accuracy: 0.6491 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6949 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6941 - accuracy: 0.6326 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6875 - accuracy: 0.6297 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6774 - accuracy: 0.6527 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6886 - accuracy: 0.6290 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6922 - accuracy: 0.6210 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6960 - accuracy: 0.6369 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6827 - accuracy: 0.6448 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6936 - accuracy: 0.6491 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6845 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6916 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6825 - accuracy: 0.6376 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6994 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6991 - accuracy: 0.6340 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6848 - accuracy: 0.6427 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6894 - accuracy: 0.6362 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.7042 - accuracy: 0.6304 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6838 - accuracy: 0.6398 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6910 - accuracy: 0.6354 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.6915 - accuracy: 0.6304 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7000 - accuracy: 0.6268 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.7036 - accuracy: 0.6239 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6829 - accuracy: 0.6383 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.6923 - accuracy: 0.6340 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6921 - accuracy: 0.6239 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6819 - accuracy: 0.6477 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.6990 - accuracy: 0.6376 - val_loss: 0.7846 - val_accuracy: 0.5821 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8304 - accuracy: 0.5604 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8436 - accuracy: 0.5396 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8201 - accuracy: 0.5704 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8462 - accuracy: 0.5470 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8307 - accuracy: 0.5604 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8424 - accuracy: 0.5512 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8238 - accuracy: 0.5679 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8426 - accuracy: 0.5479 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8357 - accuracy: 0.5387 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8474 - accuracy: 0.5545 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8390 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8483 - accuracy: 0.5470 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8307 - accuracy: 0.5545 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8348 - accuracy: 0.5570 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8328 - accuracy: 0.5495 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8315 - accuracy: 0.5604 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8361 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8255 - accuracy: 0.5554 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8397 - accuracy: 0.5412 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8232 - accuracy: 0.5645 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8210 - accuracy: 0.5595 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8192 - accuracy: 0.5604 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8313 - accuracy: 0.5579 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.8368 - accuracy: 0.5445 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8358 - accuracy: 0.5445 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8463 - accuracy: 0.5479 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8218 - accuracy: 0.5562 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8386 - accuracy: 0.5520 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8410 - accuracy: 0.5437 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8332 - accuracy: 0.5587 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8311 - accuracy: 0.5645 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8301 - accuracy: 0.5604 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8196 - accuracy: 0.5487 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8273 - accuracy: 0.5587 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8319 - accuracy: 0.5595 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.8252 - accuracy: 0.5670 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8409 - accuracy: 0.5354 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8607 - accuracy: 0.5387 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8361 - accuracy: 0.5579 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8336 - accuracy: 0.5429 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8372 - accuracy: 0.5512 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8297 - accuracy: 0.5537 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8455 - accuracy: 0.5470 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8295 - accuracy: 0.5454 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8358 - accuracy: 0.5412 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8429 - accuracy: 0.5504 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8283 - accuracy: 0.5570 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8365 - accuracy: 0.5520 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8376 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8326 - accuracy: 0.5495 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8279 - accuracy: 0.5462 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8302 - accuracy: 0.5579 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8450 - accuracy: 0.5545 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8389 - accuracy: 0.5704 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8368 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8367 - accuracy: 0.5595 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8306 - accuracy: 0.5612 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8326 - accuracy: 0.5396 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8457 - accuracy: 0.5495 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8304 - accuracy: 0.5554 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8303 - accuracy: 0.5612 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8330 - accuracy: 0.5679 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8313 - accuracy: 0.5545 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8483 - accuracy: 0.5445 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8486 - accuracy: 0.5429 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8371 - accuracy: 0.5462 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8421 - accuracy: 0.5504 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8293 - accuracy: 0.5454 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8455 - accuracy: 0.5437 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8379 - accuracy: 0.5495 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8223 - accuracy: 0.5537 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8333 - accuracy: 0.5687 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8423 - accuracy: 0.5379 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8347 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8208 - accuracy: 0.5629 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8294 - accuracy: 0.5520 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.8352 - accuracy: 0.5462 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8479 - accuracy: 0.5529 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8429 - accuracy: 0.5570 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8392 - accuracy: 0.5396 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8281 - accuracy: 0.5687 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8269 - accuracy: 0.5637 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8261 - accuracy: 0.5545 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8616 - accuracy: 0.5346 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8372 - accuracy: 0.5504 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.8317 - accuracy: 0.5479 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8277 - accuracy: 0.5562 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8375 - accuracy: 0.5487 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8432 - accuracy: 0.5379 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8189 - accuracy: 0.5554 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.8494 - accuracy: 0.5420 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.8362 - accuracy: 0.5429 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8484 - accuracy: 0.5445 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8341 - accuracy: 0.5454 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8383 - accuracy: 0.5512 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8232 - accuracy: 0.5720 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8507 - accuracy: 0.5454 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8341 - accuracy: 0.5437 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8405 - accuracy: 0.5470 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.8612 - accuracy: 0.5404 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.8332 - accuracy: 0.5504 - val_loss: 0.8308 - val_accuracy: 0.5282 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.4937 - accuracy: 0.7648 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4995 - accuracy: 0.7598 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4896 - accuracy: 0.7685 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4924 - accuracy: 0.7663 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4976 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4760 - accuracy: 0.7880 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4842 - accuracy: 0.7728 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4927 - accuracy: 0.7713 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4916 - accuracy: 0.7800 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4976 - accuracy: 0.7742 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4944 - accuracy: 0.7619 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4802 - accuracy: 0.7851 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4902 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4855 - accuracy: 0.7858 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4886 - accuracy: 0.7721 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.4899 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4871 - accuracy: 0.7721 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4803 - accuracy: 0.7779 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5007 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.5015 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4947 - accuracy: 0.7699 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4856 - accuracy: 0.7858 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4906 - accuracy: 0.7771 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4814 - accuracy: 0.7858 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4874 - accuracy: 0.7786 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4913 - accuracy: 0.7735 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4926 - accuracy: 0.7663 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4918 - accuracy: 0.7800 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4839 - accuracy: 0.7844 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5008 - accuracy: 0.7735 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5006 - accuracy: 0.7540 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4905 - accuracy: 0.7713 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4939 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4797 - accuracy: 0.7779 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5065 - accuracy: 0.7590 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4937 - accuracy: 0.7742 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.4867 - accuracy: 0.7779 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.5003 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4784 - accuracy: 0.7916 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4824 - accuracy: 0.7800 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.5013 - accuracy: 0.7619 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4959 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4788 - accuracy: 0.7793 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4930 - accuracy: 0.7742 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4874 - accuracy: 0.7692 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4915 - accuracy: 0.7735 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4822 - accuracy: 0.7844 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4946 - accuracy: 0.7648 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4922 - accuracy: 0.7764 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4900 - accuracy: 0.7800 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4824 - accuracy: 0.7779 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4740 - accuracy: 0.7909 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4728 - accuracy: 0.7713 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4860 - accuracy: 0.7786 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4904 - accuracy: 0.7598 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4838 - accuracy: 0.7829 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4896 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4822 - accuracy: 0.7829 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4877 - accuracy: 0.7786 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4913 - accuracy: 0.7880 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4961 - accuracy: 0.7677 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4938 - accuracy: 0.7808 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4851 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4991 - accuracy: 0.7663 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4767 - accuracy: 0.7873 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.5032 - accuracy: 0.7648 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4940 - accuracy: 0.7735 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4934 - accuracy: 0.7685 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4892 - accuracy: 0.7779 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4896 - accuracy: 0.7800 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4923 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4977 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4933 - accuracy: 0.7844 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4852 - accuracy: 0.7721 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4942 - accuracy: 0.7728 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4962 - accuracy: 0.7822 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4860 - accuracy: 0.7822 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4963 - accuracy: 0.7677 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4987 - accuracy: 0.7656 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4958 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4947 - accuracy: 0.7590 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4905 - accuracy: 0.7641 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4912 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4922 - accuracy: 0.7728 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4935 - accuracy: 0.7692 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4941 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4960 - accuracy: 0.7590 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4890 - accuracy: 0.7706 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4862 - accuracy: 0.7677 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4899 - accuracy: 0.7721 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4910 - accuracy: 0.7735 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4938 - accuracy: 0.7670 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4877 - accuracy: 0.7836 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.5003 - accuracy: 0.7685 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4970 - accuracy: 0.7648 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4899 - accuracy: 0.7808 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4801 - accuracy: 0.7808 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4970 - accuracy: 0.7742 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4820 - accuracy: 0.7808 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4776 - accuracy: 0.7873 - val_loss: 0.4364 - val_accuracy: 0.8121 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.4336 - accuracy: 0.8051 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4305 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4316 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.4292 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4327 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4256 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4363 - accuracy: 0.7960 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4272 - accuracy: 0.8043 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4240 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4263 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4320 - accuracy: 0.7870 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4239 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4268 - accuracy: 0.7952 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4303 - accuracy: 0.7894 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4300 - accuracy: 0.7960 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4320 - accuracy: 0.7952 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4215 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4321 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4327 - accuracy: 0.8059 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4238 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4312 - accuracy: 0.7886 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4195 - accuracy: 0.8117 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4236 - accuracy: 0.8043 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4339 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4179 - accuracy: 0.8101 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4218 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4387 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4275 - accuracy: 0.8084 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4294 - accuracy: 0.7911 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4235 - accuracy: 0.8076 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4345 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4151 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4258 - accuracy: 0.7960 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4247 - accuracy: 0.8043 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4158 - accuracy: 0.8051 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4299 - accuracy: 0.8002 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4223 - accuracy: 0.8084 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4180 - accuracy: 0.8159 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4245 - accuracy: 0.8068 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4278 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4397 - accuracy: 0.7861 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.4354 - accuracy: 0.7927 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4221 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4281 - accuracy: 0.8002 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4227 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4247 - accuracy: 0.8126 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4354 - accuracy: 0.7960 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4279 - accuracy: 0.7903 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4276 - accuracy: 0.8002 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4227 - accuracy: 0.8043 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4232 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4236 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4166 - accuracy: 0.8159 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4379 - accuracy: 0.7886 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4225 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4293 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4287 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4302 - accuracy: 0.7977 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4281 - accuracy: 0.8068 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4303 - accuracy: 0.8126 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4231 - accuracy: 0.8134 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4283 - accuracy: 0.8059 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4202 - accuracy: 0.8109 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4222 - accuracy: 0.8134 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4272 - accuracy: 0.8035 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4212 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4271 - accuracy: 0.7985 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4273 - accuracy: 0.8043 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4386 - accuracy: 0.7936 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4277 - accuracy: 0.8010 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4342 - accuracy: 0.8051 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4236 - accuracy: 0.8051 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4302 - accuracy: 0.7936 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4247 - accuracy: 0.8126 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4256 - accuracy: 0.8068 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4327 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4367 - accuracy: 0.7927 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4258 - accuracy: 0.8092 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4322 - accuracy: 0.8002 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4265 - accuracy: 0.8018 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4209 - accuracy: 0.8101 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4250 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4344 - accuracy: 0.7944 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.4270 - accuracy: 0.7944 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4193 - accuracy: 0.7985 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4252 - accuracy: 0.8117 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4336 - accuracy: 0.7985 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4293 - accuracy: 0.8068 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4229 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4319 - accuracy: 0.7985 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.4208 - accuracy: 0.7993 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4302 - accuracy: 0.8026 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.4335 - accuracy: 0.7960 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.4333 - accuracy: 0.7977 - val_loss: 0.5027 - val_accuracy: 0.7591 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4646 - accuracy: 0.7976 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4714 - accuracy: 0.7781 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4649 - accuracy: 0.7961 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4799 - accuracy: 0.7752 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4798 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4729 - accuracy: 0.7853 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4819 - accuracy: 0.7752 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4684 - accuracy: 0.7947 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4790 - accuracy: 0.7911 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4657 - accuracy: 0.7918 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.4665 - accuracy: 0.7889 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4726 - accuracy: 0.7767 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4682 - accuracy: 0.7918 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4734 - accuracy: 0.7889 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4713 - accuracy: 0.7976 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4723 - accuracy: 0.7788 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4660 - accuracy: 0.7911 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4720 - accuracy: 0.7889 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4835 - accuracy: 0.7752 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.7860 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4748 - accuracy: 0.7867 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4755 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4738 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "87/87 [==============================] - 1s 15ms/step - loss: 0.4802 - accuracy: 0.7803 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4736 - accuracy: 0.7846 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4698 - accuracy: 0.7954 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4677 - accuracy: 0.7817 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4740 - accuracy: 0.7961 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4743 - accuracy: 0.7983 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4691 - accuracy: 0.7918 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4761 - accuracy: 0.7831 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4663 - accuracy: 0.7867 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4680 - accuracy: 0.7911 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4712 - accuracy: 0.7947 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4709 - accuracy: 0.7968 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4626 - accuracy: 0.7947 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4774 - accuracy: 0.7788 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4793 - accuracy: 0.7846 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4717 - accuracy: 0.7824 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4665 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4777 - accuracy: 0.7846 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4787 - accuracy: 0.7795 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4783 - accuracy: 0.7745 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4836 - accuracy: 0.7824 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "87/87 [==============================] - 1s 12ms/step - loss: 0.4660 - accuracy: 0.7860 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4640 - accuracy: 0.7976 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4648 - accuracy: 0.7947 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4758 - accuracy: 0.7817 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4756 - accuracy: 0.7939 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4641 - accuracy: 0.7903 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4606 - accuracy: 0.7954 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4704 - accuracy: 0.7738 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4809 - accuracy: 0.7824 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4631 - accuracy: 0.7860 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4770 - accuracy: 0.7846 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4630 - accuracy: 0.7997 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4740 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4688 - accuracy: 0.7947 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4701 - accuracy: 0.7839 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4784 - accuracy: 0.7781 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4639 - accuracy: 0.7961 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4816 - accuracy: 0.7846 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4688 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4768 - accuracy: 0.7911 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4659 - accuracy: 0.8012 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4760 - accuracy: 0.7853 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.7824 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4703 - accuracy: 0.7903 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4702 - accuracy: 0.7932 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4743 - accuracy: 0.7803 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4791 - accuracy: 0.7860 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4744 - accuracy: 0.7839 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4739 - accuracy: 0.7860 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4782 - accuracy: 0.7839 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4598 - accuracy: 0.8048 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.7767 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4783 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4677 - accuracy: 0.7925 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4735 - accuracy: 0.8026 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4728 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4801 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4742 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4785 - accuracy: 0.7831 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4568 - accuracy: 0.8019 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4756 - accuracy: 0.7839 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4673 - accuracy: 0.7875 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4812 - accuracy: 0.7882 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4801 - accuracy: 0.7810 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4764 - accuracy: 0.7810 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "87/87 [==============================] - 1s 14ms/step - loss: 0.4603 - accuracy: 0.8069 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4703 - accuracy: 0.7767 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4741 - accuracy: 0.7810 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4764 - accuracy: 0.7817 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4821 - accuracy: 0.7911 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4763 - accuracy: 0.7896 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4728 - accuracy: 0.7939 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4704 - accuracy: 0.7961 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "87/87 [==============================] - 1s 13ms/step - loss: 0.4837 - accuracy: 0.7752 - val_loss: 0.4090 - val_accuracy: 0.8415 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5838 - accuracy: 0.7177 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5868 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5870 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5908 - accuracy: 0.7261 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5890 - accuracy: 0.7319 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5862 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5876 - accuracy: 0.7269 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5808 - accuracy: 0.7202 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5856 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5863 - accuracy: 0.7152 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5827 - accuracy: 0.7211 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5875 - accuracy: 0.7410 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5889 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "76/76 [==============================] - 1s 16ms/step - loss: 0.5854 - accuracy: 0.7152 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5748 - accuracy: 0.7336 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5889 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5866 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5796 - accuracy: 0.7336 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5888 - accuracy: 0.7194 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5814 - accuracy: 0.7102 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5864 - accuracy: 0.7244 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5673 - accuracy: 0.7311 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5835 - accuracy: 0.7311 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5870 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5854 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5819 - accuracy: 0.7327 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5980 - accuracy: 0.7194 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5878 - accuracy: 0.7244 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5764 - accuracy: 0.7302 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5898 - accuracy: 0.7202 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5828 - accuracy: 0.7211 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5844 - accuracy: 0.7086 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5877 - accuracy: 0.7161 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5757 - accuracy: 0.7344 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5963 - accuracy: 0.7186 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5788 - accuracy: 0.7261 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5928 - accuracy: 0.7102 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5977 - accuracy: 0.7069 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5841 - accuracy: 0.7261 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5948 - accuracy: 0.7177 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5847 - accuracy: 0.7211 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.6029 - accuracy: 0.7244 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5995 - accuracy: 0.7169 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5858 - accuracy: 0.7152 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5972 - accuracy: 0.7019 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5961 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5906 - accuracy: 0.7277 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5908 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5870 - accuracy: 0.7261 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5873 - accuracy: 0.7386 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5825 - accuracy: 0.7219 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5881 - accuracy: 0.7227 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5907 - accuracy: 0.7094 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5837 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5805 - accuracy: 0.7269 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5878 - accuracy: 0.7019 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5927 - accuracy: 0.7077 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5905 - accuracy: 0.7186 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5922 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5971 - accuracy: 0.7094 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5779 - accuracy: 0.7177 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5875 - accuracy: 0.7277 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.6004 - accuracy: 0.7194 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5759 - accuracy: 0.7402 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5808 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5810 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5849 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5873 - accuracy: 0.7227 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5864 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5943 - accuracy: 0.6994 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5815 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5808 - accuracy: 0.7086 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5926 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.6062 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5952 - accuracy: 0.7094 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5873 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5838 - accuracy: 0.7094 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5788 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.5909 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5838 - accuracy: 0.7086 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5819 - accuracy: 0.7161 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5823 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5799 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5822 - accuracy: 0.7069 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5869 - accuracy: 0.7286 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5793 - accuracy: 0.7227 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5865 - accuracy: 0.7302 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.6033 - accuracy: 0.7119 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5889 - accuracy: 0.7186 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5878 - accuracy: 0.7194 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5868 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5875 - accuracy: 0.7177 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5759 - accuracy: 0.7319 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5887 - accuracy: 0.7202 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5805 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5840 - accuracy: 0.7227 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5908 - accuracy: 0.7127 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5966 - accuracy: 0.7136 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "76/76 [==============================] - 1s 13ms/step - loss: 0.5919 - accuracy: 0.7144 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5918 - accuracy: 0.7252 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "76/76 [==============================] - 1s 14ms/step - loss: 0.5931 - accuracy: 0.7111 - val_loss: 0.5253 - val_accuracy: 0.7542 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n",
            "Epoch 1/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6035 - accuracy: 0.7051 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 2/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6172 - accuracy: 0.7000 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 3/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6140 - accuracy: 0.7029 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 4/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6207 - accuracy: 0.6854 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 5/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6053 - accuracy: 0.7109 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 6/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5961 - accuracy: 0.7058 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 7/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5997 - accuracy: 0.7131 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 8/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6108 - accuracy: 0.7051 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 9/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6045 - accuracy: 0.6971 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 10/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6021 - accuracy: 0.7226 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 11/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6032 - accuracy: 0.7022 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 12/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.6085 - accuracy: 0.6861 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 13/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6106 - accuracy: 0.6993 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 14/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6068 - accuracy: 0.6956 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 15/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6015 - accuracy: 0.7088 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 16/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5986 - accuracy: 0.7015 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 17/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6056 - accuracy: 0.7080 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 18/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6003 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 19/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5989 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 20/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6019 - accuracy: 0.7058 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 21/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6157 - accuracy: 0.6956 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 22/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5998 - accuracy: 0.7197 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 23/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6074 - accuracy: 0.6927 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 24/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6082 - accuracy: 0.7109 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 25/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6072 - accuracy: 0.6927 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 26/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6017 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 27/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5995 - accuracy: 0.7066 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 28/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5909 - accuracy: 0.7124 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 29/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5935 - accuracy: 0.7000 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 30/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6022 - accuracy: 0.7066 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 31/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6101 - accuracy: 0.7000 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 32/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6105 - accuracy: 0.6978 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 33/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6043 - accuracy: 0.6854 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 34/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6038 - accuracy: 0.7102 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 35/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6078 - accuracy: 0.6978 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 36/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.6074 - accuracy: 0.6985 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 37/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6159 - accuracy: 0.7117 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 38/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6115 - accuracy: 0.7095 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 39/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6044 - accuracy: 0.7000 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 40/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6037 - accuracy: 0.7022 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 41/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6076 - accuracy: 0.7051 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 42/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5955 - accuracy: 0.7102 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 43/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6111 - accuracy: 0.6985 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 44/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6246 - accuracy: 0.6883 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 45/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5976 - accuracy: 0.7153 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 46/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6079 - accuracy: 0.7022 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 47/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6032 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 48/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6167 - accuracy: 0.6934 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 49/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5887 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 50/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.6120 - accuracy: 0.6934 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 51/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6083 - accuracy: 0.6971 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 52/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6114 - accuracy: 0.6978 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 53/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6093 - accuracy: 0.7058 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 54/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6111 - accuracy: 0.7036 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 55/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6144 - accuracy: 0.6883 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 56/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6104 - accuracy: 0.6964 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 57/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6076 - accuracy: 0.7022 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 58/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.6131 - accuracy: 0.7007 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 59/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6136 - accuracy: 0.6971 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 60/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6028 - accuracy: 0.7190 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 61/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6018 - accuracy: 0.7095 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 62/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6075 - accuracy: 0.7007 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 63/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6127 - accuracy: 0.6971 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 64/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6187 - accuracy: 0.6854 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 65/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.5954 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 66/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6042 - accuracy: 0.6964 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 67/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6112 - accuracy: 0.6898 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 68/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6025 - accuracy: 0.7175 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 69/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6083 - accuracy: 0.6942 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 70/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6059 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 71/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6121 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 72/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6031 - accuracy: 0.6985 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 73/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.6087 - accuracy: 0.6964 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 74/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6028 - accuracy: 0.7051 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 75/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5984 - accuracy: 0.7022 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 76/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.5951 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 77/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5970 - accuracy: 0.7029 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 78/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6069 - accuracy: 0.6934 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 79/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.5873 - accuracy: 0.7095 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 80/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6124 - accuracy: 0.6927 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 81/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6051 - accuracy: 0.6993 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 82/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6062 - accuracy: 0.6985 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 83/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6081 - accuracy: 0.6971 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 84/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6076 - accuracy: 0.7153 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 85/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5942 - accuracy: 0.7080 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 86/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6070 - accuracy: 0.7051 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 87/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6045 - accuracy: 0.7073 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 88/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6021 - accuracy: 0.6891 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 89/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6020 - accuracy: 0.6964 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 90/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5945 - accuracy: 0.7153 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 91/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5984 - accuracy: 0.7124 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 92/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6049 - accuracy: 0.7102 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 93/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6062 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 94/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6015 - accuracy: 0.7044 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 95/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6112 - accuracy: 0.7066 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 96/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6048 - accuracy: 0.6942 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 97/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6125 - accuracy: 0.7015 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 98/10000\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.6133 - accuracy: 0.7029 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 99/10000\n",
            "86/86 [==============================] - 1s 12ms/step - loss: 0.6110 - accuracy: 0.7088 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 100/10000\n",
            "86/86 [==============================] - 1s 13ms/step - loss: 0.6074 - accuracy: 0.7036 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 101/10000\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.6061 - accuracy: 0.7007 - val_loss: 0.5438 - val_accuracy: 0.7434 - lr: 1.0000e-20\n",
            "Epoch 101: early stopping\n"
          ]
        }
      ],
      "source": [
        "#For RNN\n",
        "models_rnn = []\n",
        "histories_rnn = []\n",
        "for i in range(len(datasets)):\n",
        "  history_rnn = fit_model(model_rnn,X_train_all[i],y_train_all[i]) #Call back that records events into history object\n",
        "  models_rnn.append(model_rnn)\n",
        "  histories_rnn.append(history_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORlaSC-L8rbF"
      },
      "source": [
        "## **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDgxR5S9aw4m"
      },
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "def prediction(x_test, model):\n",
        "    prediction = model.predict(x_test)\n",
        "    prediction1 = []\n",
        "    #sigmoid function is used in the last layer hence if output is greater than 0.5 then pred = 1 and vice versa\n",
        "    #for i in range(len(prediction)):\n",
        "     #if prediction[i]<0.5:\n",
        "       #prediction[i]=1\n",
        "     #else:\n",
        "       #prediction[i]=0\n",
        "    for i in range(len(prediction)):\n",
        "       if prediction[i][0]>prediction[i][1]:\n",
        "         prediction1.append(0)\n",
        "       else:\n",
        "         prediction1.append(1)\n",
        "\n",
        "    return prediction1\n",
        "\n",
        "# Plot test data vs prediction\n",
        "def plot_conf_matrix(prediction, model_name, y_test):\n",
        "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=prediction)\n",
        "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "    plt.xlabel('Predictions', fontsize=18)\n",
        "    plt.ylabel('Actuals', fontsize=18)\n",
        "    plt.title('Confusion Matrix {model_name}'.format(model_name = model_name), fontsize=18)\n",
        "    plt.show()  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics**"
      ],
      "metadata": {
        "id": "-m5UknAQ4Ya-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI5aYhHPbnQb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def compute_precision(y_test,pred):\n",
        "\ttn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
        "\t'''\n",
        "\tPrecision = TP  / FP + TP \n",
        "\n",
        "\t'''\n",
        "\treturn (tp )/ float( tp + fp)\n",
        "def compute_recall(y_test,pred):\n",
        "\ttn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
        "\t'''\n",
        "\tRecall = TP /FN + TP \n",
        "\n",
        "\t'''\n",
        "\treturn (tp  )/ float( tp + fn)\n",
        "def compute_f1_score(y_test, pred):\n",
        "    # calculates the F1 score\n",
        "    precision = compute_precision(y_test, pred)\n",
        "    recall = compute_recall(y_test, pred)\n",
        "    f1_score = (2*precision*recall)/ (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "def compute_accuracy(y_test, pred):\n",
        "\t\ttn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
        "\t\treturn (tp+tn)/float(tp+tn+fp+fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL4aRj9JcinJ"
      },
      "outputs": [],
      "source": [
        "fname = []\n",
        "for filename in os.listdir(directory):\n",
        "    fname.append(filename[1:-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Precision**"
      ],
      "metadata": {
        "id": "rUgYeiMG4YUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for GRU\n",
        "precision = 0\n",
        "precision_scores_array_gru = []\n",
        "prediction_gru_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_gru_all[i] = prediction(X_test_all[i],model_gru)\n",
        "  precision = compute_precision(y_test_all[i], prediction_gru_all[i])\n",
        "  precision_scores_array_gru.append(precision)"
      ],
      "metadata": {
        "id": "Elv42OwRSsIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for LSTM\n",
        "precision = 0\n",
        "precision_scores_array_lstm = []\n",
        "prediction_lstm_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_lstm_all[i] = prediction(X_test_all[i],model_lstm)\n",
        "  precision = compute_precision(y_test_all[i], prediction_lstm_all[i])\n",
        "  precision_scores_array_lstm.append(precision)"
      ],
      "metadata": {
        "id": "60RxN_kb2YgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for RNN\n",
        "precision = 0\n",
        "precision_scores_array_rnn = []\n",
        "prediction_rnn_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_rnn_all[i] = prediction(X_test_all[i],model_rnn)\n",
        "  precision = compute_precision(y_test_all[i], prediction_rnn_all[i])\n",
        "  precision_scores_array_rnn.append(precision)"
      ],
      "metadata": {
        "id": "U3pu3AKS2z4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Index': fname, 'GRU': precision_scores_array_gru,'LSTM': precision_scores_array_lstm,'RNN': precision_scores_array_rnn}\n",
        "precision_scores_df = pd.DataFrame()\n",
        "precision_scores_df = pd.DataFrame(data)\n",
        "precision_scores_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "50S7cVXY3w9x",
        "outputId": "d0224abb-af38-4e62-e697-df457686d101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Index       GRU      LSTM       RNN\n",
              "0     NSEBANK_05  0.500000  0.437500  0.450000\n",
              "1       BSESN_05  0.500000  0.250000  0.321429\n",
              "2        NSEI_05  0.333333  0.454545  0.275862\n",
              "3       CNXIT_05  0.000000  0.250000  0.314815\n",
              "4   NSEMDCP50_05  0.526316  0.407407  0.268657\n",
              "5        NSEI_02  0.500000  0.454545  0.431034\n",
              "6     NSEBANK_02  0.500000  0.500000  0.575000\n",
              "7   NSEMDCP50_02  0.578947  0.481481  0.358209\n",
              "8       BSESN_02  0.750000  0.250000  0.535714\n",
              "9       CNXIT_02  0.666667  0.500000  0.462963\n",
              "10       NSEI_10  0.166667  0.272727  0.103448\n",
              "11    NSEBANK_10  0.500000  0.312500  0.175000\n",
              "12      BSESN_10  0.500000  0.250000  0.107143\n",
              "13      CNXIT_10  0.000000  0.000000  0.166667\n",
              "14  NSEMDCP50_10  0.210526  0.222222  0.104478"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e518dbd-c331-4015-8b49-5f4aef731435\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NSEBANK_05</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSESN_05</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.321429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSEI_05</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.275862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNXIT_05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.314815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSEMDCP50_05</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.268657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NSEI_02</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.431034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NSEBANK_02</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NSEMDCP50_02</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.358209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BSESN_02</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.535714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNXIT_02</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.462963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NSEI_10</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.103448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NSEBANK_10</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BSESN_10</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.107143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CNXIT_10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NSEMDCP50_10</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.104478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e518dbd-c331-4015-8b49-5f4aef731435')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e518dbd-c331-4015-8b49-5f4aef731435 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e518dbd-c331-4015-8b49-5f4aef731435');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Recall**"
      ],
      "metadata": {
        "id": "ZxNHjTUO41jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for GRU\n",
        "recall = 0\n",
        "recall_scores_array_gru = []\n",
        "prediction_gru_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_gru_all[i] = prediction(X_test_all[i],model_gru)\n",
        "  recall = compute_recall(y_test_all[i], prediction_gru_all[i])\n",
        "  recall_scores_array_gru.append(recall)"
      ],
      "metadata": {
        "id": "Mwl4Vs45pNAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for LSTM\n",
        "recall = 0\n",
        "recall_scores_array_lstm = []\n",
        "prediction_lstm_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_lstm_all[i] = prediction(X_test_all[i],model_lstm)\n",
        "  recall = compute_recall(y_test_all[i], prediction_lstm_all[i])\n",
        "  recall_scores_array_lstm.append(recall)"
      ],
      "metadata": {
        "id": "3SqSU8aj3Fnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for RNN\n",
        "recall = 0\n",
        "recall_scores_array_rnn = []\n",
        "prediction_rnn_all = [0]*len(datasets)\n",
        "for i in range(len(datasets)):\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  prediction_rnn_all[i] = prediction(X_test_all[i],model_rnn)\n",
        "  recall = compute_recall(y_test_all[i], prediction_rnn_all[i])\n",
        "  recall_scores_array_rnn.append(recall)"
      ],
      "metadata": {
        "id": "aESZRCP93YpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Index': fname, 'GRU': recall_scores_array_gru,'LSTM': recall_scores_array_lstm,'RNN': recall_scores_array_rnn}\n",
        "recall_scores_df = pd.DataFrame()\n",
        "recall_scores_df = pd.DataFrame(data)\n",
        "recall_scores_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "2fhAgyDC4Kpt",
        "outputId": "b8ddcfdd-d8c2-4a41-8a0c-001e03da4bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Index       GRU      LSTM       RNN\n",
              "0     NSEBANK_05  0.048000  0.056000  0.144000\n",
              "1       BSESN_05  0.017094  0.008547  0.153846\n",
              "2        NSEI_05  0.017241  0.043103  0.137931\n",
              "3       CNXIT_05  0.000000  0.008197  0.139344\n",
              "4   NSEMDCP50_05  0.070922  0.078014  0.127660\n",
              "5        NSEI_02  0.016575  0.027624  0.138122\n",
              "6     NSEBANK_02  0.036585  0.048780  0.140244\n",
              "7   NSEMDCP50_02  0.058511  0.069149  0.127660\n",
              "8       BSESN_02  0.016129  0.005376  0.161290\n",
              "9       CNXIT_02  0.012121  0.012121  0.151515\n",
              "10       NSEI_10  0.027027  0.081081  0.162162\n",
              "11    NSEBANK_10  0.101695  0.084746  0.118644\n",
              "12      BSESN_10  0.051282  0.025641  0.153846\n",
              "13      CNXIT_10  0.000000  0.000000  0.157895\n",
              "14  NSEMDCP50_10  0.063492  0.095238  0.111111"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eeb3c010-06a2-4230-84ce-48565b20dbf5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NSEBANK_05</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.144000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSESN_05</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSEI_05</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.043103</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNXIT_05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008197</td>\n",
              "      <td>0.139344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSEMDCP50_05</td>\n",
              "      <td>0.070922</td>\n",
              "      <td>0.078014</td>\n",
              "      <td>0.127660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NSEI_02</td>\n",
              "      <td>0.016575</td>\n",
              "      <td>0.027624</td>\n",
              "      <td>0.138122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NSEBANK_02</td>\n",
              "      <td>0.036585</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.140244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NSEMDCP50_02</td>\n",
              "      <td>0.058511</td>\n",
              "      <td>0.069149</td>\n",
              "      <td>0.127660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BSESN_02</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.005376</td>\n",
              "      <td>0.161290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNXIT_02</td>\n",
              "      <td>0.012121</td>\n",
              "      <td>0.012121</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NSEI_10</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NSEBANK_10</td>\n",
              "      <td>0.101695</td>\n",
              "      <td>0.084746</td>\n",
              "      <td>0.118644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BSESN_10</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CNXIT_10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NSEMDCP50_10</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeb3c010-06a2-4230-84ce-48565b20dbf5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eeb3c010-06a2-4230-84ce-48565b20dbf5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eeb3c010-06a2-4230-84ce-48565b20dbf5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce44hlU1Ytnq"
      },
      "source": [
        "### **Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubUKALdFGyxT"
      },
      "outputs": [],
      "source": [
        "#for GRU\n",
        "accuracy_all_gru = []\n",
        "prediction_gru_all = [0]*len(datasets)\n",
        "acc = 0\n",
        "for i in range(len(datasets)):\n",
        "  prediction_gru_all[i] = prediction(X_test_all[i],model_gru)\n",
        "  acc = compute_accuracy(y_test_all[i],prediction_gru_all[i])\n",
        "  accuracy_all_gru.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDcxndGvK91V"
      },
      "outputs": [],
      "source": [
        "#for LSTM\n",
        "accuracy_all_lstm = []\n",
        "acc = 0\n",
        "for i in range(len(datasets)):\n",
        "  acc = compute_accuracy(y_test_all[i],prediction_lstm_all[i])\n",
        "  accuracy_all_lstm.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqSLwU7hXrgw"
      },
      "outputs": [],
      "source": [
        "#for RNN\n",
        "accuracy_all_rnn = []\n",
        "acc = 0\n",
        "for i in range(len(datasets)):\n",
        "  acc = compute_accuracy(y_test_all[i],prediction_rnn_all[i])\n",
        "  accuracy_all_rnn.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Index': fname, 'GRU': accuracy_all_gru ,'LSTM': accuracy_all_lstm,'RNN': accuracy_all_rnn}\n",
        "accuracy_scores_df = pd.DataFrame()\n",
        "accuracy_scores_df = pd.DataFrame(data)\n",
        "accuracy_scores_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "IH9U8mGYQdPA",
        "outputId": "d857a995-3833-484e-ca6a-ac5785024057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Index       GRU      LSTM       RNN\n",
              "0     NSEBANK_05  0.663073  0.657682  0.652291\n",
              "1       BSESN_05  0.725995  0.721311  0.679157\n",
              "2        NSEI_05  0.722353  0.724706  0.665882\n",
              "3       CNXIT_05  0.660326  0.663043  0.614130\n",
              "4   NSEMDCP50_05  0.667458  0.653207  0.591449\n",
              "5        NSEI_02  0.574118  0.571765  0.555294\n",
              "6     NSEBANK_02  0.557951  0.557951  0.574124\n",
              "7   NSEMDCP50_02  0.560570  0.551069  0.508314\n",
              "8       BSESN_02  0.569087  0.559719  0.573770\n",
              "9       CNXIT_02  0.554348  0.551630  0.540761\n",
              "10       NSEI_10  0.903529  0.901176  0.804706\n",
              "11    NSEBANK_10  0.840970  0.824798  0.770889\n",
              "12      BSESN_10  0.908665  0.903981  0.805621\n",
              "13      CNXIT_10  0.836957  0.834239  0.747283\n",
              "14  NSEMDCP50_10  0.824228  0.814727  0.724466"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f8186e8-e135-49a0-a7af-3d0f48d0885f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NSEBANK_05</td>\n",
              "      <td>0.663073</td>\n",
              "      <td>0.657682</td>\n",
              "      <td>0.652291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSESN_05</td>\n",
              "      <td>0.725995</td>\n",
              "      <td>0.721311</td>\n",
              "      <td>0.679157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSEI_05</td>\n",
              "      <td>0.722353</td>\n",
              "      <td>0.724706</td>\n",
              "      <td>0.665882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNXIT_05</td>\n",
              "      <td>0.660326</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.614130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSEMDCP50_05</td>\n",
              "      <td>0.667458</td>\n",
              "      <td>0.653207</td>\n",
              "      <td>0.591449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NSEI_02</td>\n",
              "      <td>0.574118</td>\n",
              "      <td>0.571765</td>\n",
              "      <td>0.555294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NSEBANK_02</td>\n",
              "      <td>0.557951</td>\n",
              "      <td>0.557951</td>\n",
              "      <td>0.574124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NSEMDCP50_02</td>\n",
              "      <td>0.560570</td>\n",
              "      <td>0.551069</td>\n",
              "      <td>0.508314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BSESN_02</td>\n",
              "      <td>0.569087</td>\n",
              "      <td>0.559719</td>\n",
              "      <td>0.573770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNXIT_02</td>\n",
              "      <td>0.554348</td>\n",
              "      <td>0.551630</td>\n",
              "      <td>0.540761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NSEI_10</td>\n",
              "      <td>0.903529</td>\n",
              "      <td>0.901176</td>\n",
              "      <td>0.804706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NSEBANK_10</td>\n",
              "      <td>0.840970</td>\n",
              "      <td>0.824798</td>\n",
              "      <td>0.770889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BSESN_10</td>\n",
              "      <td>0.908665</td>\n",
              "      <td>0.903981</td>\n",
              "      <td>0.805621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CNXIT_10</td>\n",
              "      <td>0.836957</td>\n",
              "      <td>0.834239</td>\n",
              "      <td>0.747283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NSEMDCP50_10</td>\n",
              "      <td>0.824228</td>\n",
              "      <td>0.814727</td>\n",
              "      <td>0.724466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f8186e8-e135-49a0-a7af-3d0f48d0885f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f8186e8-e135-49a0-a7af-3d0f48d0885f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f8186e8-e135-49a0-a7af-3d0f48d0885f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSqXrcAGJ_QF"
      },
      "source": [
        "### **F1-Scores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORgGxaWWIG_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb6875b-0d21-4d33-b859-fe04e545964e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        }
      ],
      "source": [
        "#for GRU\n",
        "prediction_gru_all = [0]*len(datasets)\n",
        "f1 = 0\n",
        "f1_scores_array_gru = []\n",
        "for i in range(len(datasets)):\n",
        "  prediction_gru_all[i] = prediction(X_test_all[i],model_gru)\n",
        "  #plot_conf_matrix(prediction_gru_all[i], 'GRU', y_test_all[i])\n",
        "  f1 = compute_f1_score(y_test_all[i], prediction_gru_all[i])\n",
        "  f1_scores_array_gru.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "als_MIEOKYM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b688ad0f-f21e-4975-b989-e9d8080684d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        }
      ],
      "source": [
        "#for LSTM\n",
        "prediction_lstm_all = [0]*len(datasets)\n",
        "f1 = 0\n",
        "f1_scores_array_lstm = []\n",
        "for i in range(len(datasets)):\n",
        "  prediction_lstm_all[i] = prediction(X_test_all[i],models_lstm[i])\n",
        "  #plot_conf_matrix(prediction_lstm_all[i], 'LSTM', y_test_all[i])\n",
        "  f1 = compute_f1_score(y_test_all[i], prediction_lstm_all[i])\n",
        "  f1_scores_array_lstm.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfYPVHAjXYPi"
      },
      "outputs": [],
      "source": [
        "#for RNN\n",
        "prediction_rnn_all = [0]*len(datasets)\n",
        "f1 = 0\n",
        "f1_scores_array_rnn = []\n",
        "for i in range(len(datasets)):\n",
        "  prediction_rnn_all[i] = prediction(X_test_all[i],models_rnn[i])\n",
        "  #plot_conf_matrix(prediction_lstm_all[i], 'LSTM', y_test_all[i])\n",
        "  f1 = compute_f1_score(y_test_all[i], prediction_rnn_all[i])\n",
        "  f1_scores_array_rnn.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Index': fname, 'GRU': f1_scores_array_gru,'LSTM': f1_scores_array_lstm,'RNN': f1_scores_array_rnn}\n",
        "f1_scores_df = pd.DataFrame()\n",
        "f1_scores_df = pd.DataFrame(data)\n",
        "f1_scores_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "9e9v30e_OLmr",
        "outputId": "e9e3234e-9608-4fac-d65e-f36e701ecb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Index       GRU      LSTM       RNN\n",
              "0     NSEBANK_05  0.087591  0.099291  0.218182\n",
              "1       BSESN_05  0.033058  0.016529  0.208092\n",
              "2        NSEI_05  0.032787  0.078740  0.183908\n",
              "3       CNXIT_05       NaN  0.015873  0.193182\n",
              "4   NSEMDCP50_05  0.125000  0.130952  0.173077\n",
              "5        NSEI_02  0.032086  0.052083  0.209205\n",
              "6     NSEBANK_02  0.068182  0.088889  0.225490\n",
              "7   NSEMDCP50_02  0.106280  0.120930  0.188235\n",
              "8       BSESN_02  0.031579  0.010526  0.247934\n",
              "9       CNXIT_02  0.023810  0.023669  0.228311\n",
              "10       NSEI_10  0.046512  0.125000  0.126316\n",
              "11    NSEBANK_10  0.169014  0.133333  0.141414\n",
              "12      BSESN_10  0.093023  0.046512  0.126316\n",
              "13      CNXIT_10       NaN       NaN  0.162162\n",
              "14  NSEMDCP50_10  0.097561  0.133333  0.107692"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5eee4a4-301e-4cd8-8af3-af9d6aa0f32d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NSEBANK_05</td>\n",
              "      <td>0.087591</td>\n",
              "      <td>0.099291</td>\n",
              "      <td>0.218182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSESN_05</td>\n",
              "      <td>0.033058</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.208092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSEI_05</td>\n",
              "      <td>0.032787</td>\n",
              "      <td>0.078740</td>\n",
              "      <td>0.183908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNXIT_05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.015873</td>\n",
              "      <td>0.193182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSEMDCP50_05</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.130952</td>\n",
              "      <td>0.173077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NSEI_02</td>\n",
              "      <td>0.032086</td>\n",
              "      <td>0.052083</td>\n",
              "      <td>0.209205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NSEBANK_02</td>\n",
              "      <td>0.068182</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.225490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NSEMDCP50_02</td>\n",
              "      <td>0.106280</td>\n",
              "      <td>0.120930</td>\n",
              "      <td>0.188235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BSESN_02</td>\n",
              "      <td>0.031579</td>\n",
              "      <td>0.010526</td>\n",
              "      <td>0.247934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNXIT_02</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.023669</td>\n",
              "      <td>0.228311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NSEI_10</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.126316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NSEBANK_10</td>\n",
              "      <td>0.169014</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.141414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BSESN_10</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>0.126316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CNXIT_10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NSEMDCP50_10</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.107692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5eee4a4-301e-4cd8-8af3-af9d6aa0f32d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5eee4a4-301e-4cd8-8af3-af9d6aa0f32d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5eee4a4-301e-4cd8-8af3-af9d6aa0f32d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(os.path.isfile('/content/drive/MyDrive/binary_prediction/Metrics/metrics.xlsx')==True):\n",
        "  os.remove('/content/drive/MyDrive/binary_prediction/Metrics/metrics.xlsx')\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/binary_prediction/Metrics/metrics.xlsx') as writer:  \n",
        "    f1_scores_df.to_excel(writer, sheet_name='F1-score')\n",
        "    accuracy_scores_df.to_excel(writer, sheet_name='accuracy')\n",
        "    precision_scores_df.to_excel(writer, sheet_name='precision')\n",
        "    recall_scores_df.to_excel(writer, sheet_name='recall')"
      ],
      "metadata": {
        "id": "ATN5tLTQ6hVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "gru_lstm_rnn_omkar.ipynb",
      "provenance": [],
      "mount_file_id": "1_1AI4eDsQiK4jOfXqZLMN5frdFewRiVu",
      "authorship_tag": "ABX9TyM2giexNeTfbNE5tQE25Cx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}